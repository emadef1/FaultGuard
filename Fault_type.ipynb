{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7336598,
          "sourceType": "datasetVersion",
          "datasetId": 4259241
        },
        {
          "sourceId": 7358200,
          "sourceType": "datasetVersion",
          "datasetId": 4273891
        },
        {
          "sourceId": 7487035,
          "sourceType": "datasetVersion",
          "datasetId": 4358836
        }
      ],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:08.708773Z",
          "iopub.execute_input": "2024-02-06T14:39:08.709082Z",
          "iopub.status.idle": "2024-02-06T14:39:12.686144Z",
          "shell.execute_reply.started": "2024-02-06T14:39:08.709056Z",
          "shell.execute_reply": "2024-02-06T14:39:12.684832Z"
        },
        "trusted": true,
        "id": "LnC_d-NoXcmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Set the path to the directory containing the datasets\n",
        "dataset_path = '/kaggle/input/fault-detection'\n",
        "\n",
        "# Get the list of files in the directory\n",
        "files = os.listdir(dataset_path)\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through the files and read them into DataFrames\n",
        "for file in files[:3]:  # Assuming you want to read the first 15 datasets\n",
        "    file_path = os.path.join(dataset_path, file)\n",
        "    df= pd.read_csv(file_path)\n",
        "    # df['class'] = 'faultySignal'  # Change the file reading method based on your file format\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into one\n",
        "final_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "final_df\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:12.687775Z",
          "iopub.execute_input": "2024-02-06T14:39:12.688265Z",
          "iopub.status.idle": "2024-02-06T14:39:12.982503Z",
          "shell.execute_reply.started": "2024-02-06T14:39:12.688232Z",
          "shell.execute_reply": "2024-02-06T14:39:12.981495Z"
        },
        "trusted": true,
        "id": "j_mc6gogXcmL",
        "outputId": "dc33d00c-accf-40ce-c473-aefbcc4e67cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         norm_t    mean_t     std_t    skew_t    kurt_t     max_t    norm_f  \\\n0      0.000438 -0.022042  0.019590 -0.979555  1.005862  0.010152  0.000454   \n1      0.129230 -0.326141  0.392308 -1.081040  1.010600  0.243330  0.121197   \n2      0.292590 -0.440137  0.632733 -1.060412  0.969647  0.409214  0.258202   \n3      0.001950 -3.374825  0.040920 -0.028003  0.005230  0.015670  0.002217   \n4      0.001950 -3.374825  0.040920 -0.028003  0.005230  0.015670  0.002217   \n...         ...       ...       ...       ...       ...       ...       ...   \n11611  0.852278 -1.320850  0.702879 -0.598063  0.870597  1.133930  1.048940   \n11612  0.388596 -1.050649  0.426651 -0.231337  0.277760  0.225217  0.518506   \n11613  0.400514 -1.065550  0.433902 -0.230251  0.277691  0.228783  0.533988   \n11614  0.533584 -1.201280  0.520200 -0.247300  0.284531  0.264447  0.698794   \n11615  0.616723 -1.283507  0.564131 -0.250917  0.285992  0.284458  0.804101   \n\n         mean_f     std_f    skew_f  ...  max_a5_db4   max_cd1_db4  \\\n0      0.016955  0.021353  1.036937  ...    0.000105  2.274616e-08   \n1      0.323990  0.348179  0.941886  ...    0.059927  5.211159e-07   \n2      0.512369  0.507552  0.901947  ...    0.169775  1.610872e-06   \n3      0.016758  0.110095  5.090591  ...    0.043128  5.107586e-04   \n4      0.016758  0.110095  5.090591  ...    0.043128  5.107586e-04   \n...         ...       ...       ...  ...         ...           ...   \n11611  0.485097  1.033184  1.215652  ...    1.314887  7.049712e-01   \n11612  0.177879  0.751787  1.456125  ...    0.590762  1.713605e-07   \n11613  0.178701  0.762976  1.455101  ...    0.609823  1.774937e-07   \n11614  0.234556  0.872186  1.429447  ...    0.815078  2.339514e-03   \n11615  0.208034  0.936902  1.422121  ...    0.942315  2.747484e-07   \n\n        max_cd2_db4   max_cd3_db4  max_cd4_db4  max_cd5_db4  locLabel  \\\n0      8.531768e-07  4.657510e-07     0.000001     0.000007         1   \n1      1.146017e-04  1.097209e-04     0.000280     0.000216         1   \n2      3.983491e-04  3.796074e-04     0.001021     0.000791         1   \n3      9.973887e-05  6.676336e-05     0.000894     0.001020         1   \n4      9.973887e-05  6.676336e-05     0.000894     0.001020         1   \n...             ...           ...          ...          ...       ...   \n11611  7.305406e-02  1.133269e+01     1.057026     9.706355         4   \n11612  2.735332e-05  1.153053e-04     0.001300     0.005047         4   \n11613  3.015753e-05  1.266783e-04     0.001439     0.005262         4   \n11614  3.537845e-03  2.185118e-02     0.062731     0.174924         4   \n11615  2.912272e-04  9.971033e-04     0.017188     0.016585         4   \n\n       measloc  resistance  faultLabel  \n0            1      0.0010        ABCG  \n1            1      0.0273        ABCG  \n2            1      0.0535        ABCG  \n3            2      0.0010        ABCG  \n4            2      0.0273        ABCG  \n...        ...         ...         ...  \n11611        3      2.0000          CG  \n11612        4      0.4737          CG  \n11613        4      0.5000          CG  \n11614        4      1.0000          CG  \n11615        4      2.0000          CG  \n\n[11616 rows x 52 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>norm_t</th>\n      <th>mean_t</th>\n      <th>std_t</th>\n      <th>skew_t</th>\n      <th>kurt_t</th>\n      <th>max_t</th>\n      <th>norm_f</th>\n      <th>mean_f</th>\n      <th>std_f</th>\n      <th>skew_f</th>\n      <th>...</th>\n      <th>max_a5_db4</th>\n      <th>max_cd1_db4</th>\n      <th>max_cd2_db4</th>\n      <th>max_cd3_db4</th>\n      <th>max_cd4_db4</th>\n      <th>max_cd5_db4</th>\n      <th>locLabel</th>\n      <th>measloc</th>\n      <th>resistance</th>\n      <th>faultLabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000438</td>\n      <td>-0.022042</td>\n      <td>0.019590</td>\n      <td>-0.979555</td>\n      <td>1.005862</td>\n      <td>0.010152</td>\n      <td>0.000454</td>\n      <td>0.016955</td>\n      <td>0.021353</td>\n      <td>1.036937</td>\n      <td>...</td>\n      <td>0.000105</td>\n      <td>2.274616e-08</td>\n      <td>8.531768e-07</td>\n      <td>4.657510e-07</td>\n      <td>0.000001</td>\n      <td>0.000007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0010</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.129230</td>\n      <td>-0.326141</td>\n      <td>0.392308</td>\n      <td>-1.081040</td>\n      <td>1.010600</td>\n      <td>0.243330</td>\n      <td>0.121197</td>\n      <td>0.323990</td>\n      <td>0.348179</td>\n      <td>0.941886</td>\n      <td>...</td>\n      <td>0.059927</td>\n      <td>5.211159e-07</td>\n      <td>1.146017e-04</td>\n      <td>1.097209e-04</td>\n      <td>0.000280</td>\n      <td>0.000216</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0273</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.292590</td>\n      <td>-0.440137</td>\n      <td>0.632733</td>\n      <td>-1.060412</td>\n      <td>0.969647</td>\n      <td>0.409214</td>\n      <td>0.258202</td>\n      <td>0.512369</td>\n      <td>0.507552</td>\n      <td>0.901947</td>\n      <td>...</td>\n      <td>0.169775</td>\n      <td>1.610872e-06</td>\n      <td>3.983491e-04</td>\n      <td>3.796074e-04</td>\n      <td>0.001021</td>\n      <td>0.000791</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0535</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001950</td>\n      <td>-3.374825</td>\n      <td>0.040920</td>\n      <td>-0.028003</td>\n      <td>0.005230</td>\n      <td>0.015670</td>\n      <td>0.002217</td>\n      <td>0.016758</td>\n      <td>0.110095</td>\n      <td>5.090591</td>\n      <td>...</td>\n      <td>0.043128</td>\n      <td>5.107586e-04</td>\n      <td>9.973887e-05</td>\n      <td>6.676336e-05</td>\n      <td>0.000894</td>\n      <td>0.001020</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0010</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001950</td>\n      <td>-3.374825</td>\n      <td>0.040920</td>\n      <td>-0.028003</td>\n      <td>0.005230</td>\n      <td>0.015670</td>\n      <td>0.002217</td>\n      <td>0.016758</td>\n      <td>0.110095</td>\n      <td>5.090591</td>\n      <td>...</td>\n      <td>0.043128</td>\n      <td>5.107586e-04</td>\n      <td>9.973887e-05</td>\n      <td>6.676336e-05</td>\n      <td>0.000894</td>\n      <td>0.001020</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0273</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11611</th>\n      <td>0.852278</td>\n      <td>-1.320850</td>\n      <td>0.702879</td>\n      <td>-0.598063</td>\n      <td>0.870597</td>\n      <td>1.133930</td>\n      <td>1.048940</td>\n      <td>0.485097</td>\n      <td>1.033184</td>\n      <td>1.215652</td>\n      <td>...</td>\n      <td>1.314887</td>\n      <td>7.049712e-01</td>\n      <td>7.305406e-02</td>\n      <td>1.133269e+01</td>\n      <td>1.057026</td>\n      <td>9.706355</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.0000</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11612</th>\n      <td>0.388596</td>\n      <td>-1.050649</td>\n      <td>0.426651</td>\n      <td>-0.231337</td>\n      <td>0.277760</td>\n      <td>0.225217</td>\n      <td>0.518506</td>\n      <td>0.177879</td>\n      <td>0.751787</td>\n      <td>1.456125</td>\n      <td>...</td>\n      <td>0.590762</td>\n      <td>1.713605e-07</td>\n      <td>2.735332e-05</td>\n      <td>1.153053e-04</td>\n      <td>0.001300</td>\n      <td>0.005047</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.4737</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11613</th>\n      <td>0.400514</td>\n      <td>-1.065550</td>\n      <td>0.433902</td>\n      <td>-0.230251</td>\n      <td>0.277691</td>\n      <td>0.228783</td>\n      <td>0.533988</td>\n      <td>0.178701</td>\n      <td>0.762976</td>\n      <td>1.455101</td>\n      <td>...</td>\n      <td>0.609823</td>\n      <td>1.774937e-07</td>\n      <td>3.015753e-05</td>\n      <td>1.266783e-04</td>\n      <td>0.001439</td>\n      <td>0.005262</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.5000</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11614</th>\n      <td>0.533584</td>\n      <td>-1.201280</td>\n      <td>0.520200</td>\n      <td>-0.247300</td>\n      <td>0.284531</td>\n      <td>0.264447</td>\n      <td>0.698794</td>\n      <td>0.234556</td>\n      <td>0.872186</td>\n      <td>1.429447</td>\n      <td>...</td>\n      <td>0.815078</td>\n      <td>2.339514e-03</td>\n      <td>3.537845e-03</td>\n      <td>2.185118e-02</td>\n      <td>0.062731</td>\n      <td>0.174924</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.0000</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11615</th>\n      <td>0.616723</td>\n      <td>-1.283507</td>\n      <td>0.564131</td>\n      <td>-0.250917</td>\n      <td>0.285992</td>\n      <td>0.284458</td>\n      <td>0.804101</td>\n      <td>0.208034</td>\n      <td>0.936902</td>\n      <td>1.422121</td>\n      <td>...</td>\n      <td>0.942315</td>\n      <td>2.747484e-07</td>\n      <td>2.912272e-04</td>\n      <td>9.971033e-04</td>\n      <td>0.017188</td>\n      <td>0.016585</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2.0000</td>\n      <td>CG</td>\n    </tr>\n  </tbody>\n</table>\n<p>11616 rows × 52 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('new_data.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:12.983511Z",
          "iopub.execute_input": "2024-02-06T14:39:12.983775Z",
          "iopub.status.idle": "2024-02-06T14:39:13.584829Z",
          "shell.execute_reply.started": "2024-02-06T14:39:12.983748Z",
          "shell.execute_reply": "2024-02-06T14:39:13.583854Z"
        },
        "trusted": true,
        "id": "pxxI8nQJXcmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of the dataset\n",
        "datasetPath = '/content/drive/MyDrive/Dataset.csv'\n",
        "\n",
        "# Path of the model (saved/to save)\n",
        "modelPath = '/content/new-RNN (3).pth'\n",
        "\n",
        "# When True, retrain the whole model\n",
        "retrain = False\n",
        "\n",
        "# Size of the split\n",
        "trainSize = 0.85\n",
        "valSize = 0.05\n",
        "testSize = 0.1\n",
        "\n",
        "# Specify number of seconds for the window. Default: 16\n",
        "window_size = 16\n",
        "\n",
        "# Model hyper-parameters\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 80\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# When True create graphs (takes more time)\n",
        "makeGraphs = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:13.586569Z",
          "iopub.execute_input": "2024-02-06T14:39:13.586872Z",
          "iopub.status.idle": "2024-02-06T14:39:13.598217Z",
          "shell.execute_reply.started": "2024-02-06T14:39:13.586845Z",
          "shell.execute_reply": "2024-02-06T14:39:13.596465Z"
        },
        "trusted": true,
        "id": "vgaZp2G5XcmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_to_drop=['faultLabel']\n",
        "target_classes = final_df[['faultLabel']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:14.691269Z",
          "iopub.execute_input": "2024-02-06T14:39:14.691594Z",
          "iopub.status.idle": "2024-02-06T14:39:14.698306Z",
          "shell.execute_reply.started": "2024-02-06T14:39:14.691566Z",
          "shell.execute_reply": "2024-02-06T14:39:14.696940Z"
        },
        "trusted": true,
        "id": "Y5xf_AusXcmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_norm(self,col):\n",
        "    self._data[col]=(self._data[col]-self._data[col].min())/(self._data[col].max()-self._data[col].min())\n",
        "\n",
        "\n",
        "def std_scaler(self,col):\n",
        "    self._data[col]=(self._data[col]-self._data[col].mean())/(self._data[col].std())\n",
        "\n",
        "def f1(test_loader, model):\n",
        "    f1 = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, labels) in enumerate(test_loader):\n",
        "            outputs = model(data)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            f1 += f1_score(labels, pred, average='macro')\n",
        "    avg_f1 = f1/len(test_loader)\n",
        "    return (avg_f1)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path='/kaggle/working/new_data.csv', classes_to_drop=classes_to_drop, window_size=window_size, normalize=True, normalize_method='mean_std'):\n",
        "\n",
        "\n",
        "        self._window_size=window_size\n",
        "        self._data=pd.read_csv(file_path)\n",
        "\n",
        "        # The data is sorted by Class A,B,C the indexes of the dataframe have restarted by ignore index\n",
        "        self._data = self._data.sort_values(by=['faultLabel'], inplace=False,ignore_index = True)\n",
        "\n",
        "        # class_uniq contains the letters of the drivers A,B and it loops across all of them\n",
        "        for class_uniq in list(self._data['faultLabel'].unique()):\n",
        "            # Find the total number of elements belonging to a class\n",
        "            tot_number=sum(self._data['faultLabel']==class_uniq)\n",
        "            # Number of elements to drop so that the class element is divisible by window size\n",
        "            to_drop=tot_number%window_size\n",
        "            # Returns the index of the first element of the class\n",
        "            index_to_start_removing=self._data[self._data['faultLabel']==class_uniq].index[0]\n",
        "            # Drop element from first element to the element required\n",
        "            self._data.drop(self._data.index[index_to_start_removing:index_to_start_removing+to_drop],inplace=True)\n",
        "\n",
        "\n",
        "        # Resetting index of dataframe after dropping values\n",
        "        self._data = self._data.reset_index()\n",
        "        self._data = self._data.drop(['index'], axis=1)\n",
        "\n",
        "        index_starting_class=[] # This array contains the starting index of each class in the df\n",
        "        for class_uniq in list(self._data['faultLabel'].unique()):\n",
        "            # Appending the index of first element of each clas\n",
        "            index_starting_class.append(self._data[self._data['faultLabel']==class_uniq].index[0])\n",
        "\n",
        "        # Create the sequence of indexs of the windows\n",
        "        sequences=[]\n",
        "        for i in range(len(index_starting_class)):\n",
        "            # Check if beginning of next class is there\n",
        "            if i!=len(index_starting_class)-1:\n",
        "                ranges=np.arange(index_starting_class[i], index_starting_class[i+1])\n",
        "            else:\n",
        "                ranges = np.arange(index_starting_class[i], len(self._data))\n",
        "            for j in range(0,len(ranges),int(self._window_size/2)):\n",
        "                if len(ranges[j:j+self._window_size])==16:\n",
        "                    sequences.append(ranges[j:j+self._window_size])\n",
        "        self._sequences=sequences\n",
        "\n",
        "\n",
        "        # Take only the 'Class' which are the actual labels and store it in the labels of self\n",
        "        self._labels=self._data['faultLabel']\n",
        "        # Dropping columns which have constant measurements because they would return nan in std\n",
        "        self._data.drop(classes_to_drop, inplace=True, axis=1)\n",
        "\n",
        "        # Function to normalize the data either with min_max or mean_std\n",
        "        if normalize:\n",
        "            for col in self._data.columns:\n",
        "                if normalize_method=='min_max':\n",
        "                    min_max_norm(self,col)\n",
        "                elif normalize_method==\"mean_std\":\n",
        "                    std_scaler(self,col)\n",
        "\n",
        "        # Create the array holding the windowed multidimensional arrays\n",
        "        X=np.empty((len(sequences), self._window_size, len(self._data.columns)))\n",
        "        y=[]\n",
        "\n",
        "        for n_row, sequence in enumerate(sequences):\n",
        "            X[n_row,:,:]=self._data.iloc[sequence]\n",
        "            # The corresponding driver of the sequence is the driver at first sequence\n",
        "            y.append(self._labels[sequence[0]])\n",
        "\n",
        "\n",
        "        assert len(y)==len(X)\n",
        "        #Assing the windowed dataset to the X of self\n",
        "        self._X= X\n",
        "\n",
        "        # Targets is a transformed version of y with drivers are encoded into 0 to 9\n",
        "        targets = preprocessing.LabelEncoder().fit_transform(y)\n",
        "        targets = torch.as_tensor(targets)  # Just converting it to a pytorch tensor\n",
        "        self._y=targets # Assign it to y of self\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._X)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.FloatTensor(self._X[index,:,:]), self._y[index]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:17.666844Z",
          "iopub.execute_input": "2024-02-06T14:39:17.667151Z",
          "iopub.status.idle": "2024-02-06T14:39:17.684219Z",
          "shell.execute_reply.started": "2024-02-06T14:39:17.667126Z",
          "shell.execute_reply": "2024-02-06T14:39:17.683181Z"
        },
        "trusted": true,
        "id": "_9qgcJIIXcmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:20.537657Z",
          "iopub.execute_input": "2024-02-06T14:39:20.538183Z",
          "iopub.status.idle": "2024-02-06T14:39:20.543785Z",
          "shell.execute_reply.started": "2024-02-06T14:39:20.538151Z",
          "shell.execute_reply": "2024-02-06T14:39:20.542958Z"
        },
        "trusted": true,
        "id": "hv9dSP2VXcmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = CustomDataset()\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "val_size = int(valSize * len(a))\n",
        "test_size = len(a)-train_size-val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                                batch_size=4,\n",
        "                                                shuffle=False,\n",
        "                                                drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False,drop_last=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:22.104190Z",
          "iopub.execute_input": "2024-02-06T14:39:22.104609Z",
          "iopub.status.idle": "2024-02-06T14:39:23.414945Z",
          "shell.execute_reply.started": "2024-02-06T14:39:22.104576Z",
          "shell.execute_reply": "2024-02-06T14:39:23.414212Z"
        },
        "trusted": true,
        "id": "OISLmulqXcmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.drop(classes_to_drop,inplace=True, axis=1)\n",
        "final_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "k8VJPNn0XcmN",
        "outputId": "54f8f869-da11-45f4-eb36-087e7ab70ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         norm_t    mean_t     std_t    skew_t    kurt_t     max_t    norm_f  \\\n0      0.000438 -0.022042  0.019590 -0.979555  1.005862  0.010152  0.000454   \n1      0.129230 -0.326141  0.392308 -1.081040  1.010600  0.243330  0.121197   \n2      0.292590 -0.440137  0.632733 -1.060412  0.969647  0.409214  0.258202   \n3      0.001950 -3.374825  0.040920 -0.028003  0.005230  0.015670  0.002217   \n4      0.001950 -3.374825  0.040920 -0.028003  0.005230  0.015670  0.002217   \n...         ...       ...       ...       ...       ...       ...       ...   \n11611  0.852278 -1.320850  0.702879 -0.598063  0.870597  1.133930  1.048940   \n11612  0.388596 -1.050649  0.426651 -0.231337  0.277760  0.225217  0.518506   \n11613  0.400514 -1.065550  0.433902 -0.230251  0.277691  0.228783  0.533988   \n11614  0.533584 -1.201280  0.520200 -0.247300  0.284531  0.264447  0.698794   \n11615  0.616723 -1.283507  0.564131 -0.250917  0.285992  0.284458  0.804101   \n\n         mean_f     std_f    skew_f  ...  kurt_cd5_db4  max_a5_db4  \\\n0      0.016955  0.021353  1.036937  ...      0.063524    0.000105   \n1      0.323990  0.348179  0.941886  ...      1.389964    0.059927   \n2      0.512369  0.507552  0.901947  ...      2.120875    0.169775   \n3      0.016758  0.110095  5.090591  ...      0.249919    0.043128   \n4      0.016758  0.110095  5.090591  ...      0.249919    0.043128   \n...         ...       ...       ...  ...           ...         ...   \n11611  0.485097  1.033184  1.215652  ...      1.266173    1.314887   \n11612  0.177879  0.751787  1.456125  ...      0.791403    0.590762   \n11613  0.178701  0.762976  1.455101  ...      0.791062    0.609823   \n11614  0.234556  0.872186  1.429447  ...      1.208636    0.815078   \n11615  0.208034  0.936902  1.422121  ...      1.502077    0.942315   \n\n        max_cd1_db4   max_cd2_db4   max_cd3_db4  max_cd4_db4  max_cd5_db4  \\\n0      2.274616e-08  8.531768e-07  4.657510e-07     0.000001     0.000007   \n1      5.211159e-07  1.146017e-04  1.097209e-04     0.000280     0.000216   \n2      1.610872e-06  3.983491e-04  3.796074e-04     0.001021     0.000791   \n3      5.107586e-04  9.973887e-05  6.676336e-05     0.000894     0.001020   \n4      5.107586e-04  9.973887e-05  6.676336e-05     0.000894     0.001020   \n...             ...           ...           ...          ...          ...   \n11611  7.049712e-01  7.305406e-02  1.133269e+01     1.057026     9.706355   \n11612  1.713605e-07  2.735332e-05  1.153053e-04     0.001300     0.005047   \n11613  1.774937e-07  3.015753e-05  1.266783e-04     0.001439     0.005262   \n11614  2.339514e-03  3.537845e-03  2.185118e-02     0.062731     0.174924   \n11615  2.747484e-07  2.912272e-04  9.971033e-04     0.017188     0.016585   \n\n       locLabel  measloc  resistance  \n0             1        1      0.0010  \n1             1        1      0.0273  \n2             1        1      0.0535  \n3             1        2      0.0010  \n4             1        2      0.0273  \n...         ...      ...         ...  \n11611         4        3      2.0000  \n11612         4        4      0.4737  \n11613         4        4      0.5000  \n11614         4        4      1.0000  \n11615         4        4      2.0000  \n\n[11616 rows x 51 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>norm_t</th>\n      <th>mean_t</th>\n      <th>std_t</th>\n      <th>skew_t</th>\n      <th>kurt_t</th>\n      <th>max_t</th>\n      <th>norm_f</th>\n      <th>mean_f</th>\n      <th>std_f</th>\n      <th>skew_f</th>\n      <th>...</th>\n      <th>kurt_cd5_db4</th>\n      <th>max_a5_db4</th>\n      <th>max_cd1_db4</th>\n      <th>max_cd2_db4</th>\n      <th>max_cd3_db4</th>\n      <th>max_cd4_db4</th>\n      <th>max_cd5_db4</th>\n      <th>locLabel</th>\n      <th>measloc</th>\n      <th>resistance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000438</td>\n      <td>-0.022042</td>\n      <td>0.019590</td>\n      <td>-0.979555</td>\n      <td>1.005862</td>\n      <td>0.010152</td>\n      <td>0.000454</td>\n      <td>0.016955</td>\n      <td>0.021353</td>\n      <td>1.036937</td>\n      <td>...</td>\n      <td>0.063524</td>\n      <td>0.000105</td>\n      <td>2.274616e-08</td>\n      <td>8.531768e-07</td>\n      <td>4.657510e-07</td>\n      <td>0.000001</td>\n      <td>0.000007</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.129230</td>\n      <td>-0.326141</td>\n      <td>0.392308</td>\n      <td>-1.081040</td>\n      <td>1.010600</td>\n      <td>0.243330</td>\n      <td>0.121197</td>\n      <td>0.323990</td>\n      <td>0.348179</td>\n      <td>0.941886</td>\n      <td>...</td>\n      <td>1.389964</td>\n      <td>0.059927</td>\n      <td>5.211159e-07</td>\n      <td>1.146017e-04</td>\n      <td>1.097209e-04</td>\n      <td>0.000280</td>\n      <td>0.000216</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0273</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.292590</td>\n      <td>-0.440137</td>\n      <td>0.632733</td>\n      <td>-1.060412</td>\n      <td>0.969647</td>\n      <td>0.409214</td>\n      <td>0.258202</td>\n      <td>0.512369</td>\n      <td>0.507552</td>\n      <td>0.901947</td>\n      <td>...</td>\n      <td>2.120875</td>\n      <td>0.169775</td>\n      <td>1.610872e-06</td>\n      <td>3.983491e-04</td>\n      <td>3.796074e-04</td>\n      <td>0.001021</td>\n      <td>0.000791</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0535</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001950</td>\n      <td>-3.374825</td>\n      <td>0.040920</td>\n      <td>-0.028003</td>\n      <td>0.005230</td>\n      <td>0.015670</td>\n      <td>0.002217</td>\n      <td>0.016758</td>\n      <td>0.110095</td>\n      <td>5.090591</td>\n      <td>...</td>\n      <td>0.249919</td>\n      <td>0.043128</td>\n      <td>5.107586e-04</td>\n      <td>9.973887e-05</td>\n      <td>6.676336e-05</td>\n      <td>0.000894</td>\n      <td>0.001020</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.001950</td>\n      <td>-3.374825</td>\n      <td>0.040920</td>\n      <td>-0.028003</td>\n      <td>0.005230</td>\n      <td>0.015670</td>\n      <td>0.002217</td>\n      <td>0.016758</td>\n      <td>0.110095</td>\n      <td>5.090591</td>\n      <td>...</td>\n      <td>0.249919</td>\n      <td>0.043128</td>\n      <td>5.107586e-04</td>\n      <td>9.973887e-05</td>\n      <td>6.676336e-05</td>\n      <td>0.000894</td>\n      <td>0.001020</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0273</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11611</th>\n      <td>0.852278</td>\n      <td>-1.320850</td>\n      <td>0.702879</td>\n      <td>-0.598063</td>\n      <td>0.870597</td>\n      <td>1.133930</td>\n      <td>1.048940</td>\n      <td>0.485097</td>\n      <td>1.033184</td>\n      <td>1.215652</td>\n      <td>...</td>\n      <td>1.266173</td>\n      <td>1.314887</td>\n      <td>7.049712e-01</td>\n      <td>7.305406e-02</td>\n      <td>1.133269e+01</td>\n      <td>1.057026</td>\n      <td>9.706355</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.0000</td>\n    </tr>\n    <tr>\n      <th>11612</th>\n      <td>0.388596</td>\n      <td>-1.050649</td>\n      <td>0.426651</td>\n      <td>-0.231337</td>\n      <td>0.277760</td>\n      <td>0.225217</td>\n      <td>0.518506</td>\n      <td>0.177879</td>\n      <td>0.751787</td>\n      <td>1.456125</td>\n      <td>...</td>\n      <td>0.791403</td>\n      <td>0.590762</td>\n      <td>1.713605e-07</td>\n      <td>2.735332e-05</td>\n      <td>1.153053e-04</td>\n      <td>0.001300</td>\n      <td>0.005047</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.4737</td>\n    </tr>\n    <tr>\n      <th>11613</th>\n      <td>0.400514</td>\n      <td>-1.065550</td>\n      <td>0.433902</td>\n      <td>-0.230251</td>\n      <td>0.277691</td>\n      <td>0.228783</td>\n      <td>0.533988</td>\n      <td>0.178701</td>\n      <td>0.762976</td>\n      <td>1.455101</td>\n      <td>...</td>\n      <td>0.791062</td>\n      <td>0.609823</td>\n      <td>1.774937e-07</td>\n      <td>3.015753e-05</td>\n      <td>1.266783e-04</td>\n      <td>0.001439</td>\n      <td>0.005262</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0.5000</td>\n    </tr>\n    <tr>\n      <th>11614</th>\n      <td>0.533584</td>\n      <td>-1.201280</td>\n      <td>0.520200</td>\n      <td>-0.247300</td>\n      <td>0.284531</td>\n      <td>0.264447</td>\n      <td>0.698794</td>\n      <td>0.234556</td>\n      <td>0.872186</td>\n      <td>1.429447</td>\n      <td>...</td>\n      <td>1.208636</td>\n      <td>0.815078</td>\n      <td>2.339514e-03</td>\n      <td>3.537845e-03</td>\n      <td>2.185118e-02</td>\n      <td>0.062731</td>\n      <td>0.174924</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>11615</th>\n      <td>0.616723</td>\n      <td>-1.283507</td>\n      <td>0.564131</td>\n      <td>-0.250917</td>\n      <td>0.285992</td>\n      <td>0.284458</td>\n      <td>0.804101</td>\n      <td>0.208034</td>\n      <td>0.936902</td>\n      <td>1.422121</td>\n      <td>...</td>\n      <td>1.502077</td>\n      <td>0.942315</td>\n      <td>2.747484e-07</td>\n      <td>2.912272e-04</td>\n      <td>9.971033e-04</td>\n      <td>0.017188</td>\n      <td>0.016585</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>11616 rows × 51 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply the scaler to your DataFrame\n",
        "normalized_data = scaler.fit_transform(final_df)\n",
        "\n",
        "# Create a new DataFrame with the normalized data\n",
        "normalized_df = pd.DataFrame(normalized_data, columns=final_df.columns)\n",
        "\n",
        "normalized_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T14:39:28.512762Z",
          "iopub.execute_input": "2024-02-06T14:39:28.513138Z",
          "iopub.status.idle": "2024-02-06T14:39:28.546632Z",
          "shell.execute_reply.started": "2024-02-06T14:39:28.513103Z",
          "shell.execute_reply": "2024-02-06T14:39:28.545816Z"
        },
        "trusted": true,
        "id": "WPNsfR4UXcmN",
        "outputId": "95b39c80-f651-488c-a64e-7caa0ff8d0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         norm_t    mean_t     std_t    skew_t    kurt_t     max_t    norm_f  \\\n0     -1.499099 -0.214862 -1.474706 -0.605521  0.575383 -1.443264 -1.579096   \n1     -1.207467 -0.236463 -0.699680 -0.651058  0.581944 -0.885718 -1.289267   \n2     -0.837559 -0.244561 -0.199743 -0.641802  0.525222 -0.489077 -0.960404   \n3     -1.495677 -0.453022 -1.430352 -0.178555 -0.810541 -1.430070 -1.574863   \n4     -1.495677 -0.453022 -1.430352 -0.178555 -0.810541 -1.430070 -1.574863   \n...         ...       ...       ...       ...       ...       ...       ...   \n11611  0.429786 -0.307121 -0.053882 -0.434344  0.388033  1.243771  0.937667   \n11612 -0.620165 -0.287928 -0.628268 -0.269792 -0.433074 -0.929026 -0.335575   \n11613 -0.593179 -0.288986 -0.613189 -0.269305 -0.433169 -0.920501 -0.298412   \n11614 -0.291858 -0.298627 -0.433742 -0.276955 -0.423696 -0.835224  0.097185   \n11615 -0.103601 -0.304468 -0.342394 -0.278578 -0.421673 -0.787378  0.349960   \n\n         mean_f     std_f    skew_f  ...  kurt_cd5_db4  max_a5_db4  \\\n0     -1.154587 -2.060222 -0.555180  ...     -0.751612   -1.807947   \n1     -0.523576 -1.130579 -0.603731  ...     -0.108658   -1.668402   \n2     -0.136424 -0.677251 -0.624132  ...      0.245631   -1.412161   \n3     -1.154991 -1.807799  1.515406  ...     -0.661262   -1.707587   \n4     -1.154991 -1.807799  1.515406  ...     -0.661262   -1.707587   \n...         ...       ...       ...  ...           ...         ...   \n11611 -0.192473  0.817886 -0.463893  ...     -0.168662    1.259013   \n11612 -0.823860  0.017467 -0.341061  ...     -0.398793   -0.430136   \n11613 -0.822171  0.049293 -0.341583  ...     -0.398958   -0.385671   \n11614 -0.707379  0.359935 -0.354688  ...     -0.196551    0.093121   \n11615 -0.761885  0.544018 -0.358430  ...     -0.054313    0.389924   \n\n       max_cd1_db4  max_cd2_db4  max_cd3_db4  max_cd4_db4  max_cd5_db4  \\\n0        -0.330024    -0.130069    -0.301886    -0.310909    -0.181465   \n1        -0.330024    -0.129542    -0.301853    -0.310805    -0.181450   \n2        -0.330023    -0.128225    -0.301772    -0.310531    -0.181409   \n3        -0.329553    -0.129610    -0.301866    -0.310578    -0.181393   \n4        -0.329553    -0.129610    -0.301866    -0.310578    -0.181393   \n...            ...          ...          ...          ...          ...   \n11611     0.321058     0.208807     3.108528     0.080328     0.505005   \n11612    -0.330024    -0.129946    -0.301852    -0.310428    -0.181108   \n11613    -0.330024    -0.129933    -0.301848    -0.310377    -0.181093   \n11614    -0.327864    -0.113662    -0.295311    -0.287691    -0.169094   \n11615    -0.330024    -0.128722    -0.301586    -0.304547    -0.180292   \n\n       locLabel   measloc  resistance  \n0     -1.341641 -1.341641   -0.873957  \n1     -1.341641 -1.341641   -0.810653  \n2     -1.341641 -1.341641   -0.747590  \n3     -1.341641 -0.447214   -0.873957  \n4     -1.341641 -0.447214   -0.810653  \n...         ...       ...         ...  \n11611  1.341641  0.447214    3.937620  \n11612  1.341641  1.341641    0.263828  \n11613  1.341641  1.341641    0.327132  \n11614  1.341641  1.341641    1.530628  \n11615  1.341641  1.341641    3.937620  \n\n[11616 rows x 51 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>norm_t</th>\n      <th>mean_t</th>\n      <th>std_t</th>\n      <th>skew_t</th>\n      <th>kurt_t</th>\n      <th>max_t</th>\n      <th>norm_f</th>\n      <th>mean_f</th>\n      <th>std_f</th>\n      <th>skew_f</th>\n      <th>...</th>\n      <th>kurt_cd5_db4</th>\n      <th>max_a5_db4</th>\n      <th>max_cd1_db4</th>\n      <th>max_cd2_db4</th>\n      <th>max_cd3_db4</th>\n      <th>max_cd4_db4</th>\n      <th>max_cd5_db4</th>\n      <th>locLabel</th>\n      <th>measloc</th>\n      <th>resistance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.499099</td>\n      <td>-0.214862</td>\n      <td>-1.474706</td>\n      <td>-0.605521</td>\n      <td>0.575383</td>\n      <td>-1.443264</td>\n      <td>-1.579096</td>\n      <td>-1.154587</td>\n      <td>-2.060222</td>\n      <td>-0.555180</td>\n      <td>...</td>\n      <td>-0.751612</td>\n      <td>-1.807947</td>\n      <td>-0.330024</td>\n      <td>-0.130069</td>\n      <td>-0.301886</td>\n      <td>-0.310909</td>\n      <td>-0.181465</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.873957</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.207467</td>\n      <td>-0.236463</td>\n      <td>-0.699680</td>\n      <td>-0.651058</td>\n      <td>0.581944</td>\n      <td>-0.885718</td>\n      <td>-1.289267</td>\n      <td>-0.523576</td>\n      <td>-1.130579</td>\n      <td>-0.603731</td>\n      <td>...</td>\n      <td>-0.108658</td>\n      <td>-1.668402</td>\n      <td>-0.330024</td>\n      <td>-0.129542</td>\n      <td>-0.301853</td>\n      <td>-0.310805</td>\n      <td>-0.181450</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.810653</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.837559</td>\n      <td>-0.244561</td>\n      <td>-0.199743</td>\n      <td>-0.641802</td>\n      <td>0.525222</td>\n      <td>-0.489077</td>\n      <td>-0.960404</td>\n      <td>-0.136424</td>\n      <td>-0.677251</td>\n      <td>-0.624132</td>\n      <td>...</td>\n      <td>0.245631</td>\n      <td>-1.412161</td>\n      <td>-0.330023</td>\n      <td>-0.128225</td>\n      <td>-0.301772</td>\n      <td>-0.310531</td>\n      <td>-0.181409</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.747590</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.495677</td>\n      <td>-0.453022</td>\n      <td>-1.430352</td>\n      <td>-0.178555</td>\n      <td>-0.810541</td>\n      <td>-1.430070</td>\n      <td>-1.574863</td>\n      <td>-1.154991</td>\n      <td>-1.807799</td>\n      <td>1.515406</td>\n      <td>...</td>\n      <td>-0.661262</td>\n      <td>-1.707587</td>\n      <td>-0.329553</td>\n      <td>-0.129610</td>\n      <td>-0.301866</td>\n      <td>-0.310578</td>\n      <td>-0.181393</td>\n      <td>-1.341641</td>\n      <td>-0.447214</td>\n      <td>-0.873957</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.495677</td>\n      <td>-0.453022</td>\n      <td>-1.430352</td>\n      <td>-0.178555</td>\n      <td>-0.810541</td>\n      <td>-1.430070</td>\n      <td>-1.574863</td>\n      <td>-1.154991</td>\n      <td>-1.807799</td>\n      <td>1.515406</td>\n      <td>...</td>\n      <td>-0.661262</td>\n      <td>-1.707587</td>\n      <td>-0.329553</td>\n      <td>-0.129610</td>\n      <td>-0.301866</td>\n      <td>-0.310578</td>\n      <td>-0.181393</td>\n      <td>-1.341641</td>\n      <td>-0.447214</td>\n      <td>-0.810653</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11611</th>\n      <td>0.429786</td>\n      <td>-0.307121</td>\n      <td>-0.053882</td>\n      <td>-0.434344</td>\n      <td>0.388033</td>\n      <td>1.243771</td>\n      <td>0.937667</td>\n      <td>-0.192473</td>\n      <td>0.817886</td>\n      <td>-0.463893</td>\n      <td>...</td>\n      <td>-0.168662</td>\n      <td>1.259013</td>\n      <td>0.321058</td>\n      <td>0.208807</td>\n      <td>3.108528</td>\n      <td>0.080328</td>\n      <td>0.505005</td>\n      <td>1.341641</td>\n      <td>0.447214</td>\n      <td>3.937620</td>\n    </tr>\n    <tr>\n      <th>11612</th>\n      <td>-0.620165</td>\n      <td>-0.287928</td>\n      <td>-0.628268</td>\n      <td>-0.269792</td>\n      <td>-0.433074</td>\n      <td>-0.929026</td>\n      <td>-0.335575</td>\n      <td>-0.823860</td>\n      <td>0.017467</td>\n      <td>-0.341061</td>\n      <td>...</td>\n      <td>-0.398793</td>\n      <td>-0.430136</td>\n      <td>-0.330024</td>\n      <td>-0.129946</td>\n      <td>-0.301852</td>\n      <td>-0.310428</td>\n      <td>-0.181108</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>0.263828</td>\n    </tr>\n    <tr>\n      <th>11613</th>\n      <td>-0.593179</td>\n      <td>-0.288986</td>\n      <td>-0.613189</td>\n      <td>-0.269305</td>\n      <td>-0.433169</td>\n      <td>-0.920501</td>\n      <td>-0.298412</td>\n      <td>-0.822171</td>\n      <td>0.049293</td>\n      <td>-0.341583</td>\n      <td>...</td>\n      <td>-0.398958</td>\n      <td>-0.385671</td>\n      <td>-0.330024</td>\n      <td>-0.129933</td>\n      <td>-0.301848</td>\n      <td>-0.310377</td>\n      <td>-0.181093</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>0.327132</td>\n    </tr>\n    <tr>\n      <th>11614</th>\n      <td>-0.291858</td>\n      <td>-0.298627</td>\n      <td>-0.433742</td>\n      <td>-0.276955</td>\n      <td>-0.423696</td>\n      <td>-0.835224</td>\n      <td>0.097185</td>\n      <td>-0.707379</td>\n      <td>0.359935</td>\n      <td>-0.354688</td>\n      <td>...</td>\n      <td>-0.196551</td>\n      <td>0.093121</td>\n      <td>-0.327864</td>\n      <td>-0.113662</td>\n      <td>-0.295311</td>\n      <td>-0.287691</td>\n      <td>-0.169094</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>1.530628</td>\n    </tr>\n    <tr>\n      <th>11615</th>\n      <td>-0.103601</td>\n      <td>-0.304468</td>\n      <td>-0.342394</td>\n      <td>-0.278578</td>\n      <td>-0.421673</td>\n      <td>-0.787378</td>\n      <td>0.349960</td>\n      <td>-0.761885</td>\n      <td>0.544018</td>\n      <td>-0.358430</td>\n      <td>...</td>\n      <td>-0.054313</td>\n      <td>0.389924</td>\n      <td>-0.330024</td>\n      <td>-0.128722</td>\n      <td>-0.301586</td>\n      <td>-0.304547</td>\n      <td>-0.180292</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>3.937620</td>\n    </tr>\n  </tbody>\n</table>\n<p>11616 rows × 51 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.concat([normalized_df, target_classes], axis=1)\n",
        "result_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "rz4CkCWZXcmN",
        "outputId": "881f2efd-f793-4e3f-c0b2-17c382e3b929"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         norm_t    mean_t     std_t    skew_t    kurt_t     max_t    norm_f  \\\n0     -1.499099 -0.214862 -1.474706 -0.605521  0.575383 -1.443264 -1.579096   \n1     -1.207467 -0.236463 -0.699680 -0.651058  0.581944 -0.885718 -1.289267   \n2     -0.837559 -0.244561 -0.199743 -0.641802  0.525222 -0.489077 -0.960404   \n3     -1.495677 -0.453022 -1.430352 -0.178555 -0.810541 -1.430070 -1.574863   \n4     -1.495677 -0.453022 -1.430352 -0.178555 -0.810541 -1.430070 -1.574863   \n...         ...       ...       ...       ...       ...       ...       ...   \n11611  0.429786 -0.307121 -0.053882 -0.434344  0.388033  1.243771  0.937667   \n11612 -0.620165 -0.287928 -0.628268 -0.269792 -0.433074 -0.929026 -0.335575   \n11613 -0.593179 -0.288986 -0.613189 -0.269305 -0.433169 -0.920501 -0.298412   \n11614 -0.291858 -0.298627 -0.433742 -0.276955 -0.423696 -0.835224  0.097185   \n11615 -0.103601 -0.304468 -0.342394 -0.278578 -0.421673 -0.787378  0.349960   \n\n         mean_f     std_f    skew_f  ...  max_a5_db4  max_cd1_db4  \\\n0     -1.154587 -2.060222 -0.555180  ...   -1.807947    -0.330024   \n1     -0.523576 -1.130579 -0.603731  ...   -1.668402    -0.330024   \n2     -0.136424 -0.677251 -0.624132  ...   -1.412161    -0.330023   \n3     -1.154991 -1.807799  1.515406  ...   -1.707587    -0.329553   \n4     -1.154991 -1.807799  1.515406  ...   -1.707587    -0.329553   \n...         ...       ...       ...  ...         ...          ...   \n11611 -0.192473  0.817886 -0.463893  ...    1.259013     0.321058   \n11612 -0.823860  0.017467 -0.341061  ...   -0.430136    -0.330024   \n11613 -0.822171  0.049293 -0.341583  ...   -0.385671    -0.330024   \n11614 -0.707379  0.359935 -0.354688  ...    0.093121    -0.327864   \n11615 -0.761885  0.544018 -0.358430  ...    0.389924    -0.330024   \n\n       max_cd2_db4  max_cd3_db4  max_cd4_db4  max_cd5_db4  locLabel   measloc  \\\n0        -0.130069    -0.301886    -0.310909    -0.181465 -1.341641 -1.341641   \n1        -0.129542    -0.301853    -0.310805    -0.181450 -1.341641 -1.341641   \n2        -0.128225    -0.301772    -0.310531    -0.181409 -1.341641 -1.341641   \n3        -0.129610    -0.301866    -0.310578    -0.181393 -1.341641 -0.447214   \n4        -0.129610    -0.301866    -0.310578    -0.181393 -1.341641 -0.447214   \n...            ...          ...          ...          ...       ...       ...   \n11611     0.208807     3.108528     0.080328     0.505005  1.341641  0.447214   \n11612    -0.129946    -0.301852    -0.310428    -0.181108  1.341641  1.341641   \n11613    -0.129933    -0.301848    -0.310377    -0.181093  1.341641  1.341641   \n11614    -0.113662    -0.295311    -0.287691    -0.169094  1.341641  1.341641   \n11615    -0.128722    -0.301586    -0.304547    -0.180292  1.341641  1.341641   \n\n       resistance  faultLabel  \n0       -0.873957        ABCG  \n1       -0.810653        ABCG  \n2       -0.747590        ABCG  \n3       -0.873957        ABCG  \n4       -0.810653        ABCG  \n...           ...         ...  \n11611    3.937620          CG  \n11612    0.263828          CG  \n11613    0.327132          CG  \n11614    1.530628          CG  \n11615    3.937620          CG  \n\n[11616 rows x 52 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>norm_t</th>\n      <th>mean_t</th>\n      <th>std_t</th>\n      <th>skew_t</th>\n      <th>kurt_t</th>\n      <th>max_t</th>\n      <th>norm_f</th>\n      <th>mean_f</th>\n      <th>std_f</th>\n      <th>skew_f</th>\n      <th>...</th>\n      <th>max_a5_db4</th>\n      <th>max_cd1_db4</th>\n      <th>max_cd2_db4</th>\n      <th>max_cd3_db4</th>\n      <th>max_cd4_db4</th>\n      <th>max_cd5_db4</th>\n      <th>locLabel</th>\n      <th>measloc</th>\n      <th>resistance</th>\n      <th>faultLabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.499099</td>\n      <td>-0.214862</td>\n      <td>-1.474706</td>\n      <td>-0.605521</td>\n      <td>0.575383</td>\n      <td>-1.443264</td>\n      <td>-1.579096</td>\n      <td>-1.154587</td>\n      <td>-2.060222</td>\n      <td>-0.555180</td>\n      <td>...</td>\n      <td>-1.807947</td>\n      <td>-0.330024</td>\n      <td>-0.130069</td>\n      <td>-0.301886</td>\n      <td>-0.310909</td>\n      <td>-0.181465</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.873957</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.207467</td>\n      <td>-0.236463</td>\n      <td>-0.699680</td>\n      <td>-0.651058</td>\n      <td>0.581944</td>\n      <td>-0.885718</td>\n      <td>-1.289267</td>\n      <td>-0.523576</td>\n      <td>-1.130579</td>\n      <td>-0.603731</td>\n      <td>...</td>\n      <td>-1.668402</td>\n      <td>-0.330024</td>\n      <td>-0.129542</td>\n      <td>-0.301853</td>\n      <td>-0.310805</td>\n      <td>-0.181450</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.810653</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.837559</td>\n      <td>-0.244561</td>\n      <td>-0.199743</td>\n      <td>-0.641802</td>\n      <td>0.525222</td>\n      <td>-0.489077</td>\n      <td>-0.960404</td>\n      <td>-0.136424</td>\n      <td>-0.677251</td>\n      <td>-0.624132</td>\n      <td>...</td>\n      <td>-1.412161</td>\n      <td>-0.330023</td>\n      <td>-0.128225</td>\n      <td>-0.301772</td>\n      <td>-0.310531</td>\n      <td>-0.181409</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.747590</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.495677</td>\n      <td>-0.453022</td>\n      <td>-1.430352</td>\n      <td>-0.178555</td>\n      <td>-0.810541</td>\n      <td>-1.430070</td>\n      <td>-1.574863</td>\n      <td>-1.154991</td>\n      <td>-1.807799</td>\n      <td>1.515406</td>\n      <td>...</td>\n      <td>-1.707587</td>\n      <td>-0.329553</td>\n      <td>-0.129610</td>\n      <td>-0.301866</td>\n      <td>-0.310578</td>\n      <td>-0.181393</td>\n      <td>-1.341641</td>\n      <td>-0.447214</td>\n      <td>-0.873957</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.495677</td>\n      <td>-0.453022</td>\n      <td>-1.430352</td>\n      <td>-0.178555</td>\n      <td>-0.810541</td>\n      <td>-1.430070</td>\n      <td>-1.574863</td>\n      <td>-1.154991</td>\n      <td>-1.807799</td>\n      <td>1.515406</td>\n      <td>...</td>\n      <td>-1.707587</td>\n      <td>-0.329553</td>\n      <td>-0.129610</td>\n      <td>-0.301866</td>\n      <td>-0.310578</td>\n      <td>-0.181393</td>\n      <td>-1.341641</td>\n      <td>-0.447214</td>\n      <td>-0.810653</td>\n      <td>ABCG</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11611</th>\n      <td>0.429786</td>\n      <td>-0.307121</td>\n      <td>-0.053882</td>\n      <td>-0.434344</td>\n      <td>0.388033</td>\n      <td>1.243771</td>\n      <td>0.937667</td>\n      <td>-0.192473</td>\n      <td>0.817886</td>\n      <td>-0.463893</td>\n      <td>...</td>\n      <td>1.259013</td>\n      <td>0.321058</td>\n      <td>0.208807</td>\n      <td>3.108528</td>\n      <td>0.080328</td>\n      <td>0.505005</td>\n      <td>1.341641</td>\n      <td>0.447214</td>\n      <td>3.937620</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11612</th>\n      <td>-0.620165</td>\n      <td>-0.287928</td>\n      <td>-0.628268</td>\n      <td>-0.269792</td>\n      <td>-0.433074</td>\n      <td>-0.929026</td>\n      <td>-0.335575</td>\n      <td>-0.823860</td>\n      <td>0.017467</td>\n      <td>-0.341061</td>\n      <td>...</td>\n      <td>-0.430136</td>\n      <td>-0.330024</td>\n      <td>-0.129946</td>\n      <td>-0.301852</td>\n      <td>-0.310428</td>\n      <td>-0.181108</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>0.263828</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11613</th>\n      <td>-0.593179</td>\n      <td>-0.288986</td>\n      <td>-0.613189</td>\n      <td>-0.269305</td>\n      <td>-0.433169</td>\n      <td>-0.920501</td>\n      <td>-0.298412</td>\n      <td>-0.822171</td>\n      <td>0.049293</td>\n      <td>-0.341583</td>\n      <td>...</td>\n      <td>-0.385671</td>\n      <td>-0.330024</td>\n      <td>-0.129933</td>\n      <td>-0.301848</td>\n      <td>-0.310377</td>\n      <td>-0.181093</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>0.327132</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11614</th>\n      <td>-0.291858</td>\n      <td>-0.298627</td>\n      <td>-0.433742</td>\n      <td>-0.276955</td>\n      <td>-0.423696</td>\n      <td>-0.835224</td>\n      <td>0.097185</td>\n      <td>-0.707379</td>\n      <td>0.359935</td>\n      <td>-0.354688</td>\n      <td>...</td>\n      <td>0.093121</td>\n      <td>-0.327864</td>\n      <td>-0.113662</td>\n      <td>-0.295311</td>\n      <td>-0.287691</td>\n      <td>-0.169094</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>1.530628</td>\n      <td>CG</td>\n    </tr>\n    <tr>\n      <th>11615</th>\n      <td>-0.103601</td>\n      <td>-0.304468</td>\n      <td>-0.342394</td>\n      <td>-0.278578</td>\n      <td>-0.421673</td>\n      <td>-0.787378</td>\n      <td>0.349960</td>\n      <td>-0.761885</td>\n      <td>0.544018</td>\n      <td>-0.358430</td>\n      <td>...</td>\n      <td>0.389924</td>\n      <td>-0.330024</td>\n      <td>-0.128722</td>\n      <td>-0.301586</td>\n      <td>-0.304547</td>\n      <td>-0.180292</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>3.937620</td>\n      <td>CG</td>\n    </tr>\n  </tbody>\n</table>\n<p>11616 rows × 52 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "result_df['faultLabel'] = encoder.fit_transform(result_df['faultLabel'])\n",
        "\n",
        "# Retrieve the mapping of numerical codes to original class labels\n",
        "class_labels = encoder.classes_\n",
        "\n",
        "# Display the mapping\n",
        "for code, label in enumerate(class_labels):\n",
        "    print(f'Code: {code} -> Label: {label}')\n",
        "result_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "eeytTwTZXcmN",
        "outputId": "3ff0a242-bdcc-4cf6-f382-81055503974b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Code: 0 -> Label: AB\nCode: 1 -> Label: ABC\nCode: 2 -> Label: ABCG\nCode: 3 -> Label: ABG\nCode: 4 -> Label: AC\nCode: 5 -> Label: ACG\nCode: 6 -> Label: AG\nCode: 7 -> Label: BC\nCode: 8 -> Label: BCG\nCode: 9 -> Label: BG\nCode: 10 -> Label: CG\n",
          "output_type": "stream"
        },
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         norm_t    mean_t     std_t    skew_t    kurt_t     max_t    norm_f  \\\n0     -1.499099 -0.214862 -1.474706 -0.605521  0.575383 -1.443264 -1.579096   \n1     -1.207467 -0.236463 -0.699680 -0.651058  0.581944 -0.885718 -1.289267   \n2     -0.837559 -0.244561 -0.199743 -0.641802  0.525222 -0.489077 -0.960404   \n3     -1.495677 -0.453022 -1.430352 -0.178555 -0.810541 -1.430070 -1.574863   \n4     -1.495677 -0.453022 -1.430352 -0.178555 -0.810541 -1.430070 -1.574863   \n...         ...       ...       ...       ...       ...       ...       ...   \n11611  0.429786 -0.307121 -0.053882 -0.434344  0.388033  1.243771  0.937667   \n11612 -0.620165 -0.287928 -0.628268 -0.269792 -0.433074 -0.929026 -0.335575   \n11613 -0.593179 -0.288986 -0.613189 -0.269305 -0.433169 -0.920501 -0.298412   \n11614 -0.291858 -0.298627 -0.433742 -0.276955 -0.423696 -0.835224  0.097185   \n11615 -0.103601 -0.304468 -0.342394 -0.278578 -0.421673 -0.787378  0.349960   \n\n         mean_f     std_f    skew_f  ...  max_a5_db4  max_cd1_db4  \\\n0     -1.154587 -2.060222 -0.555180  ...   -1.807947    -0.330024   \n1     -0.523576 -1.130579 -0.603731  ...   -1.668402    -0.330024   \n2     -0.136424 -0.677251 -0.624132  ...   -1.412161    -0.330023   \n3     -1.154991 -1.807799  1.515406  ...   -1.707587    -0.329553   \n4     -1.154991 -1.807799  1.515406  ...   -1.707587    -0.329553   \n...         ...       ...       ...  ...         ...          ...   \n11611 -0.192473  0.817886 -0.463893  ...    1.259013     0.321058   \n11612 -0.823860  0.017467 -0.341061  ...   -0.430136    -0.330024   \n11613 -0.822171  0.049293 -0.341583  ...   -0.385671    -0.330024   \n11614 -0.707379  0.359935 -0.354688  ...    0.093121    -0.327864   \n11615 -0.761885  0.544018 -0.358430  ...    0.389924    -0.330024   \n\n       max_cd2_db4  max_cd3_db4  max_cd4_db4  max_cd5_db4  locLabel   measloc  \\\n0        -0.130069    -0.301886    -0.310909    -0.181465 -1.341641 -1.341641   \n1        -0.129542    -0.301853    -0.310805    -0.181450 -1.341641 -1.341641   \n2        -0.128225    -0.301772    -0.310531    -0.181409 -1.341641 -1.341641   \n3        -0.129610    -0.301866    -0.310578    -0.181393 -1.341641 -0.447214   \n4        -0.129610    -0.301866    -0.310578    -0.181393 -1.341641 -0.447214   \n...            ...          ...          ...          ...       ...       ...   \n11611     0.208807     3.108528     0.080328     0.505005  1.341641  0.447214   \n11612    -0.129946    -0.301852    -0.310428    -0.181108  1.341641  1.341641   \n11613    -0.129933    -0.301848    -0.310377    -0.181093  1.341641  1.341641   \n11614    -0.113662    -0.295311    -0.287691    -0.169094  1.341641  1.341641   \n11615    -0.128722    -0.301586    -0.304547    -0.180292  1.341641  1.341641   \n\n       resistance  faultLabel  \n0       -0.873957           2  \n1       -0.810653           2  \n2       -0.747590           2  \n3       -0.873957           2  \n4       -0.810653           2  \n...           ...         ...  \n11611    3.937620          10  \n11612    0.263828          10  \n11613    0.327132          10  \n11614    1.530628          10  \n11615    3.937620          10  \n\n[11616 rows x 52 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>norm_t</th>\n      <th>mean_t</th>\n      <th>std_t</th>\n      <th>skew_t</th>\n      <th>kurt_t</th>\n      <th>max_t</th>\n      <th>norm_f</th>\n      <th>mean_f</th>\n      <th>std_f</th>\n      <th>skew_f</th>\n      <th>...</th>\n      <th>max_a5_db4</th>\n      <th>max_cd1_db4</th>\n      <th>max_cd2_db4</th>\n      <th>max_cd3_db4</th>\n      <th>max_cd4_db4</th>\n      <th>max_cd5_db4</th>\n      <th>locLabel</th>\n      <th>measloc</th>\n      <th>resistance</th>\n      <th>faultLabel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.499099</td>\n      <td>-0.214862</td>\n      <td>-1.474706</td>\n      <td>-0.605521</td>\n      <td>0.575383</td>\n      <td>-1.443264</td>\n      <td>-1.579096</td>\n      <td>-1.154587</td>\n      <td>-2.060222</td>\n      <td>-0.555180</td>\n      <td>...</td>\n      <td>-1.807947</td>\n      <td>-0.330024</td>\n      <td>-0.130069</td>\n      <td>-0.301886</td>\n      <td>-0.310909</td>\n      <td>-0.181465</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.873957</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.207467</td>\n      <td>-0.236463</td>\n      <td>-0.699680</td>\n      <td>-0.651058</td>\n      <td>0.581944</td>\n      <td>-0.885718</td>\n      <td>-1.289267</td>\n      <td>-0.523576</td>\n      <td>-1.130579</td>\n      <td>-0.603731</td>\n      <td>...</td>\n      <td>-1.668402</td>\n      <td>-0.330024</td>\n      <td>-0.129542</td>\n      <td>-0.301853</td>\n      <td>-0.310805</td>\n      <td>-0.181450</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.810653</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.837559</td>\n      <td>-0.244561</td>\n      <td>-0.199743</td>\n      <td>-0.641802</td>\n      <td>0.525222</td>\n      <td>-0.489077</td>\n      <td>-0.960404</td>\n      <td>-0.136424</td>\n      <td>-0.677251</td>\n      <td>-0.624132</td>\n      <td>...</td>\n      <td>-1.412161</td>\n      <td>-0.330023</td>\n      <td>-0.128225</td>\n      <td>-0.301772</td>\n      <td>-0.310531</td>\n      <td>-0.181409</td>\n      <td>-1.341641</td>\n      <td>-1.341641</td>\n      <td>-0.747590</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.495677</td>\n      <td>-0.453022</td>\n      <td>-1.430352</td>\n      <td>-0.178555</td>\n      <td>-0.810541</td>\n      <td>-1.430070</td>\n      <td>-1.574863</td>\n      <td>-1.154991</td>\n      <td>-1.807799</td>\n      <td>1.515406</td>\n      <td>...</td>\n      <td>-1.707587</td>\n      <td>-0.329553</td>\n      <td>-0.129610</td>\n      <td>-0.301866</td>\n      <td>-0.310578</td>\n      <td>-0.181393</td>\n      <td>-1.341641</td>\n      <td>-0.447214</td>\n      <td>-0.873957</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.495677</td>\n      <td>-0.453022</td>\n      <td>-1.430352</td>\n      <td>-0.178555</td>\n      <td>-0.810541</td>\n      <td>-1.430070</td>\n      <td>-1.574863</td>\n      <td>-1.154991</td>\n      <td>-1.807799</td>\n      <td>1.515406</td>\n      <td>...</td>\n      <td>-1.707587</td>\n      <td>-0.329553</td>\n      <td>-0.129610</td>\n      <td>-0.301866</td>\n      <td>-0.310578</td>\n      <td>-0.181393</td>\n      <td>-1.341641</td>\n      <td>-0.447214</td>\n      <td>-0.810653</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11611</th>\n      <td>0.429786</td>\n      <td>-0.307121</td>\n      <td>-0.053882</td>\n      <td>-0.434344</td>\n      <td>0.388033</td>\n      <td>1.243771</td>\n      <td>0.937667</td>\n      <td>-0.192473</td>\n      <td>0.817886</td>\n      <td>-0.463893</td>\n      <td>...</td>\n      <td>1.259013</td>\n      <td>0.321058</td>\n      <td>0.208807</td>\n      <td>3.108528</td>\n      <td>0.080328</td>\n      <td>0.505005</td>\n      <td>1.341641</td>\n      <td>0.447214</td>\n      <td>3.937620</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11612</th>\n      <td>-0.620165</td>\n      <td>-0.287928</td>\n      <td>-0.628268</td>\n      <td>-0.269792</td>\n      <td>-0.433074</td>\n      <td>-0.929026</td>\n      <td>-0.335575</td>\n      <td>-0.823860</td>\n      <td>0.017467</td>\n      <td>-0.341061</td>\n      <td>...</td>\n      <td>-0.430136</td>\n      <td>-0.330024</td>\n      <td>-0.129946</td>\n      <td>-0.301852</td>\n      <td>-0.310428</td>\n      <td>-0.181108</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>0.263828</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11613</th>\n      <td>-0.593179</td>\n      <td>-0.288986</td>\n      <td>-0.613189</td>\n      <td>-0.269305</td>\n      <td>-0.433169</td>\n      <td>-0.920501</td>\n      <td>-0.298412</td>\n      <td>-0.822171</td>\n      <td>0.049293</td>\n      <td>-0.341583</td>\n      <td>...</td>\n      <td>-0.385671</td>\n      <td>-0.330024</td>\n      <td>-0.129933</td>\n      <td>-0.301848</td>\n      <td>-0.310377</td>\n      <td>-0.181093</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>0.327132</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11614</th>\n      <td>-0.291858</td>\n      <td>-0.298627</td>\n      <td>-0.433742</td>\n      <td>-0.276955</td>\n      <td>-0.423696</td>\n      <td>-0.835224</td>\n      <td>0.097185</td>\n      <td>-0.707379</td>\n      <td>0.359935</td>\n      <td>-0.354688</td>\n      <td>...</td>\n      <td>0.093121</td>\n      <td>-0.327864</td>\n      <td>-0.113662</td>\n      <td>-0.295311</td>\n      <td>-0.287691</td>\n      <td>-0.169094</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>1.530628</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11615</th>\n      <td>-0.103601</td>\n      <td>-0.304468</td>\n      <td>-0.342394</td>\n      <td>-0.278578</td>\n      <td>-0.421673</td>\n      <td>-0.787378</td>\n      <td>0.349960</td>\n      <td>-0.761885</td>\n      <td>0.544018</td>\n      <td>-0.358430</td>\n      <td>...</td>\n      <td>0.389924</td>\n      <td>-0.330024</td>\n      <td>-0.128722</td>\n      <td>-0.301586</td>\n      <td>-0.304547</td>\n      <td>-0.180292</td>\n      <td>1.341641</td>\n      <td>1.341641</td>\n      <td>3.937620</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>11616 rows × 52 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = result_df.drop('faultLabel',axis=1)\n",
        "y = result_df['faultLabel']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "id": "qTbMMCXKXcmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Create and train an XGBoost classification model\n",
        "model = XGBClassifier(objective='multi:softmax', random_state=42)  # You may need to adjust the objective based on your problem\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T15:17:32.317173Z",
          "iopub.execute_input": "2024-02-06T15:17:32.317518Z",
          "iopub.status.idle": "2024-02-06T15:17:37.401159Z",
          "shell.execute_reply.started": "2024-02-06T15:17:32.317488Z",
          "shell.execute_reply": "2024-02-06T15:17:37.400201Z"
        },
        "trusted": true,
        "id": "vVHmEF3cXcmO",
        "outputId": "6c99a24b-77cc-4837-c717-a1eb727d297b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.56\nConfusion Matrix:\n[[59  0  0  7 12  0  5 12  6  3  0]\n [ 2 58 29  5  4  4  0  7  3  1  2]\n [ 0 29 55  3  8  0  1 12  7  1  4]\n [ 1  3  5 52 10  2  4 10  2  7  2]\n [ 0  0  2  8 72  2  4 14  4  7  3]\n [ 0  5  3  7  6 56  6  9  7  1  4]\n [ 2  2  1  7 13  1 67  9  7  1  3]\n [ 1  1  2  7 11  0  4 64  8  1  0]\n [ 2  4  2  3  7  3  2 12 54  2  6]\n [ 1  1  0  7 10  3  1  9  7 57  1]\n [ 1  4  2  5 11  2  0 10  6  1 57]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.86      0.57      0.68       104\n           1       0.54      0.50      0.52       115\n           2       0.54      0.46      0.50       120\n           3       0.47      0.53      0.50        98\n           4       0.44      0.62      0.51       116\n           5       0.77      0.54      0.63       104\n           6       0.71      0.59      0.65       113\n           7       0.38      0.65      0.48        99\n           8       0.49      0.56      0.52        97\n           9       0.70      0.59      0.64        97\n          10       0.70      0.58      0.63        99\n\n    accuracy                           0.56      1162\n   macro avg       0.60      0.56      0.57      1162\nweighted avg       0.60      0.56      0.57      1162\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create and train a Random Forest classification model\n",
        "model1 = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of trees (n_estimators) as needed\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T15:18:05.072787Z",
          "iopub.execute_input": "2024-02-06T15:18:05.073141Z",
          "iopub.status.idle": "2024-02-06T15:18:12.806173Z",
          "shell.execute_reply.started": "2024-02-06T15:18:05.073110Z",
          "shell.execute_reply": "2024-02-06T15:18:12.805194Z"
        },
        "trusted": true,
        "id": "T9USETm7XcmP",
        "outputId": "6595e31b-360b-4aa8-e61c-854d7d3a1562"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.54\nConfusion Matrix:\n[[58  4  4  8  4  4  6  6  1  3  6]\n [ 2 55 34  3  2  4  1  2  3  3  6]\n [ 3 36 47  5  5  5  2  5  6  3  3]\n [ 7  4 11 49  3  2  8  3  4  2  5]\n [ 2  2  2  4 72  2  4  8  5  6  9]\n [ 3  6  7  3  3 54  7  4  4  6  7]\n [ 2  8  6  9  7  3 66  7  0  1  4]\n [ 4  4  2  6  3  1  5 63  3  5  3]\n [ 4  6  6  4  2  4  3  7 53  4  4]\n [ 5  4  2  6  2  5  3  5  6 56  3]\n [ 3  9  4  1  2  4  3  6  4  4 59]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.62      0.56      0.59       104\n           1       0.40      0.48      0.43       115\n           2       0.38      0.39      0.38       120\n           3       0.50      0.50      0.50        98\n           4       0.69      0.62      0.65       116\n           5       0.61      0.52      0.56       104\n           6       0.61      0.58      0.60       113\n           7       0.54      0.64      0.59        99\n           8       0.60      0.55      0.57        97\n           9       0.60      0.58      0.59        97\n          10       0.54      0.60      0.57        99\n\n    accuracy                           0.54      1162\n   macro avg       0.55      0.55      0.55      1162\nweighted avg       0.55      0.54      0.55      1162\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Create and train a Decision Tree classification model\n",
        "model3 = DecisionTreeClassifier(max_depth=None, random_state=42)  # You can adjust max_depth as needed\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model3.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T15:18:35.291088Z",
          "iopub.execute_input": "2024-02-06T15:18:35.291441Z",
          "iopub.status.idle": "2024-02-06T15:18:36.291105Z",
          "shell.execute_reply.started": "2024-02-06T15:18:35.291397Z",
          "shell.execute_reply": "2024-02-06T15:18:36.290111Z"
        },
        "trusted": true,
        "id": "w97BI9pQXcmP",
        "outputId": "5e6adf36-c516-4263-df55-b1a7cd45e5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.52\nConfusion Matrix:\n[[51 27  7 14  2  0  2  1  0  0  0]\n [22 52 29  2  1  3  1  1  1  0  3]\n [25 36 47  1  1  3  1  0  5  0  1]\n [33  3  4 51  1  0  2  1  1  2  0]\n [40  0  1  1 70  1  2  0  0  0  1]\n [29  6  3  1  1 51  4  0  4  0  5]\n [42  2  1  3  0  2 63  0  0  0  0]\n [27  5  2  2  0  0  0 62  1  0  0]\n [28  6  6  1  0  1  0  4 49  0  2]\n [34  2  4  3  0  0  0  0  0 54  0]\n [29  3  3  1  1  1  0  0  4  0 57]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.14      0.49      0.22       104\n           1       0.37      0.45      0.40       115\n           2       0.44      0.39      0.41       120\n           3       0.64      0.52      0.57        98\n           4       0.91      0.60      0.73       116\n           5       0.82      0.49      0.61       104\n           6       0.84      0.56      0.67       113\n           7       0.90      0.63      0.74        99\n           8       0.75      0.51      0.60        97\n           9       0.96      0.56      0.71        97\n          10       0.83      0.58      0.68        99\n\n    accuracy                           0.52      1162\n   macro avg       0.69      0.52      0.58      1162\nweighted avg       0.68      0.52      0.57      1162\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "id": "im-EB2XTXsNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn1 = torch.nn.GRU(num_features, 220, batch_first=True, bidirectional=True)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.fc = torch.nn.Linear(440, 11)  # Adjust the input size to the linear layer\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn1_out, h_t1 = self.rnn1(x)\n",
        "        rnn1_out1 = self.dropout(rnn1_out)\n",
        "        fc_out = self.fc(rnn1_out1[:, -1, :])\n",
        "        out = self.sigmoid(fc_out)\n",
        "        return out\n",
        "inputs, classes = next(iter(train_loader))\n",
        "model5 = RNN(inputs.shape[0],inputs.shape[1],inputs.shape[2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T12:49:21.294292Z",
          "iopub.execute_input": "2024-02-06T12:49:21.295235Z",
          "iopub.status.idle": "2024-02-06T12:49:21.307898Z",
          "shell.execute_reply.started": "2024-02-06T12:49:21.295197Z",
          "shell.execute_reply": "2024-02-06T12:49:21.307107Z"
        },
        "trusted": true,
        "id": "Js0B309BXcmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model5 = model5.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "n_epochs = 80\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model5(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_acc += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Calculate metrics for the epoch\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_acc.double() / len(train_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs} -- Train Loss: {train_loss:.4f} -- Train Accuracy: {train_acc:.4f}\")\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(training_time)\n",
        "total_params = sum(p.numel() for p in model5.parameters())\n",
        "print(f\"Total Model Parameters: {total_params}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T12:49:24.180900Z",
          "iopub.execute_input": "2024-02-06T12:49:24.181750Z",
          "iopub.status.idle": "2024-02-06T12:50:37.994194Z",
          "shell.execute_reply.started": "2024-02-06T12:49:24.181716Z",
          "shell.execute_reply": "2024-02-06T12:50:37.993202Z"
        },
        "trusted": true,
        "id": "Wie68tTgXcmQ",
        "outputId": "01be0932-e528-4ece-9faa-ae344b1ccc58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/80 -- Train Loss: 2.3734 -- Train Accuracy: 0.1193\nEpoch 2/80 -- Train Loss: 2.3292 -- Train Accuracy: 0.1503\nEpoch 3/80 -- Train Loss: 2.2517 -- Train Accuracy: 0.2459\nEpoch 4/80 -- Train Loss: 2.1693 -- Train Accuracy: 0.3121\nEpoch 5/80 -- Train Loss: 2.1058 -- Train Accuracy: 0.3399\nEpoch 6/80 -- Train Loss: 2.0592 -- Train Accuracy: 0.3881\nEpoch 7/80 -- Train Loss: 2.0113 -- Train Accuracy: 0.4232\nEpoch 8/80 -- Train Loss: 1.9759 -- Train Accuracy: 0.4608\nEpoch 9/80 -- Train Loss: 1.9387 -- Train Accuracy: 0.5065\nEpoch 10/80 -- Train Loss: 1.9072 -- Train Accuracy: 0.5425\nEpoch 11/80 -- Train Loss: 1.8677 -- Train Accuracy: 0.5752\nEpoch 12/80 -- Train Loss: 1.8413 -- Train Accuracy: 0.6152\nEpoch 13/80 -- Train Loss: 1.8260 -- Train Accuracy: 0.6299\nEpoch 14/80 -- Train Loss: 1.8126 -- Train Accuracy: 0.6405\nEpoch 15/80 -- Train Loss: 1.7903 -- Train Accuracy: 0.6757\nEpoch 16/80 -- Train Loss: 1.7977 -- Train Accuracy: 0.6618\nEpoch 17/80 -- Train Loss: 1.7820 -- Train Accuracy: 0.6855\nEpoch 18/80 -- Train Loss: 1.7405 -- Train Accuracy: 0.7377\nEpoch 19/80 -- Train Loss: 1.7345 -- Train Accuracy: 0.7369\nEpoch 20/80 -- Train Loss: 1.7286 -- Train Accuracy: 0.7459\nEpoch 21/80 -- Train Loss: 1.7124 -- Train Accuracy: 0.7737\nEpoch 22/80 -- Train Loss: 1.6986 -- Train Accuracy: 0.7827\nEpoch 23/80 -- Train Loss: 1.7175 -- Train Accuracy: 0.7786\nEpoch 24/80 -- Train Loss: 1.6987 -- Train Accuracy: 0.7966\nEpoch 25/80 -- Train Loss: 1.6932 -- Train Accuracy: 0.8170\nEpoch 26/80 -- Train Loss: 1.6728 -- Train Accuracy: 0.8325\nEpoch 27/80 -- Train Loss: 1.6692 -- Train Accuracy: 0.8391\nEpoch 28/80 -- Train Loss: 1.6705 -- Train Accuracy: 0.8415\nEpoch 29/80 -- Train Loss: 1.6651 -- Train Accuracy: 0.8358\nEpoch 30/80 -- Train Loss: 1.6577 -- Train Accuracy: 0.8513\nEpoch 31/80 -- Train Loss: 1.6602 -- Train Accuracy: 0.8587\nEpoch 32/80 -- Train Loss: 1.6582 -- Train Accuracy: 0.8513\nEpoch 33/80 -- Train Loss: 1.6425 -- Train Accuracy: 0.8791\nEpoch 34/80 -- Train Loss: 1.6273 -- Train Accuracy: 0.8962\nEpoch 35/80 -- Train Loss: 1.6224 -- Train Accuracy: 0.8938\nEpoch 36/80 -- Train Loss: 1.6264 -- Train Accuracy: 0.9036\nEpoch 37/80 -- Train Loss: 1.6215 -- Train Accuracy: 0.8979\nEpoch 38/80 -- Train Loss: 1.6276 -- Train Accuracy: 0.8881\nEpoch 39/80 -- Train Loss: 1.6267 -- Train Accuracy: 0.8897\nEpoch 40/80 -- Train Loss: 1.6224 -- Train Accuracy: 0.9011\nEpoch 41/80 -- Train Loss: 1.6198 -- Train Accuracy: 0.9134\nEpoch 42/80 -- Train Loss: 1.6117 -- Train Accuracy: 0.9134\nEpoch 43/80 -- Train Loss: 1.6167 -- Train Accuracy: 0.9085\nEpoch 44/80 -- Train Loss: 1.6292 -- Train Accuracy: 0.8930\nEpoch 45/80 -- Train Loss: 1.6017 -- Train Accuracy: 0.9216\nEpoch 46/80 -- Train Loss: 1.6076 -- Train Accuracy: 0.9118\nEpoch 47/80 -- Train Loss: 1.5961 -- Train Accuracy: 0.9273\nEpoch 48/80 -- Train Loss: 1.6040 -- Train Accuracy: 0.9306\nEpoch 49/80 -- Train Loss: 1.6037 -- Train Accuracy: 0.9355\nEpoch 50/80 -- Train Loss: 1.6149 -- Train Accuracy: 0.9248\nEpoch 51/80 -- Train Loss: 1.5995 -- Train Accuracy: 0.9265\nEpoch 52/80 -- Train Loss: 1.6219 -- Train Accuracy: 0.9118\nEpoch 53/80 -- Train Loss: 1.6180 -- Train Accuracy: 0.9216\nEpoch 54/80 -- Train Loss: 1.5982 -- Train Accuracy: 0.9281\nEpoch 55/80 -- Train Loss: 1.5924 -- Train Accuracy: 0.9355\nEpoch 56/80 -- Train Loss: 1.5999 -- Train Accuracy: 0.9297\nEpoch 57/80 -- Train Loss: 1.6008 -- Train Accuracy: 0.9404\nEpoch 58/80 -- Train Loss: 1.5958 -- Train Accuracy: 0.9436\nEpoch 59/80 -- Train Loss: 1.5977 -- Train Accuracy: 0.9363\nEpoch 60/80 -- Train Loss: 1.6040 -- Train Accuracy: 0.9363\nEpoch 61/80 -- Train Loss: 1.5984 -- Train Accuracy: 0.9444\nEpoch 62/80 -- Train Loss: 1.5840 -- Train Accuracy: 0.9542\nEpoch 63/80 -- Train Loss: 1.5816 -- Train Accuracy: 0.9559\nEpoch 64/80 -- Train Loss: 1.5930 -- Train Accuracy: 0.9453\nEpoch 65/80 -- Train Loss: 1.6052 -- Train Accuracy: 0.9306\nEpoch 66/80 -- Train Loss: 1.6128 -- Train Accuracy: 0.9314\nEpoch 67/80 -- Train Loss: 1.5934 -- Train Accuracy: 0.9404\nEpoch 68/80 -- Train Loss: 1.5853 -- Train Accuracy: 0.9485\nEpoch 69/80 -- Train Loss: 1.6060 -- Train Accuracy: 0.9371\nEpoch 70/80 -- Train Loss: 1.6038 -- Train Accuracy: 0.9395\nEpoch 71/80 -- Train Loss: 1.5846 -- Train Accuracy: 0.9575\nEpoch 72/80 -- Train Loss: 1.5849 -- Train Accuracy: 0.9469\nEpoch 73/80 -- Train Loss: 1.5880 -- Train Accuracy: 0.9485\nEpoch 74/80 -- Train Loss: 1.6094 -- Train Accuracy: 0.9240\nEpoch 75/80 -- Train Loss: 1.6025 -- Train Accuracy: 0.9322\nEpoch 76/80 -- Train Loss: 1.5839 -- Train Accuracy: 0.9518\nEpoch 77/80 -- Train Loss: 1.5779 -- Train Accuracy: 0.9624\nEpoch 78/80 -- Train Loss: 1.5815 -- Train Accuracy: 0.9575\nEpoch 79/80 -- Train Loss: 1.5812 -- Train Accuracy: 0.9592\nEpoch 80/80 -- Train Loss: 1.5785 -- Train Accuracy: 0.9559\n73.80013489723206\nTotal Model Parameters: 365211\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/kaggle/working/model_without_defence.pt'\n",
        "torch.save(model5.state_dict(), save_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-25T13:05:56.889399Z",
          "iopub.execute_input": "2024-01-25T13:05:56.890230Z",
          "iopub.status.idle": "2024-01-25T13:05:56.897440Z",
          "shell.execute_reply.started": "2024-01-25T13:05:56.890196Z",
          "shell.execute_reply": "2024-01-25T13:05:56.896668Z"
        },
        "trusted": true,
        "id": "ybjiQc-OXcmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchattacks"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T12:50:43.882415Z",
          "iopub.execute_input": "2024-02-06T12:50:43.882917Z",
          "iopub.status.idle": "2024-02-06T12:50:55.525745Z",
          "shell.execute_reply.started": "2024-02-06T12:50:43.882882Z",
          "shell.execute_reply": "2024-02-06T12:50:55.524585Z"
        },
        "trusted": true,
        "id": "nULb5KCoXcmR",
        "outputId": "82711fd4-d0b7-486d-be73-1023f85b1429"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torchattacks in /opt/conda/lib/python3.10/site-packages (3.5.1)\nRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.0.0)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (0.15.1)\nRequirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.11.4)\nRequirement already satisfied: tqdm>=4.56.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (4.66.1)\nRequirement already satisfied: requests~=2.25.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.25.1)\nRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.24.3)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2023.11.17)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->torchattacks) (10.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision\n",
        "import torchattacks\n",
        "# Load the pre-trained model\n",
        "model5.to(\"cpu\")\n",
        "model5.eval()\n",
        "\n",
        "# Assuming you have a DataLoader for the test set called 'test_loader'\n",
        "# Adjust this based on your data loading procedure\n",
        "# Also, make sure your test set is properly normalized\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.2  # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.2 # Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.2 # Perturbation magnitude for C&W\n",
        "\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "correct_adversarial_rfgsm=0\n",
        "correct_adversarial_PGD=0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = model5(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, labels)\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, labels)\n",
        "\n",
        "    # C&W: Craft adversarial example\n",
        "    attack_cw = torchattacks.CW(model5, c=epsilon_cw, kappa=0)\n",
        "    adversarial_inputs_cw = attack_cw(inputs, labels)\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, labels)\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = model5(adversarial_inputs_fgsm)\n",
        "    outputs_adversarial_bim = model5(adversarial_inputs_bim)\n",
        "    outputs_adversarial_cw = model5(adversarial_inputs_cw)\n",
        "    outputs_adversarial_rfgsm = model5(adversarial_inputs_RFGSM)\n",
        "    outputs_adversarial_PGD = model5(adversarial_inputs_PGD)\n",
        "\n",
        "\n",
        "    # Update accuracy metrics\n",
        "    total += labels.size(0)\n",
        "    correct_original += (predicted_original == labels).sum().item()\n",
        "    correct_adversarial_fgsm += (torch.argmax(outputs_adversarial_fgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_bim += (torch.argmax(outputs_adversarial_bim, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_cw += (torch.argmax(outputs_adversarial_cw, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_rfgsm += (torch.argmax(outputs_adversarial_rfgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_PGD += (torch.argmax(outputs_adversarial_PGD, dim=1) == labels).sum().item()\n",
        "\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy_original = correct_original / total\n",
        "accuracy_adversarial_fgsm = correct_adversarial_fgsm / total\n",
        "accuracy_adversarial_bim = correct_adversarial_bim / total\n",
        "accuracy_adversarial_cw = correct_adversarial_cw / total\n",
        "accuracy_adversarial_rfgsm = correct_adversarial_rfgsm / total\n",
        "accuracy_adversarial_PGD = correct_adversarial_PGD / total\n",
        "\n",
        "print(f'Accuracy on Original Data: {accuracy_original * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (FGSM): {accuracy_adversarial_fgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (BIM): {accuracy_adversarial_bim * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (C&W): {accuracy_adversarial_cw * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (RFGSM): {accuracy_adversarial_rfgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (PDG): {accuracy_adversarial_PGD * 100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T12:52:02.997912Z",
          "iopub.execute_input": "2024-02-06T12:52:02.998645Z",
          "iopub.status.idle": "2024-02-06T12:52:33.745806Z",
          "shell.execute_reply.started": "2024-02-06T12:52:02.998609Z",
          "shell.execute_reply": "2024-02-06T12:52:33.744836Z"
        },
        "trusted": true,
        "id": "bbaAJ84XXcmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given ASR values for two sets\n",
        "asr_values_set1 = [0.604,0.18, 0.173, 0.159, 0.131, 0.131, 0.111, 0.111, 0.111, 0.104, 0.104]\n",
        "asr_values_set2 = [0.604,0.208, 0.125, 0.097, 0.09,0.083, 0.083,  0.076, 0.076, 0.062, 0.055]\n",
        "asr_values_set3 = [0.604,0.138, 0.131, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]\n",
        "asr_values_set4 = [0.604,0.125, 0.062, 0.055, 0.041, 0.034,0.041, 0.048,  0.027, 0.027,0.027]\n",
        "asr_values_set5 = [0.604,0.125, 0.083, 0.048, 0.034, 0.027, 0.041, 0.041, 0.013, 0.027, 0.041]\n",
        "\n",
        "# Create a list of feature numbers starting from one\n",
        "feature_numbers = [0,0.05,0.1,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50]\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.ylim(0, 1.0)\n",
        "plt.plot(feature_numbers, asr_values_set1, marker='o', linestyle='-', color='b', label='fgsm')\n",
        "plt.plot(feature_numbers, asr_values_set2, marker='s', linestyle='-', color='r', label='bim')\n",
        "plt.plot(feature_numbers, asr_values_set3, marker='^', linestyle='-', color='g', label='cw')  # Different color for set3\n",
        "plt.plot(feature_numbers, asr_values_set4, marker='*', linestyle='-', color='orange', label='rfgsm')  # Different color for set4\n",
        "plt.plot(feature_numbers, asr_values_set5, marker='D', linestyle='-', color='purple', label='pgd')\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs epsilon')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/model_WB.pdf', format='pdf')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-25T13:15:52.242741Z",
          "iopub.execute_input": "2024-01-25T13:15:52.243446Z",
          "iopub.status.idle": "2024-01-25T13:15:53.263811Z",
          "shell.execute_reply.started": "2024-01-25T13:15:52.243413Z",
          "shell.execute_reply": "2024-01-25T13:15:53.262902Z"
        },
        "trusted": true,
        "id": "_JyiXhxxXcmR",
        "outputId": "690e5929-34ca-48ed-b553-1a8a73da1a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T16:10:04.795275Z",
          "iopub.execute_input": "2024-02-03T16:10:04.795671Z",
          "iopub.status.idle": "2024-02-03T16:10:04.807703Z",
          "shell.execute_reply.started": "2024-02-03T16:10:04.795637Z",
          "shell.execute_reply": "2024-02-03T16:10:04.806477Z"
        },
        "trusted": true,
        "id": "bef1uuvfXcmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn1 = torch.nn.GRU(num_features, 220, batch_first=True, bidirectional=True)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.fc = torch.nn.Linear(440, 11)  # Adjust the input size to the linear layer\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn1_out, h_t1 = self.rnn1(x)\n",
        "        rnn1_out1 = self.dropout(rnn1_out)\n",
        "        fc_out = self.fc(rnn1_out1[:, -1, :])\n",
        "        out = self.sigmoid(fc_out)\n",
        "        return out\n",
        "inputs, classes = next(iter(train_loader))\n",
        "model5 = RNN(inputs.shape[0],inputs.shape[1],inputs.shape[2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T16:10:05.500360Z",
          "iopub.execute_input": "2024-02-03T16:10:05.500842Z",
          "iopub.status.idle": "2024-02-03T16:10:05.575647Z",
          "shell.execute_reply.started": "2024-02-03T16:10:05.500807Z",
          "shell.execute_reply": "2024-02-03T16:10:05.574412Z"
        },
        "trusted": true,
        "id": "2qhbkQ9CXcmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchattacks\n",
        "# model5.to(\"cpu\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
        "epsilon_fgsm = 0.2  # FGSM perturbation magnitude\n",
        "epsilon_bim = 0.2 # BIM perturbation magnitude\n",
        " # C&W perturbation magnitude\n",
        "\n",
        "n_epochs = 80\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    model5.train()\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass on the original input\n",
        "        outputs = model5(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass on the original input\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # FGSM: Add perturbation to the input for FGSM attack\n",
        "\n",
        "        fgsm_attack = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "        fgsm_adversarial_inputs = fgsm_attack(inputs, labels)\n",
        "\n",
        "        # BIM: Add perturbation to the input for BIM attack\n",
        "        bim_attack = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "        bim_adversarial_inputs = bim_attack(inputs, labels)\n",
        "\n",
        "\n",
        "        # Forward pass on adversarial inputs for all attacks\n",
        "        fgsm_adversarial_outputs = model5(fgsm_adversarial_inputs)\n",
        "        bim_adversarial_outputs = model5(bim_adversarial_inputs)\n",
        "\n",
        "        # Calculate losses for all attacks\n",
        "        fgsm_adversarial_loss = criterion(fgsm_adversarial_outputs, labels)\n",
        "        bim_adversarial_loss = criterion(bim_adversarial_outputs, labels)\n",
        "\n",
        "        # Backward pass on adversarial inputs for all attacks\n",
        "        fgsm_adversarial_loss.backward()\n",
        "        bim_adversarial_loss.backward()\n",
        "\n",
        "        # Update gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += (fgsm_adversarial_loss.item() + bim_adversarial_loss.item()) * inputs.size(0)\n",
        "        _, fgsm_preds = torch.max(fgsm_adversarial_outputs, 1)\n",
        "        _, bim_preds = torch.max(bim_adversarial_outputs, 1)\n",
        "        train_acc += (torch.sum(fgsm_preds == labels.data) + torch.sum(bim_preds == labels.data))\n",
        "\n",
        "    # Calculate metrics for the epoch\n",
        "    train_loss /= (2 * len(train_loader.dataset))\n",
        "    train_acc = train_acc.double() / (2 * len(train_loader.dataset))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs} -- Train Loss: {train_loss:.4f} -- Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(training_time)\n",
        "total_params = sum(p.numel() for p in model5.parameters())\n",
        "print(f\"Total Model Parameters: {total_params}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-25T13:16:10.785694Z",
          "iopub.execute_input": "2024-01-25T13:16:10.786037Z",
          "iopub.status.idle": "2024-01-25T14:35:08.989230Z",
          "shell.execute_reply.started": "2024-01-25T13:16:10.786011Z",
          "shell.execute_reply": "2024-01-25T14:35:08.988256Z"
        },
        "trusted": true,
        "id": "JmU2bdZLXcmS",
        "outputId": "144f624d-bfd3-40f9-9717-6b01488c3f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/80 -- Train Loss: 2.4243 -- Train Accuracy: 0.0850\nEpoch 2/80 -- Train Loss: 2.4079 -- Train Accuracy: 0.1046\nEpoch 3/80 -- Train Loss: 2.3529 -- Train Accuracy: 0.1332\nEpoch 4/80 -- Train Loss: 2.3090 -- Train Accuracy: 0.1479\nEpoch 5/80 -- Train Loss: 2.2371 -- Train Accuracy: 0.2116\nEpoch 6/80 -- Train Loss: 2.1880 -- Train Accuracy: 0.2414\nEpoch 7/80 -- Train Loss: 2.1329 -- Train Accuracy: 0.2868\nEpoch 8/80 -- Train Loss: 2.0805 -- Train Accuracy: 0.3403\nEpoch 9/80 -- Train Loss: 2.0481 -- Train Accuracy: 0.3660\nEpoch 10/80 -- Train Loss: 2.0100 -- Train Accuracy: 0.3897\nEpoch 11/80 -- Train Loss: 1.9722 -- Train Accuracy: 0.4236\nEpoch 12/80 -- Train Loss: 1.9562 -- Train Accuracy: 0.4645\nEpoch 13/80 -- Train Loss: 1.9372 -- Train Accuracy: 0.4833\nEpoch 14/80 -- Train Loss: 1.9137 -- Train Accuracy: 0.5057\nEpoch 15/80 -- Train Loss: 1.8834 -- Train Accuracy: 0.5266\nEpoch 16/80 -- Train Loss: 1.8622 -- Train Accuracy: 0.5678\nEpoch 17/80 -- Train Loss: 1.8481 -- Train Accuracy: 0.5866\nEpoch 18/80 -- Train Loss: 1.8337 -- Train Accuracy: 0.5968\nEpoch 19/80 -- Train Loss: 1.8216 -- Train Accuracy: 0.6127\nEpoch 20/80 -- Train Loss: 1.8094 -- Train Accuracy: 0.6348\nEpoch 21/80 -- Train Loss: 1.7979 -- Train Accuracy: 0.6560\nEpoch 22/80 -- Train Loss: 1.7744 -- Train Accuracy: 0.6793\nEpoch 23/80 -- Train Loss: 1.7842 -- Train Accuracy: 0.6789\nEpoch 24/80 -- Train Loss: 1.7796 -- Train Accuracy: 0.6818\nEpoch 25/80 -- Train Loss: 1.7517 -- Train Accuracy: 0.7173\nEpoch 26/80 -- Train Loss: 1.7508 -- Train Accuracy: 0.7177\nEpoch 27/80 -- Train Loss: 1.7546 -- Train Accuracy: 0.7271\nEpoch 28/80 -- Train Loss: 1.7299 -- Train Accuracy: 0.7443\nEpoch 29/80 -- Train Loss: 1.7252 -- Train Accuracy: 0.7586\nEpoch 30/80 -- Train Loss: 1.7132 -- Train Accuracy: 0.7643\nEpoch 31/80 -- Train Loss: 1.7141 -- Train Accuracy: 0.7725\nEpoch 32/80 -- Train Loss: 1.7131 -- Train Accuracy: 0.7692\nEpoch 33/80 -- Train Loss: 1.7051 -- Train Accuracy: 0.7835\nEpoch 34/80 -- Train Loss: 1.6950 -- Train Accuracy: 0.7978\nEpoch 35/80 -- Train Loss: 1.6961 -- Train Accuracy: 0.7921\nEpoch 36/80 -- Train Loss: 1.6950 -- Train Accuracy: 0.8035\nEpoch 37/80 -- Train Loss: 1.6972 -- Train Accuracy: 0.8080\nEpoch 38/80 -- Train Loss: 1.6855 -- Train Accuracy: 0.8203\nEpoch 39/80 -- Train Loss: 1.6804 -- Train Accuracy: 0.8190\nEpoch 40/80 -- Train Loss: 1.6798 -- Train Accuracy: 0.8182\nEpoch 41/80 -- Train Loss: 1.6679 -- Train Accuracy: 0.8292\nEpoch 42/80 -- Train Loss: 1.6833 -- Train Accuracy: 0.8129\nEpoch 43/80 -- Train Loss: 1.6716 -- Train Accuracy: 0.8321\nEpoch 44/80 -- Train Loss: 1.6780 -- Train Accuracy: 0.8292\nEpoch 45/80 -- Train Loss: 1.6837 -- Train Accuracy: 0.8150\nEpoch 46/80 -- Train Loss: 1.6693 -- Train Accuracy: 0.8329\nEpoch 47/80 -- Train Loss: 1.6518 -- Train Accuracy: 0.8587\nEpoch 48/80 -- Train Loss: 1.6565 -- Train Accuracy: 0.8415\nEpoch 49/80 -- Train Loss: 1.6515 -- Train Accuracy: 0.8533\nEpoch 50/80 -- Train Loss: 1.6525 -- Train Accuracy: 0.8525\nEpoch 51/80 -- Train Loss: 1.6659 -- Train Accuracy: 0.8370\nEpoch 52/80 -- Train Loss: 1.6606 -- Train Accuracy: 0.8476\nEpoch 53/80 -- Train Loss: 1.6523 -- Train Accuracy: 0.8623\nEpoch 54/80 -- Train Loss: 1.6529 -- Train Accuracy: 0.8566\nEpoch 55/80 -- Train Loss: 1.6404 -- Train Accuracy: 0.8770\nEpoch 56/80 -- Train Loss: 1.6457 -- Train Accuracy: 0.8640\nEpoch 57/80 -- Train Loss: 1.6586 -- Train Accuracy: 0.8554\nEpoch 58/80 -- Train Loss: 1.6515 -- Train Accuracy: 0.8640\nEpoch 59/80 -- Train Loss: 1.6524 -- Train Accuracy: 0.8615\nEpoch 60/80 -- Train Loss: 1.6632 -- Train Accuracy: 0.8489\nEpoch 61/80 -- Train Loss: 1.6469 -- Train Accuracy: 0.8689\nEpoch 62/80 -- Train Loss: 1.6511 -- Train Accuracy: 0.8664\nEpoch 63/80 -- Train Loss: 1.6566 -- Train Accuracy: 0.8550\nEpoch 64/80 -- Train Loss: 1.6580 -- Train Accuracy: 0.8493\nEpoch 65/80 -- Train Loss: 1.6461 -- Train Accuracy: 0.8681\nEpoch 66/80 -- Train Loss: 1.6322 -- Train Accuracy: 0.8893\nEpoch 67/80 -- Train Loss: 1.6509 -- Train Accuracy: 0.8725\nEpoch 68/80 -- Train Loss: 1.6551 -- Train Accuracy: 0.8554\nEpoch 69/80 -- Train Loss: 1.6450 -- Train Accuracy: 0.8685\nEpoch 70/80 -- Train Loss: 1.6410 -- Train Accuracy: 0.8901\nEpoch 71/80 -- Train Loss: 1.6373 -- Train Accuracy: 0.8807\nEpoch 72/80 -- Train Loss: 1.6472 -- Train Accuracy: 0.8738\nEpoch 73/80 -- Train Loss: 1.6461 -- Train Accuracy: 0.8689\nEpoch 74/80 -- Train Loss: 1.6391 -- Train Accuracy: 0.8791\nEpoch 75/80 -- Train Loss: 1.6350 -- Train Accuracy: 0.8832\nEpoch 76/80 -- Train Loss: 1.6408 -- Train Accuracy: 0.8848\nEpoch 77/80 -- Train Loss: 1.6450 -- Train Accuracy: 0.8730\nEpoch 78/80 -- Train Loss: 1.6332 -- Train Accuracy: 0.8860\nEpoch 79/80 -- Train Loss: 1.6344 -- Train Accuracy: 0.8856\nEpoch 80/80 -- Train Loss: 1.6580 -- Train Accuracy: 0.8562\n4738.186660766602\nTotal Model Parameters: 365211\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/kaggle/working/model_with_defence.pt'\n",
        "torch.save(model5.state_dict(), save_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-25T14:40:00.156239Z",
          "iopub.execute_input": "2024-01-25T14:40:00.157203Z",
          "iopub.status.idle": "2024-01-25T14:40:00.164481Z",
          "shell.execute_reply.started": "2024-01-25T14:40:00.157171Z",
          "shell.execute_reply": "2024-01-25T14:40:00.163545Z"
        },
        "trusted": true,
        "id": "zzVCYcW6XcmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.load_state_dict(torch.load('/kaggle/input/test-data/model_with_defence.pt'))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T12:17:08.660195Z",
          "iopub.execute_input": "2024-02-03T12:17:08.660931Z",
          "iopub.status.idle": "2024-02-03T12:17:08.696204Z",
          "shell.execute_reply.started": "2024-02-03T12:17:08.660894Z",
          "shell.execute_reply": "2024-02-03T12:17:08.695075Z"
        },
        "trusted": true,
        "id": "3oz_Bd4BXcmS",
        "outputId": "6b649a7e-4df8-4b67-9088-f44500fbe6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(end_time)\n",
        "print(start_time)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-25T14:38:29.394996Z",
          "iopub.execute_input": "2024-01-25T14:38:29.395916Z",
          "iopub.status.idle": "2024-01-25T14:38:29.400937Z",
          "shell.execute_reply.started": "2024-01-25T14:38:29.395881Z",
          "shell.execute_reply": "2024-01-25T14:38:29.399980Z"
        },
        "trusted": true,
        "id": "lnl4zH-0XcmS",
        "outputId": "932132fa-3465-4d42-ef8d-d15119fc1821"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1706193308.9835367\n1706188570.796876\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### import torchvision\n",
        "import torchattacks\n",
        "\n",
        "# Load the pre-trained model\n",
        "model5.eval()\n",
        "\n",
        "# Assuming you have a DataLoader for the test set called 'test_loader'\n",
        "# Adjust this based on your data loading procedure\n",
        "# Also, make sure your test set is properly normalized\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.5  # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.5# Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.5# Perturbation magnitude for C&W\n",
        "\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "correct_adversarial_rfgsm=0\n",
        "correct_adversarial_PGD=0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = model5(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, labels)\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, labels)\n",
        "\n",
        "    # C&W: Craft adversarial example\n",
        "    attack_cw = torchattacks.CW(model5, c=epsilon_cw, kappa=0,steps=100)\n",
        "    adversarial_inputs_cw = attack_cw(inputs, labels)\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, labels)\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = model5(adversarial_inputs_fgsm)\n",
        "    outputs_adversarial_bim = model5(adversarial_inputs_bim)\n",
        "    outputs_adversarial_cw = model5(adversarial_inputs_cw)\n",
        "    outputs_adversarial_rfgsm = model5(adversarial_inputs_RFGSM)\n",
        "    outputs_adversarial_PGD = model5(adversarial_inputs_PGD)\n",
        "\n",
        "\n",
        "    # Update accuracy metrics\n",
        "    total += labels.size(0)\n",
        "    correct_original += (predicted_original == labels).sum().item()\n",
        "    correct_adversarial_fgsm += (torch.argmax(outputs_adversarial_fgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_bim += (torch.argmax(outputs_adversarial_bim, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_cw += (torch.argmax(outputs_adversarial_cw, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_rfgsm += (torch.argmax(outputs_adversarial_rfgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_PGD += (torch.argmax(outputs_adversarial_PGD, dim=1) == labels).sum().item()\n",
        "\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy_original = correct_original / total\n",
        "accuracy_adversarial_fgsm = correct_adversarial_fgsm / total\n",
        "accuracy_adversarial_bim = correct_adversarial_bim / total\n",
        "accuracy_adversarial_cw = correct_adversarial_cw / total\n",
        "accuracy_adversarial_rfgsm = correct_adversarial_rfgsm / total\n",
        "accuracy_adversarial_PGD = correct_adversarial_PGD / total\n",
        "\n",
        "print(f'Accuracy on Original Data: {accuracy_original * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (FGSM): {accuracy_adversarial_fgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (BIM): {accuracy_adversarial_bim * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (C&W): {accuracy_adversarial_cw * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (RFGSM): {accuracy_adversarial_rfgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (PDG): {accuracy_adversarial_PGD * 100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T10:04:12.736153Z",
          "iopub.execute_input": "2024-02-03T10:04:12.736869Z",
          "iopub.status.idle": "2024-02-03T10:05:05.105603Z",
          "shell.execute_reply.started": "2024-02-03T10:04:12.736838Z",
          "shell.execute_reply": "2024-02-03T10:05:05.104611Z"
        },
        "trusted": true,
        "id": "AXFvPjcpXcmS",
        "outputId": "4616ab16-e4ff-4433-da3d-3fba0775d13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy on Original Data: 61.81%\nAccuracy on Adversarial Data (FGSM): 18.75%\nAccuracy on Adversarial Data (BIM): 15.97%\nAccuracy on Adversarial Data (C&W): 43.75%\nAccuracy on Adversarial Data (RFGSM): 20.83%\nAccuracy on Adversarial Data (PDG): 17.36%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given ASR values for two sets\n",
        "asr_values_set1 = [0.618,0.50, 0.472, 0.451, 0.437, 0.388, 0.347, 0.319, 0.284, 0.201, 0.187]\n",
        "asr_values_set2 = [0.618,0.479, 0.444, 0.402, 0.381,0.354, 0.312, 0.25, 0.208, 0.173, 0.159]\n",
        "asr_values_set3 = [0.618,0.458, 0.458, 0.451, 0.451, 0.437, 0.437, 0.437, 0.437, 0.437, 0.437]\n",
        "asr_values_set4 = [0.618,0.451, 0.423, 0.409, 0.388, 0.368,0.347, 0.291,  0.284, 0.229, 0.194]\n",
        "asr_values_set5 = [0.618,0.444, 0.444, 0.43, 0.388, 0.354, 0.326, 0.312, 0.236, 0.166, 0.18]\n",
        "\n",
        "# Create a list of feature numbers starting from one\n",
        "feature_numbers = [0,0.05,0.1,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50]\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.ylim(0, 1.0)\n",
        "plt.plot(feature_numbers, asr_values_set1, marker='o', linestyle='-', color='b', label='fgsm')\n",
        "plt.plot(feature_numbers, asr_values_set2, marker='s', linestyle='-', color='r', label='bim')\n",
        "plt.plot(feature_numbers, asr_values_set3, marker='^', linestyle='-', color='g', label='cw')  # Different color for set3\n",
        "plt.plot(feature_numbers, asr_values_set4, marker='*', linestyle='-', color='orange', label='rfgsm')  # Different color for set4\n",
        "plt.plot(feature_numbers, asr_values_set5, marker='D', linestyle='-', color='purple', label='pgd')\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs epsilon')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/model_WB_Defence.pdf', format='pdf')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-25T14:49:52.105829Z",
          "iopub.execute_input": "2024-01-25T14:49:52.106977Z",
          "iopub.status.idle": "2024-01-25T14:49:52.832131Z",
          "shell.execute_reply.started": "2024-01-25T14:49:52.106922Z",
          "shell.execute_reply": "2024-01-25T14:49:52.831230Z"
        },
        "trusted": true,
        "id": "7Qh_lsi2XcmT",
        "outputId": "a06f41ba-c950-42c5-c55f-c319905e0fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T12:17:17.779995Z",
          "iopub.execute_input": "2024-02-03T12:17:17.780408Z",
          "iopub.status.idle": "2024-02-03T12:17:17.788240Z",
          "shell.execute_reply.started": "2024-02-03T12:17:17.780373Z",
          "shell.execute_reply": "2024-02-03T12:17:17.786414Z"
        },
        "trusted": true,
        "id": "j0HO_pqJXcmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = CustomDataset()\n",
        "trainSize = 0.9\n",
        "# valSize = 0.05\n",
        "a = CustomDataset()\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "test_size = len(a)-train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T16:11:28.587662Z",
          "iopub.execute_input": "2024-02-03T16:11:28.588623Z",
          "iopub.status.idle": "2024-02-03T16:11:33.374506Z",
          "shell.execute_reply.started": "2024-02-03T16:11:28.588575Z",
          "shell.execute_reply": "2024-02-03T16:11:33.373342Z"
        },
        "trusted": true,
        "id": "kkyDfExIXcmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchattacks\n",
        "\n",
        "# Define the generator and discriminator for the GAN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, batch_size,window_size,num_features,latent_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_features = num_features\n",
        "        self.window_size = window_size\n",
        "       # self.fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.fc1 = nn.Linear(num_features, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 256)\n",
        "        self.fc3 = nn.Linear(256,batch_size*window_size)\n",
        "        self.fc4 = nn.Linear(batch_size*window_size,num_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        #return x.view(x.size(0), 1, -1)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 160)\n",
        "        self.fc2 = nn.Linear(160, 200)\n",
        "        self.fc3 = nn.Linear(200, 256)\n",
        "        self.fc4 = nn.Linear(256, 512)\n",
        "        self.fc5 = nn.Linear(512, 1)\n",
        "        self.window_size = window_size\n",
        "        self.num_features = num_features\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "      #x = x.view(-1, self.num_features)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.relu(self.fc3(x))\n",
        "      x = F.relu(self.fc4(x))\n",
        "      x = torch.sigmoid(self.fc5(x))\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "# Define the GAN training function\n",
        "\n",
        "def train_gan(generator, discriminator, train_loader, num_epochs=100, lr=0.0002,\n",
        "              device=torch.device('cpu')):\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    # Define the loss functions and optimizers\n",
        "\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (inputs,Labels) in enumerate(train_loader):\n",
        "            # Move data to device\n",
        "            inputs = inputs.to(device)\n",
        "            Labels = Labels.to(device)\n",
        "\n",
        "            # Train discriminator on real data\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            real_labels = torch.ones(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            real_outputs = discriminator(inputs)\n",
        "            discriminator_loss_real = adversarial_loss(real_outputs, real_labels)\n",
        "            discriminator_loss_real.backward()\n",
        "\n",
        "            # Train discriminator on fake data generated by the generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            latent_inputs = torch.randn(inputs.shape[0], inputs.shape[1], inputs.shape[2]).to(device)\n",
        "            fake_inputs = generator(latent_inputs)\n",
        "            fake_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            fake_outputs = discriminator(fake_inputs)\n",
        "            discriminator_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
        "            discriminator_loss_fake.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "            attack_fgsm = torchattacks.FGSM(model5, eps=0.05)\n",
        "            adversarial_inputs_fgsm = attack_fgsm(inputs, torch.ones_like(Labels))\n",
        "            attack_bim = torchattacks.BIM(model5, eps=0.05)\n",
        "            adversarial_inputs_bim = attack_bim(inputs, torch.ones_like(Labels))\n",
        "            adversarial_inputs_combined = torch.cat([adversarial_inputs_fgsm, adversarial_inputs_bim], dim=0)\n",
        "            fake_labels = torch.zeros(adversarial_inputs_combined.size(0), adversarial_inputs_combined.size(1), 1).to(device)\n",
        "            fake_outputs = discriminator(adversarial_inputs_combined)\n",
        "            discriminator_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
        "            discriminator_loss_fake.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "\n",
        "            # Train generator to generate samples that increase the discriminator loss\n",
        "            generator_optimizer.zero_grad()\n",
        "            latent_inputs = torch.randn(inputs.shape[0], inputs.shape[1], inputs.shape[2]).to(device)\n",
        "            fake_inputs = generator(latent_inputs)\n",
        "            # @S: generator wants to maximize the probability of the discriminator being wrong. So loss is computed between discriminator's output to a fake image and the\n",
        "            #fake label (if the fake label is 0)\n",
        "            fake_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            generator_loss =adversarial_loss(discriminator(fake_inputs), real_labels)\n",
        "            generator_loss.backward()\n",
        "            generator_optimizer.step()\n",
        "            if i % 10 == 0:\n",
        "              print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'\n",
        "                      .format(epoch, num_epochs, i, len(train_loader),\n",
        "discriminator_loss_real.item() + discriminator_loss_fake.item(), generator_loss.item()))\n",
        "                # Return the trained generator\n",
        "    return generator,discriminator\n",
        "\n",
        "\n",
        "# Define the number of epochs and learning rate for training the GAN\n",
        "num_epochs = 100\n",
        "lr = 0.0002\n",
        "inputs, classes = next(iter(train_loader))\n",
        "# Create the GAN models\n",
        "batch_size, window_size, num_features = inputs.shape\n",
        "generator = Generator(batch_size,window_size,num_features)\n",
        "discriminator = Discriminator(batch_size, window_size, num_features)\n",
        "\n",
        "# Train the GAN on your data\n",
        "trained_generator_new,trained_discriminator = train_gan(generator, discriminator, train_loader, num_epochs=num_epochs, lr=lr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T16:11:53.131858Z",
          "iopub.execute_input": "2024-02-03T16:11:53.132775Z",
          "iopub.status.idle": "2024-02-03T17:35:39.538779Z",
          "shell.execute_reply.started": "2024-02-03T16:11:53.132730Z",
          "shell.execute_reply": "2024-02-03T17:35:39.537449Z"
        },
        "trusted": true,
        "id": "ybdHzgnaXcmY",
        "outputId": "77bca4cb-2912-4c2c-d882-e5ce43282209"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch [0/100], Step [0/324], Discriminator Loss: 1.3888, Generator Loss: 0.7081\nEpoch [0/100], Step [10/324], Discriminator Loss: 1.3180, Generator Loss: 0.7796\nEpoch [0/100], Step [20/324], Discriminator Loss: 1.1860, Generator Loss: 0.9548\nEpoch [0/100], Step [30/324], Discriminator Loss: 0.9365, Generator Loss: 1.4415\nEpoch [0/100], Step [40/324], Discriminator Loss: 0.6005, Generator Loss: 2.4837\nEpoch [0/100], Step [50/324], Discriminator Loss: 0.4850, Generator Loss: 3.4934\nEpoch [0/100], Step [60/324], Discriminator Loss: 0.5054, Generator Loss: 3.8669\nEpoch [0/100], Step [70/324], Discriminator Loss: 0.2667, Generator Loss: 4.2028\nEpoch [0/100], Step [80/324], Discriminator Loss: 0.2270, Generator Loss: 4.7782\nEpoch [0/100], Step [90/324], Discriminator Loss: 0.1423, Generator Loss: 6.4534\nEpoch [0/100], Step [100/324], Discriminator Loss: 0.2986, Generator Loss: 6.2715\nEpoch [0/100], Step [110/324], Discriminator Loss: 0.1189, Generator Loss: 6.6884\nEpoch [0/100], Step [120/324], Discriminator Loss: 0.2690, Generator Loss: 10.3378\nEpoch [0/100], Step [130/324], Discriminator Loss: 0.2689, Generator Loss: 11.5952\nEpoch [0/100], Step [140/324], Discriminator Loss: 0.4347, Generator Loss: 10.9753\nEpoch [0/100], Step [150/324], Discriminator Loss: 0.3780, Generator Loss: 10.5973\nEpoch [0/100], Step [160/324], Discriminator Loss: 0.2313, Generator Loss: 13.2157\nEpoch [0/100], Step [170/324], Discriminator Loss: 0.9629, Generator Loss: 8.7138\nEpoch [0/100], Step [180/324], Discriminator Loss: 0.3052, Generator Loss: 12.3906\nEpoch [0/100], Step [190/324], Discriminator Loss: 0.2968, Generator Loss: 7.7362\nEpoch [0/100], Step [200/324], Discriminator Loss: 0.2336, Generator Loss: 9.7142\nEpoch [0/100], Step [210/324], Discriminator Loss: 0.1517, Generator Loss: 12.1526\nEpoch [0/100], Step [220/324], Discriminator Loss: 0.3133, Generator Loss: 6.3636\nEpoch [0/100], Step [230/324], Discriminator Loss: 0.1965, Generator Loss: 6.0718\nEpoch [0/100], Step [240/324], Discriminator Loss: 0.1976, Generator Loss: 7.6938\nEpoch [0/100], Step [250/324], Discriminator Loss: 0.3202, Generator Loss: 8.6631\nEpoch [0/100], Step [260/324], Discriminator Loss: 0.2799, Generator Loss: 10.5750\nEpoch [0/100], Step [270/324], Discriminator Loss: 0.1584, Generator Loss: 9.0136\nEpoch [0/100], Step [280/324], Discriminator Loss: 0.0837, Generator Loss: 14.1835\nEpoch [0/100], Step [290/324], Discriminator Loss: 0.2294, Generator Loss: 8.7065\nEpoch [0/100], Step [300/324], Discriminator Loss: 0.3499, Generator Loss: 13.3983\nEpoch [0/100], Step [310/324], Discriminator Loss: 0.2001, Generator Loss: 8.7669\nEpoch [0/100], Step [320/324], Discriminator Loss: 0.1538, Generator Loss: 7.7716\nEpoch [1/100], Step [0/324], Discriminator Loss: 0.1496, Generator Loss: 6.9538\nEpoch [1/100], Step [10/324], Discriminator Loss: 0.2919, Generator Loss: 4.8953\nEpoch [1/100], Step [20/324], Discriminator Loss: 0.3315, Generator Loss: 11.8232\nEpoch [1/100], Step [30/324], Discriminator Loss: 0.2332, Generator Loss: 7.8377\nEpoch [1/100], Step [40/324], Discriminator Loss: 0.1871, Generator Loss: 5.6991\nEpoch [1/100], Step [50/324], Discriminator Loss: 0.1187, Generator Loss: 9.1972\nEpoch [1/100], Step [60/324], Discriminator Loss: 0.0916, Generator Loss: 7.6297\nEpoch [1/100], Step [70/324], Discriminator Loss: 0.2048, Generator Loss: 9.3814\nEpoch [1/100], Step [80/324], Discriminator Loss: 0.1705, Generator Loss: 13.5996\nEpoch [1/100], Step [90/324], Discriminator Loss: 0.0420, Generator Loss: 8.9774\nEpoch [1/100], Step [100/324], Discriminator Loss: 0.1105, Generator Loss: 15.8386\nEpoch [1/100], Step [110/324], Discriminator Loss: 0.1951, Generator Loss: 13.3902\nEpoch [1/100], Step [120/324], Discriminator Loss: 0.0508, Generator Loss: 9.7473\nEpoch [1/100], Step [130/324], Discriminator Loss: 0.0968, Generator Loss: 6.2003\nEpoch [1/100], Step [140/324], Discriminator Loss: 0.1528, Generator Loss: 7.4316\nEpoch [1/100], Step [150/324], Discriminator Loss: 0.0975, Generator Loss: 7.8149\nEpoch [1/100], Step [160/324], Discriminator Loss: 0.0429, Generator Loss: 7.7460\nEpoch [1/100], Step [170/324], Discriminator Loss: 0.4232, Generator Loss: 18.8056\nEpoch [1/100], Step [180/324], Discriminator Loss: 0.0923, Generator Loss: 13.9735\nEpoch [1/100], Step [190/324], Discriminator Loss: 0.0569, Generator Loss: 8.2362\nEpoch [1/100], Step [200/324], Discriminator Loss: 0.1344, Generator Loss: 9.6757\nEpoch [1/100], Step [210/324], Discriminator Loss: 0.0582, Generator Loss: 9.4008\nEpoch [1/100], Step [220/324], Discriminator Loss: 0.0240, Generator Loss: 10.6346\nEpoch [1/100], Step [230/324], Discriminator Loss: 0.2678, Generator Loss: 12.6991\nEpoch [1/100], Step [240/324], Discriminator Loss: 0.0336, Generator Loss: 5.8621\nEpoch [1/100], Step [250/324], Discriminator Loss: 0.2504, Generator Loss: 11.4490\nEpoch [1/100], Step [260/324], Discriminator Loss: 0.1437, Generator Loss: 8.0974\nEpoch [1/100], Step [270/324], Discriminator Loss: 0.0592, Generator Loss: 7.1095\nEpoch [1/100], Step [280/324], Discriminator Loss: 0.0666, Generator Loss: 6.5070\nEpoch [1/100], Step [290/324], Discriminator Loss: 0.0571, Generator Loss: 6.1499\nEpoch [1/100], Step [300/324], Discriminator Loss: 0.0100, Generator Loss: 6.4172\nEpoch [1/100], Step [310/324], Discriminator Loss: 0.0738, Generator Loss: 6.6678\nEpoch [1/100], Step [320/324], Discriminator Loss: 0.0843, Generator Loss: 7.8581\nEpoch [2/100], Step [0/324], Discriminator Loss: 0.0381, Generator Loss: 6.5501\nEpoch [2/100], Step [10/324], Discriminator Loss: 0.0369, Generator Loss: 9.5471\nEpoch [2/100], Step [20/324], Discriminator Loss: 0.1226, Generator Loss: 7.3098\nEpoch [2/100], Step [30/324], Discriminator Loss: 0.0743, Generator Loss: 6.7059\nEpoch [2/100], Step [40/324], Discriminator Loss: 0.0220, Generator Loss: 7.5954\nEpoch [2/100], Step [50/324], Discriminator Loss: 0.0223, Generator Loss: 8.8984\nEpoch [2/100], Step [60/324], Discriminator Loss: 0.0503, Generator Loss: 7.1959\nEpoch [2/100], Step [70/324], Discriminator Loss: 0.0687, Generator Loss: 10.8993\nEpoch [2/100], Step [80/324], Discriminator Loss: 0.0585, Generator Loss: 8.5231\nEpoch [2/100], Step [90/324], Discriminator Loss: 0.1010, Generator Loss: 10.7877\nEpoch [2/100], Step [100/324], Discriminator Loss: 0.0442, Generator Loss: 10.5829\nEpoch [2/100], Step [110/324], Discriminator Loss: 0.0130, Generator Loss: 9.3442\nEpoch [2/100], Step [120/324], Discriminator Loss: 0.0446, Generator Loss: 7.8009\nEpoch [2/100], Step [130/324], Discriminator Loss: 0.1055, Generator Loss: 17.5846\nEpoch [2/100], Step [140/324], Discriminator Loss: 0.1839, Generator Loss: 15.1354\nEpoch [2/100], Step [150/324], Discriminator Loss: 0.1109, Generator Loss: 11.3911\nEpoch [2/100], Step [160/324], Discriminator Loss: 0.0412, Generator Loss: 9.0482\nEpoch [2/100], Step [170/324], Discriminator Loss: 0.0358, Generator Loss: 7.8708\nEpoch [2/100], Step [180/324], Discriminator Loss: 0.0330, Generator Loss: 9.1125\nEpoch [2/100], Step [190/324], Discriminator Loss: 0.0220, Generator Loss: 7.6979\nEpoch [2/100], Step [200/324], Discriminator Loss: 0.0359, Generator Loss: 9.8725\nEpoch [2/100], Step [210/324], Discriminator Loss: 0.1304, Generator Loss: 7.3393\nEpoch [2/100], Step [220/324], Discriminator Loss: 0.1281, Generator Loss: 8.0194\nEpoch [2/100], Step [230/324], Discriminator Loss: 0.0646, Generator Loss: 7.9194\nEpoch [2/100], Step [240/324], Discriminator Loss: 0.0470, Generator Loss: 7.4717\nEpoch [2/100], Step [250/324], Discriminator Loss: 0.1492, Generator Loss: 9.0413\nEpoch [2/100], Step [260/324], Discriminator Loss: 0.0870, Generator Loss: 9.9935\nEpoch [2/100], Step [270/324], Discriminator Loss: 0.0477, Generator Loss: 11.7822\nEpoch [2/100], Step [280/324], Discriminator Loss: 0.0522, Generator Loss: 9.4673\nEpoch [2/100], Step [290/324], Discriminator Loss: 0.0410, Generator Loss: 5.5452\nEpoch [2/100], Step [300/324], Discriminator Loss: 0.0317, Generator Loss: 8.4473\nEpoch [2/100], Step [310/324], Discriminator Loss: 0.0293, Generator Loss: 8.8915\nEpoch [2/100], Step [320/324], Discriminator Loss: 0.0444, Generator Loss: 6.9575\nEpoch [3/100], Step [0/324], Discriminator Loss: 0.0665, Generator Loss: 5.3829\nEpoch [3/100], Step [10/324], Discriminator Loss: 0.0700, Generator Loss: 7.0067\nEpoch [3/100], Step [20/324], Discriminator Loss: 0.0122, Generator Loss: 7.5791\nEpoch [3/100], Step [30/324], Discriminator Loss: 0.0235, Generator Loss: 8.2957\nEpoch [3/100], Step [40/324], Discriminator Loss: 0.0272, Generator Loss: 11.0341\nEpoch [3/100], Step [50/324], Discriminator Loss: 0.0910, Generator Loss: 9.4603\nEpoch [3/100], Step [60/324], Discriminator Loss: 0.0322, Generator Loss: 8.8472\nEpoch [3/100], Step [70/324], Discriminator Loss: 0.2469, Generator Loss: 10.2593\nEpoch [3/100], Step [80/324], Discriminator Loss: 1.0179, Generator Loss: 9.7235\nEpoch [3/100], Step [90/324], Discriminator Loss: 0.0467, Generator Loss: 9.4739\nEpoch [3/100], Step [100/324], Discriminator Loss: 0.0271, Generator Loss: 6.9932\nEpoch [3/100], Step [110/324], Discriminator Loss: 0.0160, Generator Loss: 9.3904\nEpoch [3/100], Step [120/324], Discriminator Loss: 0.0979, Generator Loss: 10.2990\nEpoch [3/100], Step [130/324], Discriminator Loss: 0.7197, Generator Loss: 5.8811\nEpoch [3/100], Step [140/324], Discriminator Loss: 0.0422, Generator Loss: 5.5072\nEpoch [3/100], Step [150/324], Discriminator Loss: 0.0090, Generator Loss: 5.4791\nEpoch [3/100], Step [160/324], Discriminator Loss: 0.0816, Generator Loss: 6.0638\nEpoch [3/100], Step [170/324], Discriminator Loss: 0.0776, Generator Loss: 6.3730\nEpoch [3/100], Step [180/324], Discriminator Loss: 0.0184, Generator Loss: 6.7162\nEpoch [3/100], Step [190/324], Discriminator Loss: 0.0130, Generator Loss: 5.6608\nEpoch [3/100], Step [200/324], Discriminator Loss: 0.0500, Generator Loss: 5.9676\nEpoch [3/100], Step [210/324], Discriminator Loss: 0.0320, Generator Loss: 5.9526\nEpoch [3/100], Step [220/324], Discriminator Loss: 0.0577, Generator Loss: 4.3142\nEpoch [3/100], Step [230/324], Discriminator Loss: 0.0194, Generator Loss: 7.4281\nEpoch [3/100], Step [240/324], Discriminator Loss: 0.0321, Generator Loss: 7.0552\nEpoch [3/100], Step [250/324], Discriminator Loss: 0.0064, Generator Loss: 6.2524\nEpoch [3/100], Step [260/324], Discriminator Loss: 0.0742, Generator Loss: 5.4871\nEpoch [3/100], Step [270/324], Discriminator Loss: 0.0803, Generator Loss: 7.8556\nEpoch [3/100], Step [280/324], Discriminator Loss: 0.0088, Generator Loss: 5.8679\nEpoch [3/100], Step [290/324], Discriminator Loss: 0.0040, Generator Loss: 6.9792\nEpoch [3/100], Step [300/324], Discriminator Loss: 0.0044, Generator Loss: 6.4181\nEpoch [3/100], Step [310/324], Discriminator Loss: 0.0180, Generator Loss: 6.4606\nEpoch [3/100], Step [320/324], Discriminator Loss: 0.0040, Generator Loss: 6.2122\nEpoch [4/100], Step [0/324], Discriminator Loss: 0.0052, Generator Loss: 5.9949\nEpoch [4/100], Step [10/324], Discriminator Loss: 0.1321, Generator Loss: 7.2732\nEpoch [4/100], Step [20/324], Discriminator Loss: 0.0064, Generator Loss: 8.0851\nEpoch [4/100], Step [30/324], Discriminator Loss: 0.0562, Generator Loss: 6.6151\nEpoch [4/100], Step [40/324], Discriminator Loss: 0.0035, Generator Loss: 7.2706\nEpoch [4/100], Step [50/324], Discriminator Loss: 0.0525, Generator Loss: 6.0614\nEpoch [4/100], Step [60/324], Discriminator Loss: 0.0877, Generator Loss: 8.0191\nEpoch [4/100], Step [70/324], Discriminator Loss: 0.0392, Generator Loss: 8.2116\nEpoch [4/100], Step [80/324], Discriminator Loss: 0.0084, Generator Loss: 8.2199\nEpoch [4/100], Step [90/324], Discriminator Loss: 0.1921, Generator Loss: 10.8908\nEpoch [4/100], Step [100/324], Discriminator Loss: 0.2136, Generator Loss: 18.2353\nEpoch [4/100], Step [110/324], Discriminator Loss: 0.2118, Generator Loss: 14.4036\nEpoch [4/100], Step [120/324], Discriminator Loss: 0.0542, Generator Loss: 11.2512\nEpoch [4/100], Step [130/324], Discriminator Loss: 0.0058, Generator Loss: 9.2288\nEpoch [4/100], Step [140/324], Discriminator Loss: 0.0201, Generator Loss: 7.1838\nEpoch [4/100], Step [150/324], Discriminator Loss: 0.0064, Generator Loss: 4.9777\nEpoch [4/100], Step [160/324], Discriminator Loss: 0.1241, Generator Loss: 7.7360\nEpoch [4/100], Step [170/324], Discriminator Loss: 0.0960, Generator Loss: 5.9518\nEpoch [4/100], Step [180/324], Discriminator Loss: 0.0108, Generator Loss: 6.7659\nEpoch [4/100], Step [190/324], Discriminator Loss: 0.0039, Generator Loss: 6.3788\nEpoch [4/100], Step [200/324], Discriminator Loss: 0.0025, Generator Loss: 6.7057\nEpoch [4/100], Step [210/324], Discriminator Loss: 0.0085, Generator Loss: 7.3522\nEpoch [4/100], Step [220/324], Discriminator Loss: 0.0302, Generator Loss: 9.3838\nEpoch [4/100], Step [230/324], Discriminator Loss: 0.0200, Generator Loss: 7.3634\nEpoch [4/100], Step [240/324], Discriminator Loss: 0.0264, Generator Loss: 10.9680\nEpoch [4/100], Step [250/324], Discriminator Loss: 0.0475, Generator Loss: 10.7491\nEpoch [4/100], Step [260/324], Discriminator Loss: 0.0035, Generator Loss: 10.4359\nEpoch [4/100], Step [270/324], Discriminator Loss: 0.0094, Generator Loss: 9.2161\nEpoch [4/100], Step [280/324], Discriminator Loss: 0.1438, Generator Loss: 15.4132\nEpoch [4/100], Step [290/324], Discriminator Loss: 0.0071, Generator Loss: 11.7061\nEpoch [4/100], Step [300/324], Discriminator Loss: 0.0335, Generator Loss: 7.3150\nEpoch [4/100], Step [310/324], Discriminator Loss: 0.0187, Generator Loss: 8.7210\nEpoch [4/100], Step [320/324], Discriminator Loss: 0.0690, Generator Loss: 10.8214\nEpoch [5/100], Step [0/324], Discriminator Loss: 0.0197, Generator Loss: 16.2793\nEpoch [5/100], Step [10/324], Discriminator Loss: 0.2566, Generator Loss: 7.8836\nEpoch [5/100], Step [20/324], Discriminator Loss: 0.0651, Generator Loss: 14.1489\nEpoch [5/100], Step [30/324], Discriminator Loss: 0.0039, Generator Loss: 11.6950\nEpoch [5/100], Step [40/324], Discriminator Loss: 0.0049, Generator Loss: 10.0173\nEpoch [5/100], Step [50/324], Discriminator Loss: 0.0018, Generator Loss: 6.0380\nEpoch [5/100], Step [60/324], Discriminator Loss: 0.0249, Generator Loss: 7.9726\nEpoch [5/100], Step [70/324], Discriminator Loss: 0.0013, Generator Loss: 7.8987\nEpoch [5/100], Step [80/324], Discriminator Loss: 0.0034, Generator Loss: 6.5260\nEpoch [5/100], Step [90/324], Discriminator Loss: 0.0006, Generator Loss: 7.2463\nEpoch [5/100], Step [100/324], Discriminator Loss: 0.0102, Generator Loss: 7.5433\nEpoch [5/100], Step [110/324], Discriminator Loss: 0.0029, Generator Loss: 7.2338\nEpoch [5/100], Step [120/324], Discriminator Loss: 0.0183, Generator Loss: 7.4283\nEpoch [5/100], Step [130/324], Discriminator Loss: 0.0115, Generator Loss: 8.4585\nEpoch [5/100], Step [140/324], Discriminator Loss: 0.1778, Generator Loss: 7.5162\nEpoch [5/100], Step [150/324], Discriminator Loss: 0.0304, Generator Loss: 12.9197\nEpoch [5/100], Step [170/324], Discriminator Loss: 0.0129, Generator Loss: 7.7075\nEpoch [5/100], Step [180/324], Discriminator Loss: 0.0108, Generator Loss: 5.7126\nEpoch [5/100], Step [190/324], Discriminator Loss: 0.0040, Generator Loss: 6.7638\nEpoch [5/100], Step [200/324], Discriminator Loss: 0.0129, Generator Loss: 8.2551\nEpoch [5/100], Step [210/324], Discriminator Loss: 0.0831, Generator Loss: 7.4377\nEpoch [5/100], Step [220/324], Discriminator Loss: 0.0356, Generator Loss: 9.0064\nEpoch [5/100], Step [230/324], Discriminator Loss: 0.0034, Generator Loss: 8.6056\nEpoch [5/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 7.4260\nEpoch [5/100], Step [250/324], Discriminator Loss: 0.0033, Generator Loss: 9.9529\nEpoch [5/100], Step [260/324], Discriminator Loss: 0.0013, Generator Loss: 6.4347\nEpoch [5/100], Step [270/324], Discriminator Loss: 0.0062, Generator Loss: 10.4381\nEpoch [5/100], Step [280/324], Discriminator Loss: 0.3089, Generator Loss: 15.7480\nEpoch [5/100], Step [290/324], Discriminator Loss: 0.0085, Generator Loss: 12.7758\nEpoch [5/100], Step [300/324], Discriminator Loss: 0.0533, Generator Loss: 5.8809\nEpoch [5/100], Step [310/324], Discriminator Loss: 0.0584, Generator Loss: 3.6425\nEpoch [5/100], Step [320/324], Discriminator Loss: 0.0020, Generator Loss: 11.8712\nEpoch [6/100], Step [0/324], Discriminator Loss: 0.0025, Generator Loss: 10.5482\nEpoch [6/100], Step [10/324], Discriminator Loss: 0.0280, Generator Loss: 7.5964\nEpoch [6/100], Step [20/324], Discriminator Loss: 0.0016, Generator Loss: 6.1367\nEpoch [6/100], Step [30/324], Discriminator Loss: 0.0040, Generator Loss: 5.9862\nEpoch [6/100], Step [40/324], Discriminator Loss: 0.0455, Generator Loss: 7.1916\nEpoch [6/100], Step [50/324], Discriminator Loss: 0.0013, Generator Loss: 10.0022\nEpoch [6/100], Step [60/324], Discriminator Loss: 0.0820, Generator Loss: 11.1061\nEpoch [6/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 9.2004\nEpoch [6/100], Step [80/324], Discriminator Loss: 0.0006, Generator Loss: 7.1037\nEpoch [6/100], Step [90/324], Discriminator Loss: 1.5716, Generator Loss: 16.3579\nEpoch [6/100], Step [100/324], Discriminator Loss: 0.0924, Generator Loss: 13.7693\nEpoch [6/100], Step [110/324], Discriminator Loss: 0.0010, Generator Loss: 11.6634\nEpoch [6/100], Step [120/324], Discriminator Loss: 0.0152, Generator Loss: 9.9148\nEpoch [6/100], Step [130/324], Discriminator Loss: 0.0901, Generator Loss: 7.6847\nEpoch [6/100], Step [140/324], Discriminator Loss: 0.0080, Generator Loss: 5.7742\nEpoch [6/100], Step [150/324], Discriminator Loss: 0.0395, Generator Loss: 6.1667\nEpoch [6/100], Step [160/324], Discriminator Loss: 0.0723, Generator Loss: 6.3946\nEpoch [6/100], Step [170/324], Discriminator Loss: 0.0015, Generator Loss: 6.2787\nEpoch [6/100], Step [180/324], Discriminator Loss: 0.0369, Generator Loss: 7.0093\nEpoch [6/100], Step [190/324], Discriminator Loss: 0.0036, Generator Loss: 6.4971\nEpoch [6/100], Step [200/324], Discriminator Loss: 0.0141, Generator Loss: 7.2585\nEpoch [6/100], Step [210/324], Discriminator Loss: 0.0647, Generator Loss: 7.6565\nEpoch [6/100], Step [220/324], Discriminator Loss: 0.0039, Generator Loss: 8.1328\nEpoch [6/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 8.2789\nEpoch [6/100], Step [240/324], Discriminator Loss: 0.1051, Generator Loss: 12.1062\nEpoch [6/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 7.9293\nEpoch [6/100], Step [260/324], Discriminator Loss: 0.0012, Generator Loss: 16.8492\nEpoch [6/100], Step [270/324], Discriminator Loss: 0.0430, Generator Loss: 14.3549\nEpoch [6/100], Step [280/324], Discriminator Loss: 0.0357, Generator Loss: 9.7462\nEpoch [6/100], Step [290/324], Discriminator Loss: 0.0005, Generator Loss: 7.7817\nEpoch [6/100], Step [300/324], Discriminator Loss: 0.0027, Generator Loss: 8.2495\nEpoch [6/100], Step [310/324], Discriminator Loss: 0.2020, Generator Loss: 12.6585\nEpoch [6/100], Step [320/324], Discriminator Loss: 0.0012, Generator Loss: 8.4105\nEpoch [7/100], Step [0/324], Discriminator Loss: 0.0008, Generator Loss: 11.0781\nEpoch [7/100], Step [10/324], Discriminator Loss: 0.2274, Generator Loss: 6.1462\nEpoch [7/100], Step [20/324], Discriminator Loss: 0.0297, Generator Loss: 5.7281\nEpoch [7/100], Step [30/324], Discriminator Loss: 0.0019, Generator Loss: 7.3317\nEpoch [7/100], Step [40/324], Discriminator Loss: 0.0133, Generator Loss: 5.9275\nEpoch [7/100], Step [50/324], Discriminator Loss: 0.0733, Generator Loss: 8.2278\nEpoch [7/100], Step [60/324], Discriminator Loss: 0.0004, Generator Loss: 10.6643\nEpoch [7/100], Step [70/324], Discriminator Loss: 0.0926, Generator Loss: 5.4834\nEpoch [7/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 9.7140\nEpoch [7/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 8.2595\nEpoch [7/100], Step [100/324], Discriminator Loss: 0.0008, Generator Loss: 11.0075\nEpoch [7/100], Step [110/324], Discriminator Loss: 0.0074, Generator Loss: 13.7415\nEpoch [7/100], Step [120/324], Discriminator Loss: 0.0345, Generator Loss: 7.2089\nEpoch [7/100], Step [130/324], Discriminator Loss: 0.0968, Generator Loss: 7.5193\nEpoch [7/100], Step [140/324], Discriminator Loss: 0.0006, Generator Loss: 9.6156\nEpoch [7/100], Step [150/324], Discriminator Loss: 0.1656, Generator Loss: 12.1333\nEpoch [7/100], Step [160/324], Discriminator Loss: 0.0089, Generator Loss: 6.3050\nEpoch [7/100], Step [170/324], Discriminator Loss: 0.0477, Generator Loss: 7.8261\nEpoch [7/100], Step [180/324], Discriminator Loss: 0.0350, Generator Loss: 6.3347\nEpoch [7/100], Step [190/324], Discriminator Loss: 0.0036, Generator Loss: 7.1493\nEpoch [7/100], Step [200/324], Discriminator Loss: 0.0468, Generator Loss: 6.0594\nEpoch [7/100], Step [210/324], Discriminator Loss: 0.0344, Generator Loss: 5.0338\nEpoch [7/100], Step [220/324], Discriminator Loss: 0.0106, Generator Loss: 8.8998\nEpoch [7/100], Step [230/324], Discriminator Loss: 0.0083, Generator Loss: 6.6733\nEpoch [7/100], Step [240/324], Discriminator Loss: 0.2803, Generator Loss: 3.5582\nEpoch [7/100], Step [250/324], Discriminator Loss: 0.0005, Generator Loss: 10.6800\nEpoch [7/100], Step [260/324], Discriminator Loss: 0.0073, Generator Loss: 7.2144\nEpoch [7/100], Step [270/324], Discriminator Loss: 0.0203, Generator Loss: 7.0641\nEpoch [7/100], Step [280/324], Discriminator Loss: 0.3719, Generator Loss: 8.2564\nEpoch [7/100], Step [290/324], Discriminator Loss: 0.0048, Generator Loss: 6.0392\nEpoch [7/100], Step [300/324], Discriminator Loss: 0.0004, Generator Loss: 6.8765\nEpoch [7/100], Step [310/324], Discriminator Loss: 0.0049, Generator Loss: 7.6617\nEpoch [7/100], Step [320/324], Discriminator Loss: 0.0190, Generator Loss: 7.6941\nEpoch [8/100], Step [0/324], Discriminator Loss: 0.0066, Generator Loss: 8.5957\nEpoch [8/100], Step [10/324], Discriminator Loss: 0.0867, Generator Loss: 9.5121\nEpoch [8/100], Step [20/324], Discriminator Loss: 0.0220, Generator Loss: 4.4449\nEpoch [8/100], Step [30/324], Discriminator Loss: 0.0132, Generator Loss: 5.9785\nEpoch [8/100], Step [40/324], Discriminator Loss: 0.0038, Generator Loss: 5.0641\nEpoch [8/100], Step [50/324], Discriminator Loss: 0.0011, Generator Loss: 3.0806\nEpoch [8/100], Step [60/324], Discriminator Loss: 0.0074, Generator Loss: 5.8490\nEpoch [8/100], Step [70/324], Discriminator Loss: 0.0066, Generator Loss: 7.4078\nEpoch [8/100], Step [80/324], Discriminator Loss: 0.0010, Generator Loss: 5.4432\nEpoch [8/100], Step [90/324], Discriminator Loss: 0.0005, Generator Loss: 6.5140\nEpoch [8/100], Step [100/324], Discriminator Loss: 0.1274, Generator Loss: 9.4733\nEpoch [8/100], Step [110/324], Discriminator Loss: 0.0007, Generator Loss: 6.3642\nEpoch [8/100], Step [120/324], Discriminator Loss: 0.0056, Generator Loss: 7.3697\nEpoch [8/100], Step [130/324], Discriminator Loss: 0.0561, Generator Loss: 7.2593\nEpoch [8/100], Step [140/324], Discriminator Loss: 0.0059, Generator Loss: 8.9795\nEpoch [8/100], Step [150/324], Discriminator Loss: 0.0162, Generator Loss: 3.2104\nEpoch [8/100], Step [160/324], Discriminator Loss: 0.1656, Generator Loss: 11.3086\nEpoch [8/100], Step [170/324], Discriminator Loss: 0.0255, Generator Loss: 5.4064\nEpoch [8/100], Step [180/324], Discriminator Loss: 0.0060, Generator Loss: 4.9710\nEpoch [8/100], Step [190/324], Discriminator Loss: 0.0034, Generator Loss: 8.3270\nEpoch [8/100], Step [200/324], Discriminator Loss: 0.0924, Generator Loss: 5.6770\nEpoch [8/100], Step [210/324], Discriminator Loss: 0.0015, Generator Loss: 5.6297\nEpoch [8/100], Step [220/324], Discriminator Loss: 0.1670, Generator Loss: 4.4587\nEpoch [8/100], Step [230/324], Discriminator Loss: 0.0251, Generator Loss: 5.6528\nEpoch [8/100], Step [240/324], Discriminator Loss: 0.3325, Generator Loss: 8.7999\nEpoch [8/100], Step [250/324], Discriminator Loss: 0.2554, Generator Loss: 10.0908\nEpoch [8/100], Step [260/324], Discriminator Loss: 0.2158, Generator Loss: 3.7781\nEpoch [8/100], Step [270/324], Discriminator Loss: 0.1013, Generator Loss: 4.2869\nEpoch [8/100], Step [280/324], Discriminator Loss: 0.0151, Generator Loss: 4.2678\nEpoch [8/100], Step [290/324], Discriminator Loss: 0.0008, Generator Loss: 5.1088\nEpoch [8/100], Step [300/324], Discriminator Loss: 0.1278, Generator Loss: 5.0948\nEpoch [8/100], Step [310/324], Discriminator Loss: 0.0005, Generator Loss: 4.3286\nEpoch [8/100], Step [320/324], Discriminator Loss: 0.0025, Generator Loss: 5.1471\nEpoch [9/100], Step [0/324], Discriminator Loss: 0.0046, Generator Loss: 4.4524\nEpoch [9/100], Step [10/324], Discriminator Loss: 0.0012, Generator Loss: 5.6242\nEpoch [9/100], Step [20/324], Discriminator Loss: 0.1212, Generator Loss: 3.9222\nEpoch [9/100], Step [30/324], Discriminator Loss: 0.0169, Generator Loss: 4.0353\nEpoch [9/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 6.8250\nEpoch [9/100], Step [50/324], Discriminator Loss: 0.0114, Generator Loss: 6.7814\nEpoch [9/100], Step [60/324], Discriminator Loss: 0.0757, Generator Loss: 7.6304\nEpoch [9/100], Step [70/324], Discriminator Loss: 0.0021, Generator Loss: 6.6645\nEpoch [9/100], Step [80/324], Discriminator Loss: 0.0595, Generator Loss: 8.2652\nEpoch [9/100], Step [90/324], Discriminator Loss: 0.1297, Generator Loss: 7.7966\nEpoch [9/100], Step [100/324], Discriminator Loss: 0.0187, Generator Loss: 2.0251\nEpoch [9/100], Step [110/324], Discriminator Loss: 0.0021, Generator Loss: 9.8733\nEpoch [9/100], Step [120/324], Discriminator Loss: 0.0623, Generator Loss: 2.6881\nEpoch [9/100], Step [130/324], Discriminator Loss: 0.0990, Generator Loss: 5.1222\nEpoch [9/100], Step [140/324], Discriminator Loss: 0.0168, Generator Loss: 3.6516\nEpoch [9/100], Step [150/324], Discriminator Loss: 0.0425, Generator Loss: 4.6252\nEpoch [9/100], Step [160/324], Discriminator Loss: 0.0355, Generator Loss: 6.3547\nEpoch [9/100], Step [170/324], Discriminator Loss: 0.0024, Generator Loss: 3.8288\nEpoch [9/100], Step [180/324], Discriminator Loss: 0.5021, Generator Loss: 5.3598\nEpoch [9/100], Step [190/324], Discriminator Loss: 0.0008, Generator Loss: 3.9210\nEpoch [9/100], Step [200/324], Discriminator Loss: 0.0411, Generator Loss: 4.1941\nEpoch [9/100], Step [210/324], Discriminator Loss: 0.0013, Generator Loss: 5.2573\nEpoch [9/100], Step [220/324], Discriminator Loss: 0.0045, Generator Loss: 5.3090\nEpoch [9/100], Step [230/324], Discriminator Loss: 0.0012, Generator Loss: 3.9901\nEpoch [9/100], Step [240/324], Discriminator Loss: 0.2338, Generator Loss: 6.9061\nEpoch [9/100], Step [250/324], Discriminator Loss: 0.0050, Generator Loss: 3.6286\nEpoch [9/100], Step [260/324], Discriminator Loss: 0.0012, Generator Loss: 3.9879\nEpoch [9/100], Step [270/324], Discriminator Loss: 0.0025, Generator Loss: 6.4382\nEpoch [9/100], Step [280/324], Discriminator Loss: 0.0076, Generator Loss: 3.9909\nEpoch [9/100], Step [290/324], Discriminator Loss: 0.0663, Generator Loss: 5.7607\nEpoch [9/100], Step [300/324], Discriminator Loss: 0.0008, Generator Loss: 6.1366\nEpoch [9/100], Step [310/324], Discriminator Loss: 0.0029, Generator Loss: 3.3438\nEpoch [9/100], Step [320/324], Discriminator Loss: 0.0043, Generator Loss: 4.8780\nEpoch [10/100], Step [0/324], Discriminator Loss: 0.2846, Generator Loss: 3.9141\nEpoch [10/100], Step [10/324], Discriminator Loss: 0.0349, Generator Loss: 3.9039\nEpoch [10/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.3124\nEpoch [10/100], Step [30/324], Discriminator Loss: 0.0015, Generator Loss: 5.3080\nEpoch [10/100], Step [40/324], Discriminator Loss: 0.0007, Generator Loss: 4.5627\nEpoch [10/100], Step [50/324], Discriminator Loss: 0.0245, Generator Loss: 5.9183\nEpoch [10/100], Step [60/324], Discriminator Loss: 0.0253, Generator Loss: 6.5354\nEpoch [10/100], Step [70/324], Discriminator Loss: 1.5627, Generator Loss: 7.9554\nEpoch [10/100], Step [80/324], Discriminator Loss: 0.1633, Generator Loss: 7.4876\nEpoch [10/100], Step [90/324], Discriminator Loss: 0.0464, Generator Loss: 3.3455\nEpoch [10/100], Step [100/324], Discriminator Loss: 0.2421, Generator Loss: 6.3570\nEpoch [10/100], Step [110/324], Discriminator Loss: 0.0392, Generator Loss: 3.3482\nEpoch [10/100], Step [120/324], Discriminator Loss: 0.3013, Generator Loss: 4.7804\nEpoch [10/100], Step [130/324], Discriminator Loss: 0.0007, Generator Loss: 4.6359\nEpoch [10/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 5.5187\nEpoch [10/100], Step [150/324], Discriminator Loss: 0.0642, Generator Loss: 5.4569\nEpoch [10/100], Step [160/324], Discriminator Loss: 0.0184, Generator Loss: 3.4874\nEpoch [10/100], Step [170/324], Discriminator Loss: 0.0937, Generator Loss: 4.2715\nEpoch [10/100], Step [180/324], Discriminator Loss: 0.4085, Generator Loss: 9.1571\nEpoch [10/100], Step [190/324], Discriminator Loss: 0.0030, Generator Loss: 3.4622\nEpoch [10/100], Step [200/324], Discriminator Loss: 0.0227, Generator Loss: 4.5316\nEpoch [10/100], Step [210/324], Discriminator Loss: 0.0571, Generator Loss: 4.7301\nEpoch [10/100], Step [220/324], Discriminator Loss: 0.0067, Generator Loss: 4.8639\nEpoch [10/100], Step [230/324], Discriminator Loss: 0.0357, Generator Loss: 3.4720\nEpoch [10/100], Step [240/324], Discriminator Loss: 0.2127, Generator Loss: 9.6045\nEpoch [10/100], Step [250/324], Discriminator Loss: 0.0030, Generator Loss: 5.5433\nEpoch [10/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 5.3482\nEpoch [10/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 4.2343\nEpoch [10/100], Step [280/324], Discriminator Loss: 0.0174, Generator Loss: 4.4828\nEpoch [10/100], Step [290/324], Discriminator Loss: 0.0012, Generator Loss: 4.0708\nEpoch [10/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 5.2855\nEpoch [10/100], Step [310/324], Discriminator Loss: 0.0868, Generator Loss: 6.5282\nEpoch [10/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 4.0883\nEpoch [11/100], Step [0/324], Discriminator Loss: 0.4900, Generator Loss: 4.8853\nEpoch [11/100], Step [10/324], Discriminator Loss: 0.0249, Generator Loss: 4.4994\nEpoch [11/100], Step [20/324], Discriminator Loss: 0.1672, Generator Loss: 3.9736\nEpoch [11/100], Step [30/324], Discriminator Loss: 0.0004, Generator Loss: 4.2605\nEpoch [11/100], Step [40/324], Discriminator Loss: 0.0016, Generator Loss: 4.6494\nEpoch [11/100], Step [50/324], Discriminator Loss: 0.1358, Generator Loss: 4.9020\nEpoch [11/100], Step [60/324], Discriminator Loss: 0.0007, Generator Loss: 4.5570\nEpoch [11/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 4.4800\nEpoch [11/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 5.1685\nEpoch [11/100], Step [90/324], Discriminator Loss: 0.0007, Generator Loss: 5.3788\nEpoch [11/100], Step [100/324], Discriminator Loss: 0.0048, Generator Loss: 5.0901\nEpoch [11/100], Step [110/324], Discriminator Loss: 0.0002, Generator Loss: 5.3724\nEpoch [11/100], Step [120/324], Discriminator Loss: 0.3119, Generator Loss: 5.3928\nEpoch [11/100], Step [130/324], Discriminator Loss: 0.4205, Generator Loss: 2.6446\nEpoch [11/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 8.6014\nEpoch [11/100], Step [150/324], Discriminator Loss: 0.0004, Generator Loss: 4.5696\nEpoch [11/100], Step [160/324], Discriminator Loss: 0.0003, Generator Loss: 4.3699\nEpoch [11/100], Step [170/324], Discriminator Loss: 0.0174, Generator Loss: 4.7723\nEpoch [11/100], Step [180/324], Discriminator Loss: 0.0718, Generator Loss: 4.8389\nEpoch [11/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 5.3769\nEpoch [11/100], Step [200/324], Discriminator Loss: 0.0024, Generator Loss: 5.6460\nEpoch [11/100], Step [210/324], Discriminator Loss: 0.3056, Generator Loss: 7.0824\nEpoch [11/100], Step [220/324], Discriminator Loss: 0.1495, Generator Loss: 5.5620\nEpoch [11/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.3829\nEpoch [11/100], Step [240/324], Discriminator Loss: 0.0430, Generator Loss: 3.9286\nEpoch [11/100], Step [250/324], Discriminator Loss: 0.0183, Generator Loss: 5.0772\nEpoch [11/100], Step [260/324], Discriminator Loss: 0.2080, Generator Loss: 6.4481\nEpoch [11/100], Step [270/324], Discriminator Loss: 0.0558, Generator Loss: 3.8353\nEpoch [11/100], Step [280/324], Discriminator Loss: 0.0005, Generator Loss: 4.8413\nEpoch [11/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 10.0759\nEpoch [11/100], Step [300/324], Discriminator Loss: 0.2558, Generator Loss: 6.1318\nEpoch [11/100], Step [310/324], Discriminator Loss: 0.0055, Generator Loss: 5.1827\nEpoch [11/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 4.0456\nEpoch [12/100], Step [0/324], Discriminator Loss: 0.0624, Generator Loss: 4.1707\nEpoch [12/100], Step [10/324], Discriminator Loss: 0.1990, Generator Loss: 2.3141\nEpoch [12/100], Step [20/324], Discriminator Loss: 0.0607, Generator Loss: 3.7280\nEpoch [12/100], Step [30/324], Discriminator Loss: 0.0151, Generator Loss: 6.2582\nEpoch [12/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 4.5774\nEpoch [12/100], Step [50/324], Discriminator Loss: 0.0089, Generator Loss: 4.2026\nEpoch [12/100], Step [60/324], Discriminator Loss: 0.2342, Generator Loss: 5.8720\nEpoch [12/100], Step [70/324], Discriminator Loss: 0.0413, Generator Loss: 3.6355\nEpoch [12/100], Step [80/324], Discriminator Loss: 0.0004, Generator Loss: 5.9585\nEpoch [12/100], Step [90/324], Discriminator Loss: 0.2234, Generator Loss: 5.8212\nEpoch [12/100], Step [100/324], Discriminator Loss: 0.0269, Generator Loss: 5.4902\nEpoch [12/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 5.3246\nEpoch [12/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 8.2184\nEpoch [12/100], Step [130/324], Discriminator Loss: 0.1993, Generator Loss: 4.7685\nEpoch [12/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 5.0133\nEpoch [12/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 5.7848\nEpoch [12/100], Step [160/324], Discriminator Loss: 0.0050, Generator Loss: 5.3385\nEpoch [12/100], Step [170/324], Discriminator Loss: 0.0244, Generator Loss: 4.9501\nEpoch [12/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 7.7206\nEpoch [12/100], Step [190/324], Discriminator Loss: 0.0654, Generator Loss: 5.3139\nEpoch [12/100], Step [200/324], Discriminator Loss: 0.0326, Generator Loss: 4.3997\nEpoch [12/100], Step [210/324], Discriminator Loss: 0.0005, Generator Loss: 3.9652\nEpoch [12/100], Step [220/324], Discriminator Loss: 0.1557, Generator Loss: 5.4604\nEpoch [12/100], Step [230/324], Discriminator Loss: 0.0004, Generator Loss: 5.0706\nEpoch [12/100], Step [240/324], Discriminator Loss: 0.0137, Generator Loss: 4.9518\nEpoch [12/100], Step [250/324], Discriminator Loss: 0.0083, Generator Loss: 4.5676\nEpoch [12/100], Step [260/324], Discriminator Loss: 0.0055, Generator Loss: 7.1386\nEpoch [12/100], Step [270/324], Discriminator Loss: 0.0021, Generator Loss: 5.6120\nEpoch [12/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.9183\nEpoch [12/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 5.3784\nEpoch [12/100], Step [300/324], Discriminator Loss: 0.0255, Generator Loss: 7.9912\nEpoch [12/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 10.1223\nEpoch [12/100], Step [320/324], Discriminator Loss: 0.0700, Generator Loss: 5.4361\nEpoch [13/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 7.1006\nEpoch [13/100], Step [10/324], Discriminator Loss: 0.0016, Generator Loss: 4.3288\nEpoch [13/100], Step [20/324], Discriminator Loss: 0.0004, Generator Loss: 5.0997\nEpoch [13/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.9901\nEpoch [13/100], Step [40/324], Discriminator Loss: 0.2489, Generator Loss: 4.5445\nEpoch [13/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.5900\nEpoch [13/100], Step [60/324], Discriminator Loss: 0.1499, Generator Loss: 3.8007\nEpoch [13/100], Step [70/324], Discriminator Loss: 0.0003, Generator Loss: 3.9869\nEpoch [13/100], Step [80/324], Discriminator Loss: 0.0006, Generator Loss: 4.8997\nEpoch [13/100], Step [90/324], Discriminator Loss: 0.0005, Generator Loss: 5.1271\nEpoch [13/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 5.0325\nEpoch [13/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 5.6665\nEpoch [13/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 5.1214\nEpoch [13/100], Step [130/324], Discriminator Loss: 0.0193, Generator Loss: 4.9506\nEpoch [13/100], Step [140/324], Discriminator Loss: 0.0573, Generator Loss: 5.5713\nEpoch [13/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 5.8319\nEpoch [13/100], Step [160/324], Discriminator Loss: 0.1869, Generator Loss: 4.1952\nEpoch [13/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.7697\nEpoch [13/100], Step [180/324], Discriminator Loss: 0.1914, Generator Loss: 5.7761\nEpoch [13/100], Step [190/324], Discriminator Loss: 0.1106, Generator Loss: 6.2995\nEpoch [13/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 5.9436\nEpoch [13/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 7.6182\nEpoch [13/100], Step [220/324], Discriminator Loss: 0.8352, Generator Loss: 10.2542\nEpoch [13/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 8.2569\nEpoch [13/100], Step [240/324], Discriminator Loss: 0.0042, Generator Loss: 4.8284\nEpoch [13/100], Step [250/324], Discriminator Loss: 0.0004, Generator Loss: 4.6190\nEpoch [13/100], Step [260/324], Discriminator Loss: 0.1787, Generator Loss: 4.1861\nEpoch [13/100], Step [270/324], Discriminator Loss: 0.0216, Generator Loss: 5.4031\nEpoch [13/100], Step [280/324], Discriminator Loss: 0.0207, Generator Loss: 5.9135\nEpoch [13/100], Step [290/324], Discriminator Loss: 0.3424, Generator Loss: 7.0379\nEpoch [13/100], Step [300/324], Discriminator Loss: 0.0471, Generator Loss: 4.3636\nEpoch [13/100], Step [310/324], Discriminator Loss: 0.0011, Generator Loss: 3.9627\nEpoch [13/100], Step [320/324], Discriminator Loss: 0.0529, Generator Loss: 3.9322\nEpoch [14/100], Step [0/324], Discriminator Loss: 0.0005, Generator Loss: 4.4622\nEpoch [14/100], Step [10/324], Discriminator Loss: 0.0944, Generator Loss: 4.4734\nEpoch [14/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 4.9577\nEpoch [14/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.6098\nEpoch [14/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.8041\nEpoch [14/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 5.7518\nEpoch [14/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 5.1572\nEpoch [14/100], Step [70/324], Discriminator Loss: 0.0015, Generator Loss: 5.3128\nEpoch [14/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 6.3288\nEpoch [14/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 6.8037\nEpoch [14/100], Step [100/324], Discriminator Loss: 0.0007, Generator Loss: 5.2083\nEpoch [14/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.2899\nEpoch [14/100], Step [120/324], Discriminator Loss: 0.0003, Generator Loss: 5.1447\nEpoch [14/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 5.1018\nEpoch [14/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 5.8841\nEpoch [14/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 6.4272\nEpoch [14/100], Step [160/324], Discriminator Loss: 0.3715, Generator Loss: 7.1650\nEpoch [14/100], Step [170/324], Discriminator Loss: 0.0571, Generator Loss: 6.2798\nEpoch [14/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.5787\nEpoch [14/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.4382\nEpoch [14/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.4123\nEpoch [14/100], Step [210/324], Discriminator Loss: 0.0057, Generator Loss: 5.9773\nEpoch [14/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 5.8990\nEpoch [14/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 6.5424\nEpoch [14/100], Step [240/324], Discriminator Loss: 0.3725, Generator Loss: 9.4891\nEpoch [14/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 6.5084\nEpoch [14/100], Step [260/324], Discriminator Loss: 0.0169, Generator Loss: 4.1336\nEpoch [14/100], Step [270/324], Discriminator Loss: 0.0016, Generator Loss: 3.9334\nEpoch [14/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 5.4454\nEpoch [14/100], Step [290/324], Discriminator Loss: 0.2542, Generator Loss: 5.8190\nEpoch [14/100], Step [300/324], Discriminator Loss: 0.0003, Generator Loss: 5.4550\nEpoch [14/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 5.3001\nEpoch [14/100], Step [320/324], Discriminator Loss: 0.5981, Generator Loss: 5.5382\nEpoch [15/100], Step [0/324], Discriminator Loss: 0.0016, Generator Loss: 4.5476\nEpoch [15/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 4.6089\nEpoch [15/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 3.8377\nEpoch [15/100], Step [30/324], Discriminator Loss: 0.1777, Generator Loss: 4.9984\nEpoch [15/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 6.1801\nEpoch [15/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.9028\nEpoch [15/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.5832\nEpoch [15/100], Step [70/324], Discriminator Loss: 0.2948, Generator Loss: 4.9122\nEpoch [15/100], Step [80/324], Discriminator Loss: 0.0028, Generator Loss: 5.0769\nEpoch [15/100], Step [90/324], Discriminator Loss: 0.0481, Generator Loss: 6.0434\nEpoch [15/100], Step [100/324], Discriminator Loss: 0.0003, Generator Loss: 5.4122\nEpoch [15/100], Step [110/324], Discriminator Loss: 0.3100, Generator Loss: 3.2055\nEpoch [15/100], Step [120/324], Discriminator Loss: 0.0231, Generator Loss: 4.6118\nEpoch [15/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 5.7412\nEpoch [15/100], Step [140/324], Discriminator Loss: 0.0013, Generator Loss: 4.4183\nEpoch [15/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 5.0729\nEpoch [15/100], Step [160/324], Discriminator Loss: 0.0242, Generator Loss: 4.9077\nEpoch [15/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 7.3813\nEpoch [15/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 5.0841\nEpoch [15/100], Step [190/324], Discriminator Loss: 0.0006, Generator Loss: 6.0416\nEpoch [15/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.2902\nEpoch [15/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 4.7298\nEpoch [15/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 5.9167\nEpoch [15/100], Step [230/324], Discriminator Loss: 0.0061, Generator Loss: 3.6640\nEpoch [15/100], Step [240/324], Discriminator Loss: 0.1105, Generator Loss: 6.7151\nEpoch [15/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 6.2609\nEpoch [15/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 5.6953\nEpoch [15/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 7.1115\nEpoch [15/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 6.5426\nEpoch [15/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 6.5478\nEpoch [15/100], Step [300/324], Discriminator Loss: 0.2162, Generator Loss: 6.0689\nEpoch [15/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 3.6993\nEpoch [15/100], Step [320/324], Discriminator Loss: 0.0071, Generator Loss: 3.7369\nEpoch [16/100], Step [0/324], Discriminator Loss: 0.0243, Generator Loss: 4.4870\nEpoch [16/100], Step [10/324], Discriminator Loss: 0.0340, Generator Loss: 4.8687\nEpoch [16/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 5.0673\nEpoch [16/100], Step [30/324], Discriminator Loss: 0.0547, Generator Loss: 6.0350\nEpoch [16/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.6158\nEpoch [16/100], Step [50/324], Discriminator Loss: 0.1267, Generator Loss: 4.9666\nEpoch [16/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.6507\nEpoch [16/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 6.2322\nEpoch [16/100], Step [80/324], Discriminator Loss: 0.0017, Generator Loss: 6.1005\nEpoch [16/100], Step [90/324], Discriminator Loss: 0.0038, Generator Loss: 5.9418\nEpoch [16/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 6.6316\nEpoch [16/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 5.3435\nEpoch [16/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 7.6397\nEpoch [16/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 7.6277\nEpoch [16/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 6.8348\nEpoch [16/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 7.7862\nEpoch [16/100], Step [160/324], Discriminator Loss: 0.0038, Generator Loss: 4.8363\nEpoch [16/100], Step [170/324], Discriminator Loss: 0.1589, Generator Loss: 5.1213\nEpoch [16/100], Step [180/324], Discriminator Loss: 0.0016, Generator Loss: 4.5654\nEpoch [16/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.6302\nEpoch [16/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 5.3530\nEpoch [16/100], Step [210/324], Discriminator Loss: 0.0013, Generator Loss: 5.8199\nEpoch [16/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 4.9679\nEpoch [16/100], Step [230/324], Discriminator Loss: 0.0246, Generator Loss: 5.8707\nEpoch [16/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 6.3290\nEpoch [16/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.5911\nEpoch [16/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 5.2250\nEpoch [16/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.0047\nEpoch [16/100], Step [280/324], Discriminator Loss: 0.3079, Generator Loss: 5.0772\nEpoch [16/100], Step [290/324], Discriminator Loss: 0.0301, Generator Loss: 5.7097\nEpoch [16/100], Step [300/324], Discriminator Loss: 0.0005, Generator Loss: 5.5842\nEpoch [16/100], Step [310/324], Discriminator Loss: 0.2513, Generator Loss: 5.7568\nEpoch [16/100], Step [320/324], Discriminator Loss: 0.5310, Generator Loss: 9.5012\nEpoch [17/100], Step [0/324], Discriminator Loss: 0.0027, Generator Loss: 7.8991\nEpoch [17/100], Step [10/324], Discriminator Loss: 0.0008, Generator Loss: 4.8336\nEpoch [17/100], Step [20/324], Discriminator Loss: 0.0800, Generator Loss: 4.3091\nEpoch [17/100], Step [30/324], Discriminator Loss: 0.0009, Generator Loss: 4.9792\nEpoch [17/100], Step [40/324], Discriminator Loss: 0.0007, Generator Loss: 3.7459\nEpoch [17/100], Step [50/324], Discriminator Loss: 0.0326, Generator Loss: 4.2606\nEpoch [17/100], Step [60/324], Discriminator Loss: 0.0041, Generator Loss: 4.4944\nEpoch [17/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 5.0437\nEpoch [17/100], Step [80/324], Discriminator Loss: 0.0004, Generator Loss: 4.3259\nEpoch [17/100], Step [90/324], Discriminator Loss: 0.0003, Generator Loss: 3.4057\nEpoch [17/100], Step [100/324], Discriminator Loss: 0.0503, Generator Loss: 4.7374\nEpoch [17/100], Step [110/324], Discriminator Loss: 0.0006, Generator Loss: 3.9777\nEpoch [17/100], Step [120/324], Discriminator Loss: 1.5629, Generator Loss: 4.8017\nEpoch [17/100], Step [130/324], Discriminator Loss: 0.2058, Generator Loss: 4.7519\nEpoch [17/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 4.9724\nEpoch [17/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 4.9844\nEpoch [17/100], Step [160/324], Discriminator Loss: 0.0005, Generator Loss: 4.4763\nEpoch [17/100], Step [170/324], Discriminator Loss: 0.0052, Generator Loss: 4.0754\nEpoch [17/100], Step [180/324], Discriminator Loss: 0.0007, Generator Loss: 4.3955\nEpoch [17/100], Step [190/324], Discriminator Loss: 0.5646, Generator Loss: 5.2846\nEpoch [17/100], Step [200/324], Discriminator Loss: 0.0003, Generator Loss: 7.7410\nEpoch [17/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 8.7815\nEpoch [17/100], Step [220/324], Discriminator Loss: 0.2420, Generator Loss: 5.7269\nEpoch [17/100], Step [230/324], Discriminator Loss: 0.0004, Generator Loss: 4.7137\nEpoch [17/100], Step [240/324], Discriminator Loss: 0.0016, Generator Loss: 4.5534\nEpoch [17/100], Step [250/324], Discriminator Loss: 0.0360, Generator Loss: 5.3431\nEpoch [17/100], Step [260/324], Discriminator Loss: 0.2361, Generator Loss: 4.3873\nEpoch [17/100], Step [270/324], Discriminator Loss: 0.0857, Generator Loss: 3.6950\nEpoch [17/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.3562\nEpoch [17/100], Step [290/324], Discriminator Loss: 0.0020, Generator Loss: 4.2307\nEpoch [17/100], Step [300/324], Discriminator Loss: 0.0136, Generator Loss: 4.0205\nEpoch [17/100], Step [310/324], Discriminator Loss: 0.0011, Generator Loss: 6.7754\nEpoch [17/100], Step [320/324], Discriminator Loss: 0.0017, Generator Loss: 6.0564\nEpoch [18/100], Step [0/324], Discriminator Loss: 0.0031, Generator Loss: 5.3128\nEpoch [18/100], Step [10/324], Discriminator Loss: 0.0004, Generator Loss: 5.0452\nEpoch [18/100], Step [20/324], Discriminator Loss: 0.0082, Generator Loss: 4.6535\nEpoch [18/100], Step [30/324], Discriminator Loss: 0.0004, Generator Loss: 4.3097\nEpoch [18/100], Step [40/324], Discriminator Loss: 0.0039, Generator Loss: 4.5075\nEpoch [18/100], Step [50/324], Discriminator Loss: 0.1415, Generator Loss: 4.6247\nEpoch [18/100], Step [60/324], Discriminator Loss: 0.2429, Generator Loss: 7.4590\nEpoch [18/100], Step [70/324], Discriminator Loss: 0.2758, Generator Loss: 6.7662\nEpoch [18/100], Step [80/324], Discriminator Loss: 0.4199, Generator Loss: 4.9024\nEpoch [18/100], Step [90/324], Discriminator Loss: 0.2785, Generator Loss: 4.5903\nEpoch [18/100], Step [100/324], Discriminator Loss: 0.0028, Generator Loss: 3.6466\nEpoch [18/100], Step [110/324], Discriminator Loss: 0.0021, Generator Loss: 3.9882\nEpoch [18/100], Step [120/324], Discriminator Loss: 0.2795, Generator Loss: 3.9120\nEpoch [18/100], Step [130/324], Discriminator Loss: 0.0005, Generator Loss: 4.1329\nEpoch [18/100], Step [140/324], Discriminator Loss: 0.0009, Generator Loss: 3.3395\nEpoch [18/100], Step [150/324], Discriminator Loss: 0.0049, Generator Loss: 4.1208\nEpoch [18/100], Step [160/324], Discriminator Loss: 0.0009, Generator Loss: 3.8804\nEpoch [18/100], Step [170/324], Discriminator Loss: 0.0005, Generator Loss: 3.8518\nEpoch [18/100], Step [180/324], Discriminator Loss: 0.0010, Generator Loss: 4.9999\nEpoch [18/100], Step [190/324], Discriminator Loss: 0.1894, Generator Loss: 3.8950\nEpoch [18/100], Step [200/324], Discriminator Loss: 0.7793, Generator Loss: 4.5586\nEpoch [18/100], Step [210/324], Discriminator Loss: 0.0007, Generator Loss: 3.6780\nEpoch [18/100], Step [220/324], Discriminator Loss: 0.0020, Generator Loss: 3.9611\nEpoch [18/100], Step [230/324], Discriminator Loss: 0.0008, Generator Loss: 3.7960\nEpoch [18/100], Step [240/324], Discriminator Loss: 0.1770, Generator Loss: 4.2597\nEpoch [18/100], Step [250/324], Discriminator Loss: 0.0058, Generator Loss: 4.7147\nEpoch [18/100], Step [260/324], Discriminator Loss: 0.0677, Generator Loss: 4.8771\nEpoch [18/100], Step [270/324], Discriminator Loss: 0.0985, Generator Loss: 3.8723\nEpoch [18/100], Step [280/324], Discriminator Loss: 0.0621, Generator Loss: 4.1484\nEpoch [18/100], Step [290/324], Discriminator Loss: 0.0008, Generator Loss: 4.4988\nEpoch [18/100], Step [300/324], Discriminator Loss: 0.0005, Generator Loss: 3.2934\nEpoch [18/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.5810\nEpoch [18/100], Step [320/324], Discriminator Loss: 0.2217, Generator Loss: 3.0007\nEpoch [19/100], Step [0/324], Discriminator Loss: 0.1024, Generator Loss: 3.8708\nEpoch [19/100], Step [10/324], Discriminator Loss: 0.0109, Generator Loss: 3.2354\nEpoch [19/100], Step [20/324], Discriminator Loss: 0.1820, Generator Loss: 4.7389\nEpoch [19/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 3.1820\nEpoch [19/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 4.5974\nEpoch [19/100], Step [50/324], Discriminator Loss: 0.1653, Generator Loss: 4.9501\nEpoch [19/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 5.1598\nEpoch [19/100], Step [70/324], Discriminator Loss: 0.0185, Generator Loss: 4.5984\nEpoch [19/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 3.4068\nEpoch [19/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 4.1612\nEpoch [19/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.3328\nEpoch [19/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.1558\nEpoch [19/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 4.0747\nEpoch [19/100], Step [130/324], Discriminator Loss: 0.0004, Generator Loss: 4.1154\nEpoch [19/100], Step [140/324], Discriminator Loss: 0.0003, Generator Loss: 3.7705\nEpoch [19/100], Step [150/324], Discriminator Loss: 0.0003, Generator Loss: 4.3361\nEpoch [19/100], Step [160/324], Discriminator Loss: 0.0002, Generator Loss: 3.1786\nEpoch [19/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 4.7788\nEpoch [19/100], Step [180/324], Discriminator Loss: 0.0331, Generator Loss: 3.6867\nEpoch [19/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.8858\nEpoch [19/100], Step [200/324], Discriminator Loss: 0.0827, Generator Loss: 4.5394\nEpoch [19/100], Step [210/324], Discriminator Loss: 0.1456, Generator Loss: 3.9477\nEpoch [19/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.5997\nEpoch [19/100], Step [230/324], Discriminator Loss: 0.1437, Generator Loss: 4.3312\nEpoch [19/100], Step [240/324], Discriminator Loss: 0.0033, Generator Loss: 4.2458\nEpoch [19/100], Step [250/324], Discriminator Loss: 0.0661, Generator Loss: 4.2747\nEpoch [19/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.7331\nEpoch [19/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 4.3664\nEpoch [19/100], Step [280/324], Discriminator Loss: 0.0255, Generator Loss: 5.3860\nEpoch [19/100], Step [290/324], Discriminator Loss: 0.3036, Generator Loss: 6.9083\nEpoch [19/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 5.3965\nEpoch [19/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 6.6561\nEpoch [19/100], Step [320/324], Discriminator Loss: 0.0007, Generator Loss: 3.9673\nEpoch [20/100], Step [0/324], Discriminator Loss: 0.4772, Generator Loss: 3.7579\nEpoch [20/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 4.6305\nEpoch [20/100], Step [20/324], Discriminator Loss: 0.0399, Generator Loss: 5.0538\nEpoch [20/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.9352\nEpoch [20/100], Step [40/324], Discriminator Loss: 0.0006, Generator Loss: 4.3896\nEpoch [20/100], Step [50/324], Discriminator Loss: 0.0004, Generator Loss: 5.5486\nEpoch [20/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.2879\nEpoch [20/100], Step [70/324], Discriminator Loss: 0.0021, Generator Loss: 4.3616\nEpoch [20/100], Step [80/324], Discriminator Loss: 0.0004, Generator Loss: 3.7698\nEpoch [20/100], Step [90/324], Discriminator Loss: 0.0017, Generator Loss: 3.8063\nEpoch [20/100], Step [100/324], Discriminator Loss: 0.0935, Generator Loss: 5.6920\nEpoch [20/100], Step [110/324], Discriminator Loss: 0.0025, Generator Loss: 5.4683\nEpoch [20/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 11.0636\nEpoch [20/100], Step [130/324], Discriminator Loss: 0.6035, Generator Loss: 5.5073\nEpoch [20/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 3.9487\nEpoch [20/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 4.4461\nEpoch [20/100], Step [160/324], Discriminator Loss: 0.0010, Generator Loss: 4.4902\nEpoch [20/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.8472\nEpoch [20/100], Step [180/324], Discriminator Loss: 0.0594, Generator Loss: 4.0530\nEpoch [20/100], Step [190/324], Discriminator Loss: 0.0004, Generator Loss: 4.0941\nEpoch [20/100], Step [200/324], Discriminator Loss: 0.1320, Generator Loss: 4.1748\nEpoch [20/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.8530\nEpoch [20/100], Step [220/324], Discriminator Loss: 0.0478, Generator Loss: 4.6613\nEpoch [20/100], Step [230/324], Discriminator Loss: 0.0462, Generator Loss: 3.6287\nEpoch [20/100], Step [240/324], Discriminator Loss: 0.1348, Generator Loss: 3.1055\nEpoch [20/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 5.9584\nEpoch [20/100], Step [260/324], Discriminator Loss: 0.2984, Generator Loss: 4.2705\nEpoch [20/100], Step [270/324], Discriminator Loss: 0.2515, Generator Loss: 3.5688\nEpoch [20/100], Step [280/324], Discriminator Loss: 1.5694, Generator Loss: 4.7477\nEpoch [20/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 4.3500\nEpoch [20/100], Step [300/324], Discriminator Loss: 0.3310, Generator Loss: 3.7538\nEpoch [20/100], Step [310/324], Discriminator Loss: 0.1462, Generator Loss: 3.7353\nEpoch [20/100], Step [320/324], Discriminator Loss: 0.1076, Generator Loss: 5.2818\nEpoch [21/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 5.5139\nEpoch [21/100], Step [10/324], Discriminator Loss: 0.0008, Generator Loss: 3.1140\nEpoch [21/100], Step [20/324], Discriminator Loss: 0.0013, Generator Loss: 3.3941\nEpoch [21/100], Step [30/324], Discriminator Loss: 1.5627, Generator Loss: 4.5689\nEpoch [21/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.6424\nEpoch [21/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.1133\nEpoch [21/100], Step [60/324], Discriminator Loss: 0.1870, Generator Loss: 3.6289\nEpoch [21/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 5.6095\nEpoch [21/100], Step [80/324], Discriminator Loss: 0.0004, Generator Loss: 4.5079\nEpoch [21/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 5.3827\nEpoch [21/100], Step [100/324], Discriminator Loss: 0.0004, Generator Loss: 3.8548\nEpoch [21/100], Step [110/324], Discriminator Loss: 0.0005, Generator Loss: 3.4020\nEpoch [21/100], Step [120/324], Discriminator Loss: 0.0581, Generator Loss: 3.8247\nEpoch [21/100], Step [130/324], Discriminator Loss: 0.1000, Generator Loss: 3.8658\nEpoch [21/100], Step [140/324], Discriminator Loss: 0.2334, Generator Loss: 4.7579\nEpoch [21/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 5.1330\nEpoch [21/100], Step [160/324], Discriminator Loss: 0.0005, Generator Loss: 4.0790\nEpoch [21/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.3452\nEpoch [21/100], Step [180/324], Discriminator Loss: 0.0011, Generator Loss: 3.7740\nEpoch [21/100], Step [190/324], Discriminator Loss: 0.0535, Generator Loss: 4.4084\nEpoch [21/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.2981\nEpoch [21/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.8928\nEpoch [21/100], Step [220/324], Discriminator Loss: 0.0004, Generator Loss: 4.1012\nEpoch [21/100], Step [230/324], Discriminator Loss: 0.0042, Generator Loss: 5.2854\nEpoch [21/100], Step [240/324], Discriminator Loss: 0.1757, Generator Loss: 4.1280\nEpoch [21/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 5.0244\nEpoch [21/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.6976\nEpoch [21/100], Step [270/324], Discriminator Loss: 0.1480, Generator Loss: 3.7268\nEpoch [21/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 4.5215\nEpoch [21/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 5.0583\nEpoch [21/100], Step [300/324], Discriminator Loss: 0.3983, Generator Loss: 5.5889\nEpoch [21/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.1551\nEpoch [21/100], Step [320/324], Discriminator Loss: 0.6116, Generator Loss: 4.4418\nEpoch [22/100], Step [0/324], Discriminator Loss: 0.0003, Generator Loss: 4.6596\nEpoch [22/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 5.9188\nEpoch [22/100], Step [20/324], Discriminator Loss: 0.0008, Generator Loss: 4.1091\nEpoch [22/100], Step [30/324], Discriminator Loss: 0.5028, Generator Loss: 5.7906\nEpoch [22/100], Step [40/324], Discriminator Loss: 0.3462, Generator Loss: 4.2979\nEpoch [22/100], Step [60/324], Discriminator Loss: 0.0006, Generator Loss: 5.8702\nEpoch [22/100], Step [70/324], Discriminator Loss: 0.0413, Generator Loss: 3.6463\nEpoch [22/100], Step [80/324], Discriminator Loss: 0.2015, Generator Loss: 4.9451\nEpoch [22/100], Step [90/324], Discriminator Loss: 0.0053, Generator Loss: 5.4737\nEpoch [22/100], Step [100/324], Discriminator Loss: 0.5428, Generator Loss: 6.9305\nEpoch [22/100], Step [110/324], Discriminator Loss: 0.2933, Generator Loss: 3.2878\nEpoch [22/100], Step [120/324], Discriminator Loss: 0.0003, Generator Loss: 4.7939\nEpoch [22/100], Step [130/324], Discriminator Loss: 0.0025, Generator Loss: 4.1245\nEpoch [22/100], Step [140/324], Discriminator Loss: 0.0028, Generator Loss: 2.8860\nEpoch [22/100], Step [150/324], Discriminator Loss: 0.0962, Generator Loss: 4.4654\nEpoch [22/100], Step [160/324], Discriminator Loss: 0.0003, Generator Loss: 3.7805\nEpoch [22/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 5.7428\nEpoch [22/100], Step [180/324], Discriminator Loss: 0.0003, Generator Loss: 4.6430\nEpoch [22/100], Step [190/324], Discriminator Loss: 0.1468, Generator Loss: 3.0106\nEpoch [22/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.8522\nEpoch [22/100], Step [210/324], Discriminator Loss: 0.0013, Generator Loss: 4.4246\nEpoch [22/100], Step [220/324], Discriminator Loss: 0.0003, Generator Loss: 5.5867\nEpoch [22/100], Step [230/324], Discriminator Loss: 0.0004, Generator Loss: 3.7308\nEpoch [22/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 4.4011\nEpoch [22/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 5.0908\nEpoch [22/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.9214\nEpoch [22/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.6020\nEpoch [22/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 4.9658\nEpoch [22/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.3988\nEpoch [22/100], Step [300/324], Discriminator Loss: 0.1788, Generator Loss: 3.5565\nEpoch [22/100], Step [310/324], Discriminator Loss: 0.1695, Generator Loss: 4.5995\nEpoch [22/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 3.3513\nEpoch [23/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 4.2038\nEpoch [23/100], Step [10/324], Discriminator Loss: 0.3379, Generator Loss: 5.2189\nEpoch [23/100], Step [20/324], Discriminator Loss: 0.0003, Generator Loss: 3.9309\nEpoch [23/100], Step [30/324], Discriminator Loss: 0.0014, Generator Loss: 4.2759\nEpoch [23/100], Step [40/324], Discriminator Loss: 0.2315, Generator Loss: 4.3171\nEpoch [23/100], Step [50/324], Discriminator Loss: 0.0004, Generator Loss: 4.5823\nEpoch [23/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.3278\nEpoch [23/100], Step [70/324], Discriminator Loss: 0.0005, Generator Loss: 4.1052\nEpoch [23/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 6.1792\nEpoch [23/100], Step [90/324], Discriminator Loss: 0.0673, Generator Loss: 4.4603\nEpoch [23/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.0992\nEpoch [23/100], Step [110/324], Discriminator Loss: 0.3004, Generator Loss: 5.0459\nEpoch [23/100], Step [120/324], Discriminator Loss: 0.0026, Generator Loss: 4.5604\nEpoch [23/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.4193\nEpoch [23/100], Step [140/324], Discriminator Loss: 0.2088, Generator Loss: 4.2701\nEpoch [23/100], Step [150/324], Discriminator Loss: 0.2627, Generator Loss: 4.7518\nEpoch [23/100], Step [160/324], Discriminator Loss: 0.0886, Generator Loss: 5.5106\nEpoch [23/100], Step [170/324], Discriminator Loss: 0.0032, Generator Loss: 4.5438\nEpoch [23/100], Step [180/324], Discriminator Loss: 0.0004, Generator Loss: 3.8419\nEpoch [23/100], Step [190/324], Discriminator Loss: 0.0018, Generator Loss: 4.7763\nEpoch [23/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 5.1264\nEpoch [23/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.3676\nEpoch [23/100], Step [220/324], Discriminator Loss: 0.0005, Generator Loss: 3.5832\nEpoch [23/100], Step [230/324], Discriminator Loss: 0.2035, Generator Loss: 3.5478\nEpoch [23/100], Step [240/324], Discriminator Loss: 0.3486, Generator Loss: 4.2729\nEpoch [23/100], Step [250/324], Discriminator Loss: 0.0047, Generator Loss: 4.2902\nEpoch [23/100], Step [260/324], Discriminator Loss: 0.1167, Generator Loss: 3.8009\nEpoch [23/100], Step [270/324], Discriminator Loss: 0.0005, Generator Loss: 3.1870\nEpoch [23/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 5.6009\nEpoch [23/100], Step [290/324], Discriminator Loss: 0.1072, Generator Loss: 4.8516\nEpoch [23/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.1178\nEpoch [23/100], Step [310/324], Discriminator Loss: 0.5131, Generator Loss: 4.4837\nEpoch [23/100], Step [320/324], Discriminator Loss: 0.1014, Generator Loss: 4.5840\nEpoch [24/100], Step [0/324], Discriminator Loss: 0.2305, Generator Loss: 4.4213\nEpoch [24/100], Step [10/324], Discriminator Loss: 0.0585, Generator Loss: 3.8569\nEpoch [24/100], Step [20/324], Discriminator Loss: 0.0011, Generator Loss: 4.8048\nEpoch [24/100], Step [30/324], Discriminator Loss: 0.0003, Generator Loss: 4.2027\nEpoch [24/100], Step [40/324], Discriminator Loss: 0.0898, Generator Loss: 4.1776\nEpoch [24/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 5.0887\nEpoch [24/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 5.0248\nEpoch [24/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.7491\nEpoch [24/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 3.8486\nEpoch [24/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 5.4011\nEpoch [24/100], Step [100/324], Discriminator Loss: 0.6611, Generator Loss: 5.9879\nEpoch [24/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 3.7500\nEpoch [24/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.4549\nEpoch [24/100], Step [130/324], Discriminator Loss: 0.0093, Generator Loss: 3.2214\nEpoch [24/100], Step [140/324], Discriminator Loss: 0.0682, Generator Loss: 4.0197\nEpoch [24/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.7848\nEpoch [24/100], Step [160/324], Discriminator Loss: 0.0126, Generator Loss: 3.3610\nEpoch [24/100], Step [170/324], Discriminator Loss: 0.0458, Generator Loss: 4.2585\nEpoch [24/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 4.9187\nEpoch [24/100], Step [190/324], Discriminator Loss: 0.0807, Generator Loss: 4.4098\nEpoch [24/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 5.1726\nEpoch [24/100], Step [210/324], Discriminator Loss: 0.1878, Generator Loss: 4.3937\nEpoch [24/100], Step [220/324], Discriminator Loss: 0.1690, Generator Loss: 6.9586\nEpoch [24/100], Step [230/324], Discriminator Loss: 0.0425, Generator Loss: 4.9558\nEpoch [24/100], Step [240/324], Discriminator Loss: 0.0004, Generator Loss: 3.5093\nEpoch [24/100], Step [250/324], Discriminator Loss: 0.0011, Generator Loss: 4.2687\nEpoch [24/100], Step [260/324], Discriminator Loss: 0.2263, Generator Loss: 4.6695\nEpoch [24/100], Step [270/324], Discriminator Loss: 0.0018, Generator Loss: 3.8455\nEpoch [24/100], Step [280/324], Discriminator Loss: 0.2918, Generator Loss: 3.7632\nEpoch [24/100], Step [290/324], Discriminator Loss: 0.0031, Generator Loss: 3.4859\nEpoch [24/100], Step [300/324], Discriminator Loss: 0.0011, Generator Loss: 4.4561\nEpoch [24/100], Step [310/324], Discriminator Loss: 0.0007, Generator Loss: 4.0710\nEpoch [24/100], Step [320/324], Discriminator Loss: 0.3091, Generator Loss: 3.4140\nEpoch [25/100], Step [0/324], Discriminator Loss: 0.0023, Generator Loss: 3.2508\nEpoch [25/100], Step [10/324], Discriminator Loss: 0.1660, Generator Loss: 3.7970\nEpoch [25/100], Step [20/324], Discriminator Loss: 0.0006, Generator Loss: 4.1866\nEpoch [25/100], Step [30/324], Discriminator Loss: 0.0005, Generator Loss: 3.5974\nEpoch [25/100], Step [40/324], Discriminator Loss: 0.0694, Generator Loss: 5.2416\nEpoch [25/100], Step [50/324], Discriminator Loss: 0.0006, Generator Loss: 3.8852\nEpoch [25/100], Step [60/324], Discriminator Loss: 0.2148, Generator Loss: 3.6668\nEpoch [25/100], Step [70/324], Discriminator Loss: 0.0008, Generator Loss: 3.4680\nEpoch [25/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 4.7086\nEpoch [25/100], Step [90/324], Discriminator Loss: 1.5630, Generator Loss: 5.1423\nEpoch [25/100], Step [100/324], Discriminator Loss: 0.0006, Generator Loss: 4.1543\nEpoch [25/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.5857\nEpoch [25/100], Step [120/324], Discriminator Loss: 0.1797, Generator Loss: 4.3259\nEpoch [25/100], Step [130/324], Discriminator Loss: 0.1897, Generator Loss: 3.3482\nEpoch [25/100], Step [140/324], Discriminator Loss: 0.2067, Generator Loss: 3.8158\nEpoch [25/100], Step [150/324], Discriminator Loss: 0.0005, Generator Loss: 4.5987\nEpoch [25/100], Step [160/324], Discriminator Loss: 0.1263, Generator Loss: 3.8712\nEpoch [25/100], Step [170/324], Discriminator Loss: 0.0670, Generator Loss: 4.3378\nEpoch [25/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 4.3865\nEpoch [25/100], Step [190/324], Discriminator Loss: 0.0004, Generator Loss: 4.2662\nEpoch [25/100], Step [200/324], Discriminator Loss: 0.0488, Generator Loss: 3.3597\nEpoch [25/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.8020\nEpoch [25/100], Step [220/324], Discriminator Loss: 0.1308, Generator Loss: 4.4126\nEpoch [25/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 2.7764\nEpoch [25/100], Step [240/324], Discriminator Loss: 0.0004, Generator Loss: 5.0153\nEpoch [25/100], Step [250/324], Discriminator Loss: 0.0009, Generator Loss: 3.8841\nEpoch [25/100], Step [260/324], Discriminator Loss: 0.0005, Generator Loss: 4.3301\nEpoch [25/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.8256\nEpoch [25/100], Step [280/324], Discriminator Loss: 0.0012, Generator Loss: 3.0891\nEpoch [25/100], Step [290/324], Discriminator Loss: 0.0005, Generator Loss: 4.0801\nEpoch [25/100], Step [300/324], Discriminator Loss: 0.1805, Generator Loss: 4.2951\nEpoch [25/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 4.2996\nEpoch [25/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 3.6765\nEpoch [26/100], Step [0/324], Discriminator Loss: 0.1477, Generator Loss: 3.7213\nEpoch [26/100], Step [10/324], Discriminator Loss: 0.0007, Generator Loss: 4.0643\nEpoch [26/100], Step [20/324], Discriminator Loss: 0.0004, Generator Loss: 3.9480\nEpoch [26/100], Step [30/324], Discriminator Loss: 0.0004, Generator Loss: 3.8900\nEpoch [26/100], Step [40/324], Discriminator Loss: 0.3656, Generator Loss: 4.1060\nEpoch [26/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.6848\nEpoch [26/100], Step [60/324], Discriminator Loss: 0.0010, Generator Loss: 3.7634\nEpoch [26/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 4.4765\nEpoch [26/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.1958\nEpoch [26/100], Step [90/324], Discriminator Loss: 0.0526, Generator Loss: 4.0675\nEpoch [26/100], Step [100/324], Discriminator Loss: 0.1435, Generator Loss: 3.7355\nEpoch [26/100], Step [110/324], Discriminator Loss: 0.0003, Generator Loss: 4.9719\nEpoch [26/100], Step [120/324], Discriminator Loss: 0.0003, Generator Loss: 4.0645\nEpoch [26/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 4.0193\nEpoch [26/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 3.2571\nEpoch [26/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.8119\nEpoch [26/100], Step [160/324], Discriminator Loss: 0.4822, Generator Loss: 4.1689\nEpoch [26/100], Step [170/324], Discriminator Loss: 0.0003, Generator Loss: 4.4156\nEpoch [26/100], Step [180/324], Discriminator Loss: 0.1752, Generator Loss: 4.2339\nEpoch [26/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 3.3769\nEpoch [26/100], Step [200/324], Discriminator Loss: 0.4511, Generator Loss: 4.5866\nEpoch [26/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 4.7547\nEpoch [26/100], Step [220/324], Discriminator Loss: 0.1431, Generator Loss: 3.5005\nEpoch [26/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 4.1756\nEpoch [26/100], Step [240/324], Discriminator Loss: 0.0699, Generator Loss: 4.6816\nEpoch [26/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 3.7403\nEpoch [26/100], Step [260/324], Discriminator Loss: 0.0544, Generator Loss: 3.7773\nEpoch [26/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 4.3868\nEpoch [26/100], Step [280/324], Discriminator Loss: 1.5626, Generator Loss: 4.5474\nEpoch [26/100], Step [290/324], Discriminator Loss: 0.1988, Generator Loss: 4.2323\nEpoch [26/100], Step [300/324], Discriminator Loss: 0.0661, Generator Loss: 4.1280\nEpoch [26/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 4.1157\nEpoch [26/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.7322\nEpoch [27/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.4142\nEpoch [27/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.8379\nEpoch [27/100], Step [20/324], Discriminator Loss: 1.5625, Generator Loss: 4.4826\nEpoch [27/100], Step [30/324], Discriminator Loss: 0.2565, Generator Loss: 4.5380\nEpoch [27/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 4.6492\nEpoch [27/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.2173\nEpoch [27/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.7937\nEpoch [27/100], Step [70/324], Discriminator Loss: 0.1743, Generator Loss: 4.5528\nEpoch [27/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 4.4466\nEpoch [27/100], Step [90/324], Discriminator Loss: 0.1365, Generator Loss: 3.9544\nEpoch [27/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.9264\nEpoch [27/100], Step [110/324], Discriminator Loss: 0.0473, Generator Loss: 3.4512\nEpoch [27/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.6256\nEpoch [27/100], Step [130/324], Discriminator Loss: 0.1826, Generator Loss: 3.5697\nEpoch [27/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 3.3721\nEpoch [27/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 4.8064\nEpoch [27/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.7763\nEpoch [27/100], Step [170/324], Discriminator Loss: 0.4192, Generator Loss: 4.0632\nEpoch [27/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.6392\nEpoch [27/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 3.5726\nEpoch [27/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.6988\nEpoch [27/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 4.0082\nEpoch [27/100], Step [220/324], Discriminator Loss: 0.0005, Generator Loss: 5.6508\nEpoch [27/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 4.4629\nEpoch [27/100], Step [240/324], Discriminator Loss: 0.5988, Generator Loss: 3.8407\nEpoch [27/100], Step [250/324], Discriminator Loss: 0.5033, Generator Loss: 4.5721\nEpoch [27/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.5463\nEpoch [27/100], Step [270/324], Discriminator Loss: 0.3412, Generator Loss: 3.6020\nEpoch [27/100], Step [280/324], Discriminator Loss: 0.0486, Generator Loss: 5.0897\nEpoch [27/100], Step [290/324], Discriminator Loss: 0.0705, Generator Loss: 4.1986\nEpoch [27/100], Step [300/324], Discriminator Loss: 0.0003, Generator Loss: 4.8967\nEpoch [27/100], Step [310/324], Discriminator Loss: 0.0010, Generator Loss: 6.3238\nEpoch [27/100], Step [320/324], Discriminator Loss: 0.1597, Generator Loss: 4.4686\nEpoch [28/100], Step [0/324], Discriminator Loss: 0.0008, Generator Loss: 3.6769\nEpoch [28/100], Step [10/324], Discriminator Loss: 0.0006, Generator Loss: 4.7640\nEpoch [28/100], Step [20/324], Discriminator Loss: 0.0006, Generator Loss: 3.5435\nEpoch [28/100], Step [30/324], Discriminator Loss: 0.0003, Generator Loss: 3.8093\nEpoch [28/100], Step [40/324], Discriminator Loss: 0.0824, Generator Loss: 3.5115\nEpoch [28/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.3027\nEpoch [28/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 3.5713\nEpoch [28/100], Step [70/324], Discriminator Loss: 0.2867, Generator Loss: 4.5844\nEpoch [28/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.0765\nEpoch [28/100], Step [90/324], Discriminator Loss: 0.3955, Generator Loss: 3.9719\nEpoch [28/100], Step [100/324], Discriminator Loss: 0.0002, Generator Loss: 4.6715\nEpoch [28/100], Step [110/324], Discriminator Loss: 0.1078, Generator Loss: 3.6528\nEpoch [28/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.1929\nEpoch [28/100], Step [130/324], Discriminator Loss: 0.3594, Generator Loss: 4.1780\nEpoch [28/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.3655\nEpoch [28/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 5.5249\nEpoch [28/100], Step [160/324], Discriminator Loss: 0.2255, Generator Loss: 4.4749\nEpoch [28/100], Step [170/324], Discriminator Loss: 0.3588, Generator Loss: 4.2485\nEpoch [28/100], Step [180/324], Discriminator Loss: 0.0506, Generator Loss: 3.1730\nEpoch [28/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.1222\nEpoch [28/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 5.3541\nEpoch [28/100], Step [210/324], Discriminator Loss: 0.3080, Generator Loss: 3.1930\nEpoch [28/100], Step [220/324], Discriminator Loss: 0.1976, Generator Loss: 3.7998\nEpoch [28/100], Step [230/324], Discriminator Loss: 0.0054, Generator Loss: 4.4192\nEpoch [28/100], Step [240/324], Discriminator Loss: 0.0007, Generator Loss: 4.6415\nEpoch [28/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 4.4837\nEpoch [28/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.5767\nEpoch [28/100], Step [270/324], Discriminator Loss: 0.3034, Generator Loss: 3.0062\nEpoch [28/100], Step [280/324], Discriminator Loss: 0.0003, Generator Loss: 4.7135\nEpoch [28/100], Step [290/324], Discriminator Loss: 0.3037, Generator Loss: 4.9255\nEpoch [28/100], Step [300/324], Discriminator Loss: 0.2738, Generator Loss: 3.3126\nEpoch [28/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.9523\nEpoch [28/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 4.3485\nEpoch [29/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.9708\nEpoch [29/100], Step [10/324], Discriminator Loss: 0.1761, Generator Loss: 3.8438\nEpoch [29/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 5.3310\nEpoch [29/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.5036\nEpoch [29/100], Step [40/324], Discriminator Loss: 0.1971, Generator Loss: 4.2425\nEpoch [29/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 4.2366\nEpoch [29/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 3.5698\nEpoch [29/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.1975\nEpoch [29/100], Step [80/324], Discriminator Loss: 0.0004, Generator Loss: 4.2244\nEpoch [29/100], Step [90/324], Discriminator Loss: 0.0103, Generator Loss: 5.4356\nEpoch [29/100], Step [100/324], Discriminator Loss: 0.2022, Generator Loss: 4.5982\nEpoch [29/100], Step [110/324], Discriminator Loss: 0.0002, Generator Loss: 4.0188\nEpoch [29/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.5701\nEpoch [29/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 4.6946\nEpoch [29/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.2974\nEpoch [29/100], Step [150/324], Discriminator Loss: 0.0992, Generator Loss: 3.8746\nEpoch [29/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.6854\nEpoch [29/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 3.8985\nEpoch [29/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 6.1477\nEpoch [29/100], Step [190/324], Discriminator Loss: 0.3102, Generator Loss: 3.7809\nEpoch [29/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.3984\nEpoch [29/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 6.1542\nEpoch [29/100], Step [220/324], Discriminator Loss: 0.1651, Generator Loss: 4.2007\nEpoch [29/100], Step [230/324], Discriminator Loss: 0.1599, Generator Loss: 3.6709\nEpoch [29/100], Step [240/324], Discriminator Loss: 0.5339, Generator Loss: 4.0410\nEpoch [29/100], Step [250/324], Discriminator Loss: 0.1901, Generator Loss: 5.2787\nEpoch [29/100], Step [260/324], Discriminator Loss: 0.1288, Generator Loss: 5.3224\nEpoch [29/100], Step [270/324], Discriminator Loss: 0.1990, Generator Loss: 2.7904\nEpoch [29/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 5.1512\nEpoch [29/100], Step [290/324], Discriminator Loss: 0.2494, Generator Loss: 3.6148\nEpoch [29/100], Step [300/324], Discriminator Loss: 0.1375, Generator Loss: 3.2724\nEpoch [29/100], Step [310/324], Discriminator Loss: 1.5627, Generator Loss: 5.9932\nEpoch [29/100], Step [320/324], Discriminator Loss: 0.3781, Generator Loss: 3.6954\nEpoch [30/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.7271\nEpoch [30/100], Step [10/324], Discriminator Loss: 0.0021, Generator Loss: 5.4810\nEpoch [30/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 4.7282\nEpoch [30/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.0462\nEpoch [30/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 5.0561\nEpoch [30/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 4.7179\nEpoch [30/100], Step [60/324], Discriminator Loss: 0.2367, Generator Loss: 4.1593\nEpoch [30/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 3.8415\nEpoch [30/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.4484\nEpoch [30/100], Step [90/324], Discriminator Loss: 0.0014, Generator Loss: 4.3039\nEpoch [30/100], Step [100/324], Discriminator Loss: 0.2322, Generator Loss: 3.8998\nEpoch [30/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.8080\nEpoch [30/100], Step [120/324], Discriminator Loss: 0.2820, Generator Loss: 4.0862\nEpoch [30/100], Step [130/324], Discriminator Loss: 0.0003, Generator Loss: 4.0930\nEpoch [30/100], Step [140/324], Discriminator Loss: 0.1258, Generator Loss: 3.9787\nEpoch [30/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.5548\nEpoch [30/100], Step [160/324], Discriminator Loss: 0.4538, Generator Loss: 3.2206\nEpoch [30/100], Step [170/324], Discriminator Loss: 0.0006, Generator Loss: 4.4030\nEpoch [30/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 3.4493\nEpoch [30/100], Step [190/324], Discriminator Loss: 0.0087, Generator Loss: 3.1397\nEpoch [30/100], Step [200/324], Discriminator Loss: 0.1780, Generator Loss: 4.2437\nEpoch [30/100], Step [210/324], Discriminator Loss: 0.1211, Generator Loss: 4.4848\nEpoch [30/100], Step [220/324], Discriminator Loss: 0.0006, Generator Loss: 4.2969\nEpoch [30/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.7620\nEpoch [30/100], Step [240/324], Discriminator Loss: 0.0005, Generator Loss: 4.0759\nEpoch [30/100], Step [250/324], Discriminator Loss: 0.5732, Generator Loss: 4.4514\nEpoch [30/100], Step [260/324], Discriminator Loss: 0.1466, Generator Loss: 4.4054\nEpoch [30/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 3.2379\nEpoch [30/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.7881\nEpoch [30/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 5.2263\nEpoch [30/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 4.6792\nEpoch [30/100], Step [310/324], Discriminator Loss: 0.0636, Generator Loss: 3.7578\nEpoch [30/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.8578\nEpoch [31/100], Step [0/324], Discriminator Loss: 0.0709, Generator Loss: 4.8962\nEpoch [31/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 3.8406\nEpoch [31/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 4.6210\nEpoch [31/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 3.5745\nEpoch [31/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.6992\nEpoch [31/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.5953\nEpoch [31/100], Step [60/324], Discriminator Loss: 0.2403, Generator Loss: 3.6747\nEpoch [31/100], Step [70/324], Discriminator Loss: 0.0633, Generator Loss: 5.0681\nEpoch [31/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 3.7397\nEpoch [31/100], Step [90/324], Discriminator Loss: 0.1717, Generator Loss: 5.1713\nEpoch [31/100], Step [100/324], Discriminator Loss: 0.2828, Generator Loss: 4.5794\nEpoch [31/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.7703\nEpoch [31/100], Step [120/324], Discriminator Loss: 0.2999, Generator Loss: 3.2965\nEpoch [31/100], Step [130/324], Discriminator Loss: 0.2337, Generator Loss: 5.4091\nEpoch [31/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 3.3514\nEpoch [31/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 4.3081\nEpoch [31/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.1988\nEpoch [31/100], Step [170/324], Discriminator Loss: 0.1518, Generator Loss: 3.2396\nEpoch [31/100], Step [180/324], Discriminator Loss: 0.3687, Generator Loss: 4.0063\nEpoch [31/100], Step [190/324], Discriminator Loss: 0.2444, Generator Loss: 4.7232\nEpoch [31/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 3.9308\nEpoch [31/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 4.4240\nEpoch [31/100], Step [220/324], Discriminator Loss: 0.0005, Generator Loss: 4.5466\nEpoch [31/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 3.7523\nEpoch [31/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.5369\nEpoch [31/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.6168\nEpoch [31/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 5.1503\nEpoch [31/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.4212\nEpoch [31/100], Step [280/324], Discriminator Loss: 0.2799, Generator Loss: 3.9651\nEpoch [31/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.4559\nEpoch [31/100], Step [300/324], Discriminator Loss: 0.0408, Generator Loss: 4.3943\nEpoch [31/100], Step [310/324], Discriminator Loss: 1.5625, Generator Loss: 5.8062\nEpoch [31/100], Step [320/324], Discriminator Loss: 0.0014, Generator Loss: 3.8709\nEpoch [32/100], Step [0/324], Discriminator Loss: 0.3184, Generator Loss: 4.0198\nEpoch [32/100], Step [10/324], Discriminator Loss: 0.4740, Generator Loss: 3.9304\nEpoch [32/100], Step [20/324], Discriminator Loss: 0.0005, Generator Loss: 4.3882\nEpoch [32/100], Step [30/324], Discriminator Loss: 0.0086, Generator Loss: 4.5245\nEpoch [32/100], Step [40/324], Discriminator Loss: 0.1401, Generator Loss: 4.3293\nEpoch [32/100], Step [50/324], Discriminator Loss: 0.2221, Generator Loss: 3.6882\nEpoch [32/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.0127\nEpoch [32/100], Step [70/324], Discriminator Loss: 0.0716, Generator Loss: 3.1189\nEpoch [32/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 4.5692\nEpoch [32/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.9913\nEpoch [32/100], Step [100/324], Discriminator Loss: 0.0003, Generator Loss: 4.1258\nEpoch [32/100], Step [110/324], Discriminator Loss: 0.0004, Generator Loss: 3.2989\nEpoch [32/100], Step [120/324], Discriminator Loss: 0.1703, Generator Loss: 4.6016\nEpoch [32/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 4.0600\nEpoch [32/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 4.1995\nEpoch [32/100], Step [150/324], Discriminator Loss: 0.1669, Generator Loss: 3.6267\nEpoch [32/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.9222\nEpoch [32/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 5.1819\nEpoch [32/100], Step [180/324], Discriminator Loss: 0.1750, Generator Loss: 3.6309\nEpoch [32/100], Step [190/324], Discriminator Loss: 0.4929, Generator Loss: 3.9094\nEpoch [32/100], Step [200/324], Discriminator Loss: 0.2487, Generator Loss: 3.6796\nEpoch [32/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.6991\nEpoch [32/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.9519\nEpoch [32/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 4.9105\nEpoch [32/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 5.4153\nEpoch [32/100], Step [250/324], Discriminator Loss: 0.0645, Generator Loss: 4.1995\nEpoch [32/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.3074\nEpoch [32/100], Step [270/324], Discriminator Loss: 0.1284, Generator Loss: 4.3066\nEpoch [32/100], Step [280/324], Discriminator Loss: 0.2100, Generator Loss: 4.9310\nEpoch [32/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 3.8278\nEpoch [32/100], Step [300/324], Discriminator Loss: 0.1005, Generator Loss: 6.0277\nEpoch [32/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 4.0091\nEpoch [32/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 3.4961\nEpoch [33/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.7000\nEpoch [33/100], Step [10/324], Discriminator Loss: 0.2486, Generator Loss: 3.8225\nEpoch [33/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 4.8851\nEpoch [33/100], Step [30/324], Discriminator Loss: 0.2336, Generator Loss: 3.9376\nEpoch [33/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 3.5951\nEpoch [33/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.9047\nEpoch [33/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.2472\nEpoch [33/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 3.8314\nEpoch [33/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 4.2007\nEpoch [33/100], Step [90/324], Discriminator Loss: 0.1881, Generator Loss: 4.3716\nEpoch [33/100], Step [100/324], Discriminator Loss: 0.0003, Generator Loss: 3.5547\nEpoch [33/100], Step [110/324], Discriminator Loss: 0.0657, Generator Loss: 4.4372\nEpoch [33/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.2116\nEpoch [33/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.0646\nEpoch [33/100], Step [140/324], Discriminator Loss: 0.1811, Generator Loss: 4.9156\nEpoch [33/100], Step [150/324], Discriminator Loss: 0.1243, Generator Loss: 4.6465\nEpoch [33/100], Step [160/324], Discriminator Loss: 0.0002, Generator Loss: 4.4820\nEpoch [33/100], Step [170/324], Discriminator Loss: 0.0003, Generator Loss: 3.8258\nEpoch [33/100], Step [180/324], Discriminator Loss: 0.0004, Generator Loss: 4.1220\nEpoch [33/100], Step [190/324], Discriminator Loss: 0.1542, Generator Loss: 4.6071\nEpoch [33/100], Step [200/324], Discriminator Loss: 0.0003, Generator Loss: 4.5208\nEpoch [33/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.9462\nEpoch [33/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.1541\nEpoch [33/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 4.0680\nEpoch [33/100], Step [240/324], Discriminator Loss: 0.0515, Generator Loss: 4.1212\nEpoch [33/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 4.0921\nEpoch [33/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.8528\nEpoch [33/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 3.7474\nEpoch [33/100], Step [280/324], Discriminator Loss: 0.4510, Generator Loss: 4.1600\nEpoch [33/100], Step [290/324], Discriminator Loss: 0.0613, Generator Loss: 4.6718\nEpoch [33/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 3.6987\nEpoch [33/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.3384\nEpoch [33/100], Step [320/324], Discriminator Loss: 0.1925, Generator Loss: 5.7482\nEpoch [34/100], Step [0/324], Discriminator Loss: 0.0009, Generator Loss: 4.1486\nEpoch [34/100], Step [10/324], Discriminator Loss: 0.2036, Generator Loss: 3.6933\nEpoch [34/100], Step [20/324], Discriminator Loss: 0.0007, Generator Loss: 2.8663\nEpoch [34/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.6637\nEpoch [34/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 4.0956\nEpoch [34/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 4.8324\nEpoch [34/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.5359\nEpoch [34/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 1.7428\nEpoch [34/100], Step [80/324], Discriminator Loss: 0.0007, Generator Loss: 6.9854\nEpoch [34/100], Step [90/324], Discriminator Loss: 0.0529, Generator Loss: 4.6377\nEpoch [34/100], Step [100/324], Discriminator Loss: 0.3480, Generator Loss: 4.0458\nEpoch [34/100], Step [110/324], Discriminator Loss: 0.0024, Generator Loss: 4.3966\nEpoch [34/100], Step [120/324], Discriminator Loss: 0.0031, Generator Loss: 5.1100\nEpoch [34/100], Step [130/324], Discriminator Loss: 0.0027, Generator Loss: 4.7387\nEpoch [34/100], Step [140/324], Discriminator Loss: 0.0027, Generator Loss: 3.4906\nEpoch [34/100], Step [150/324], Discriminator Loss: 0.2603, Generator Loss: 3.8107\nEpoch [34/100], Step [160/324], Discriminator Loss: 0.0032, Generator Loss: 4.3940\nEpoch [34/100], Step [170/324], Discriminator Loss: 0.0012, Generator Loss: 3.0776\nEpoch [34/100], Step [180/324], Discriminator Loss: 0.0003, Generator Loss: 4.5545\nEpoch [34/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 5.7286\nEpoch [34/100], Step [200/324], Discriminator Loss: 0.0004, Generator Loss: 3.4357\nEpoch [34/100], Step [210/324], Discriminator Loss: 0.0004, Generator Loss: 3.7810\nEpoch [34/100], Step [220/324], Discriminator Loss: 0.3195, Generator Loss: 4.7724\nEpoch [34/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 4.0633\nEpoch [34/100], Step [240/324], Discriminator Loss: 0.2523, Generator Loss: 4.3515\nEpoch [34/100], Step [250/324], Discriminator Loss: 0.0006, Generator Loss: 4.1538\nEpoch [34/100], Step [260/324], Discriminator Loss: 0.2569, Generator Loss: 3.9077\nEpoch [34/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 3.4558\nEpoch [34/100], Step [280/324], Discriminator Loss: 0.0005, Generator Loss: 4.5400\nEpoch [34/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.5166\nEpoch [34/100], Step [300/324], Discriminator Loss: 0.0014, Generator Loss: 3.2383\nEpoch [34/100], Step [310/324], Discriminator Loss: 0.1778, Generator Loss: 4.3787\nEpoch [34/100], Step [320/324], Discriminator Loss: 0.2698, Generator Loss: 4.4092\nEpoch [35/100], Step [0/324], Discriminator Loss: 0.2506, Generator Loss: 4.0208\nEpoch [35/100], Step [10/324], Discriminator Loss: 0.1775, Generator Loss: 4.4629\nEpoch [35/100], Step [20/324], Discriminator Loss: 0.1317, Generator Loss: 3.5136\nEpoch [35/100], Step [30/324], Discriminator Loss: 0.4307, Generator Loss: 3.9994\nEpoch [35/100], Step [40/324], Discriminator Loss: 0.0004, Generator Loss: 3.9013\nEpoch [35/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.9172\nEpoch [35/100], Step [60/324], Discriminator Loss: 0.0003, Generator Loss: 3.6900\nEpoch [35/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.3634\nEpoch [35/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 3.6692\nEpoch [35/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.9754\nEpoch [35/100], Step [100/324], Discriminator Loss: 0.2490, Generator Loss: 4.7300\nEpoch [35/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.8589\nEpoch [35/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 3.7542\nEpoch [35/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 4.1356\nEpoch [35/100], Step [140/324], Discriminator Loss: 0.2511, Generator Loss: 5.2561\nEpoch [35/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.6849\nEpoch [35/100], Step [160/324], Discriminator Loss: 0.4192, Generator Loss: 4.8426\nEpoch [35/100], Step [170/324], Discriminator Loss: 1.5627, Generator Loss: 3.9113\nEpoch [35/100], Step [180/324], Discriminator Loss: 0.0006, Generator Loss: 5.2723\nEpoch [35/100], Step [190/324], Discriminator Loss: 0.1859, Generator Loss: 3.5431\nEpoch [35/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 3.8556\nEpoch [35/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.3045\nEpoch [35/100], Step [220/324], Discriminator Loss: 0.0004, Generator Loss: 3.1517\nEpoch [35/100], Step [230/324], Discriminator Loss: 0.0930, Generator Loss: 4.4132\nEpoch [35/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 3.7764\nEpoch [35/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.5271\nEpoch [35/100], Step [260/324], Discriminator Loss: 0.0003, Generator Loss: 4.2306\nEpoch [35/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.7622\nEpoch [35/100], Step [280/324], Discriminator Loss: 0.4419, Generator Loss: 3.9315\nEpoch [35/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 4.2839\nEpoch [35/100], Step [300/324], Discriminator Loss: 0.0929, Generator Loss: 5.8554\nEpoch [35/100], Step [310/324], Discriminator Loss: 0.1686, Generator Loss: 3.9741\nEpoch [35/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 5.5528\nEpoch [36/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.7793\nEpoch [36/100], Step [10/324], Discriminator Loss: 0.1814, Generator Loss: 3.9089\nEpoch [36/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.9259\nEpoch [36/100], Step [30/324], Discriminator Loss: 0.1369, Generator Loss: 3.6041\nEpoch [36/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 3.4290\nEpoch [36/100], Step [50/324], Discriminator Loss: 0.0008, Generator Loss: 3.9666\nEpoch [36/100], Step [60/324], Discriminator Loss: 0.0003, Generator Loss: 5.1161\nEpoch [36/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 3.2480\nEpoch [36/100], Step [80/324], Discriminator Loss: 0.0003, Generator Loss: 3.9589\nEpoch [36/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.1174\nEpoch [36/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.1454\nEpoch [36/100], Step [110/324], Discriminator Loss: 0.2330, Generator Loss: 3.9622\nEpoch [36/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 4.7512\nEpoch [36/100], Step [130/324], Discriminator Loss: 0.2779, Generator Loss: 5.7191\nEpoch [36/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 3.3151\nEpoch [36/100], Step [150/324], Discriminator Loss: 0.1064, Generator Loss: 3.9856\nEpoch [36/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.3460\nEpoch [36/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 3.7693\nEpoch [36/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.7857\nEpoch [36/100], Step [190/324], Discriminator Loss: 0.0004, Generator Loss: 5.2902\nEpoch [36/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.1937\nEpoch [36/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.6002\nEpoch [36/100], Step [220/324], Discriminator Loss: 0.2066, Generator Loss: 3.4773\nEpoch [36/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.6866\nEpoch [36/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 3.7178\nEpoch [36/100], Step [250/324], Discriminator Loss: 0.1973, Generator Loss: 4.4636\nEpoch [36/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 3.8203\nEpoch [36/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 3.6875\nEpoch [36/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.7352\nEpoch [36/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 4.6801\nEpoch [36/100], Step [300/324], Discriminator Loss: 0.1257, Generator Loss: 3.8692\nEpoch [36/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.7050\nEpoch [36/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 5.3463\nEpoch [37/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 5.4101\nEpoch [37/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 4.9469\nEpoch [37/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 5.0205\nEpoch [37/100], Step [30/324], Discriminator Loss: 0.1490, Generator Loss: 4.7852\nEpoch [37/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 3.4790\nEpoch [37/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 4.7286\nEpoch [37/100], Step [60/324], Discriminator Loss: 0.2361, Generator Loss: 4.5835\nEpoch [37/100], Step [70/324], Discriminator Loss: 1.9623, Generator Loss: 4.4019\nEpoch [37/100], Step [80/324], Discriminator Loss: 0.0433, Generator Loss: 3.4618\nEpoch [37/100], Step [90/324], Discriminator Loss: 0.0003, Generator Loss: 5.0552\nEpoch [37/100], Step [100/324], Discriminator Loss: 0.3451, Generator Loss: 3.7498\nEpoch [37/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.8782\nEpoch [37/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.3263\nEpoch [37/100], Step [130/324], Discriminator Loss: 0.3079, Generator Loss: 3.6904\nEpoch [37/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 3.9131\nEpoch [37/100], Step [150/324], Discriminator Loss: 0.0003, Generator Loss: 4.2492\nEpoch [37/100], Step [160/324], Discriminator Loss: 0.3067, Generator Loss: 4.4507\nEpoch [37/100], Step [170/324], Discriminator Loss: 0.4222, Generator Loss: 4.0615\nEpoch [37/100], Step [180/324], Discriminator Loss: 0.0003, Generator Loss: 4.7106\nEpoch [37/100], Step [190/324], Discriminator Loss: 0.2874, Generator Loss: 3.3862\nEpoch [37/100], Step [200/324], Discriminator Loss: 0.8679, Generator Loss: 4.4518\nEpoch [37/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.7443\nEpoch [37/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 4.2091\nEpoch [37/100], Step [230/324], Discriminator Loss: 0.2360, Generator Loss: 4.7654\nEpoch [37/100], Step [240/324], Discriminator Loss: 0.3901, Generator Loss: 3.2694\nEpoch [37/100], Step [250/324], Discriminator Loss: 0.1890, Generator Loss: 4.2277\nEpoch [37/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.2427\nEpoch [37/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 3.4766\nEpoch [37/100], Step [280/324], Discriminator Loss: 0.0479, Generator Loss: 3.5083\nEpoch [37/100], Step [290/324], Discriminator Loss: 0.0588, Generator Loss: 3.8744\nEpoch [37/100], Step [300/324], Discriminator Loss: 0.0003, Generator Loss: 4.7968\nEpoch [37/100], Step [310/324], Discriminator Loss: 0.0003, Generator Loss: 4.1922\nEpoch [37/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.6252\nEpoch [38/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 5.2191\nEpoch [38/100], Step [10/324], Discriminator Loss: 0.1707, Generator Loss: 4.7600\nEpoch [38/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.2193\nEpoch [38/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 5.0511\nEpoch [38/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.2736\nEpoch [38/100], Step [60/324], Discriminator Loss: 0.0006, Generator Loss: 4.4198\nEpoch [38/100], Step [70/324], Discriminator Loss: 0.1481, Generator Loss: 3.1491\nEpoch [38/100], Step [80/324], Discriminator Loss: 0.0992, Generator Loss: 5.0013\nEpoch [38/100], Step [90/324], Discriminator Loss: 0.0700, Generator Loss: 3.3829\nEpoch [38/100], Step [100/324], Discriminator Loss: 0.0006, Generator Loss: 4.3839\nEpoch [38/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.2554\nEpoch [38/100], Step [120/324], Discriminator Loss: 0.1389, Generator Loss: 3.3875\nEpoch [38/100], Step [130/324], Discriminator Loss: 0.0013, Generator Loss: 3.7414\nEpoch [38/100], Step [140/324], Discriminator Loss: 0.2602, Generator Loss: 4.2415\nEpoch [38/100], Step [150/324], Discriminator Loss: 0.4068, Generator Loss: 4.8276\nEpoch [38/100], Step [160/324], Discriminator Loss: 0.0026, Generator Loss: 4.6074\nEpoch [38/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.0518\nEpoch [38/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 5.1847\nEpoch [38/100], Step [190/324], Discriminator Loss: 0.0772, Generator Loss: 3.3469\nEpoch [38/100], Step [200/324], Discriminator Loss: 0.3129, Generator Loss: 4.6882\nEpoch [38/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.9459\nEpoch [38/100], Step [220/324], Discriminator Loss: 0.2230, Generator Loss: 4.9388\nEpoch [38/100], Step [230/324], Discriminator Loss: 0.0352, Generator Loss: 3.4167\nEpoch [38/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.0188\nEpoch [38/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.9813\nEpoch [38/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.9737\nEpoch [38/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.2792\nEpoch [38/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 4.7146\nEpoch [38/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.1857\nEpoch [38/100], Step [300/324], Discriminator Loss: 0.2062, Generator Loss: 4.5588\nEpoch [38/100], Step [310/324], Discriminator Loss: 0.0462, Generator Loss: 4.2839\nEpoch [38/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.6827\nEpoch [39/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 5.2895\nEpoch [39/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 4.3665\nEpoch [39/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 4.4413\nEpoch [39/100], Step [30/324], Discriminator Loss: 0.0432, Generator Loss: 3.6572\nEpoch [39/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.4262\nEpoch [39/100], Step [50/324], Discriminator Loss: 0.2393, Generator Loss: 4.7492\nEpoch [39/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.5709\nEpoch [39/100], Step [70/324], Discriminator Loss: 0.0860, Generator Loss: 2.8688\nEpoch [39/100], Step [80/324], Discriminator Loss: 0.0004, Generator Loss: 5.2917\nEpoch [39/100], Step [90/324], Discriminator Loss: 0.0675, Generator Loss: 3.4907\nEpoch [39/100], Step [100/324], Discriminator Loss: 0.0002, Generator Loss: 4.0244\nEpoch [39/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.6916\nEpoch [39/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.2282\nEpoch [39/100], Step [130/324], Discriminator Loss: 0.0369, Generator Loss: 4.4379\nEpoch [39/100], Step [140/324], Discriminator Loss: 0.2242, Generator Loss: 5.0333\nEpoch [39/100], Step [150/324], Discriminator Loss: 0.0003, Generator Loss: 4.9463\nEpoch [39/100], Step [160/324], Discriminator Loss: 0.0010, Generator Loss: 4.3815\nEpoch [39/100], Step [170/324], Discriminator Loss: 0.0010, Generator Loss: 4.1369\nEpoch [39/100], Step [180/324], Discriminator Loss: 0.3674, Generator Loss: 3.4063\nEpoch [39/100], Step [190/324], Discriminator Loss: 0.0004, Generator Loss: 4.1899\nEpoch [39/100], Step [200/324], Discriminator Loss: 0.0003, Generator Loss: 4.3914\nEpoch [39/100], Step [210/324], Discriminator Loss: 0.0334, Generator Loss: 3.5707\nEpoch [39/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 5.5816\nEpoch [39/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 8.5905\nEpoch [39/100], Step [240/324], Discriminator Loss: 0.2899, Generator Loss: 4.3182\nEpoch [39/100], Step [250/324], Discriminator Loss: 0.0424, Generator Loss: 3.7212\nEpoch [39/100], Step [260/324], Discriminator Loss: 0.0019, Generator Loss: 4.6394\nEpoch [39/100], Step [270/324], Discriminator Loss: 0.0029, Generator Loss: 4.9640\nEpoch [39/100], Step [280/324], Discriminator Loss: 0.0044, Generator Loss: 4.3147\nEpoch [39/100], Step [290/324], Discriminator Loss: 0.3702, Generator Loss: 4.4668\nEpoch [39/100], Step [300/324], Discriminator Loss: 0.0010, Generator Loss: 5.6433\nEpoch [39/100], Step [310/324], Discriminator Loss: 0.2802, Generator Loss: 4.5370\nEpoch [39/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 5.8247\nEpoch [40/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.9812\nEpoch [40/100], Step [10/324], Discriminator Loss: 0.2217, Generator Loss: 4.1226\nEpoch [40/100], Step [20/324], Discriminator Loss: 0.0008, Generator Loss: 4.0828\nEpoch [40/100], Step [30/324], Discriminator Loss: 0.0005, Generator Loss: 4.6923\nEpoch [40/100], Step [40/324], Discriminator Loss: 0.3757, Generator Loss: 4.9938\nEpoch [40/100], Step [50/324], Discriminator Loss: 0.2247, Generator Loss: 3.7585\nEpoch [40/100], Step [60/324], Discriminator Loss: 0.1343, Generator Loss: 3.6648\nEpoch [40/100], Step [70/324], Discriminator Loss: 0.2246, Generator Loss: 3.8750\nEpoch [40/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.1278\nEpoch [40/100], Step [90/324], Discriminator Loss: 0.2476, Generator Loss: 5.6031\nEpoch [40/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.4610\nEpoch [40/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.3371\nEpoch [40/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 3.2309\nEpoch [40/100], Step [130/324], Discriminator Loss: 0.0566, Generator Loss: 4.4244\nEpoch [40/100], Step [140/324], Discriminator Loss: 0.1177, Generator Loss: 4.3585\nEpoch [40/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 4.1748\nEpoch [40/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.8208\nEpoch [40/100], Step [170/324], Discriminator Loss: 0.4367, Generator Loss: 3.7040\nEpoch [40/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.5372\nEpoch [40/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 5.6358\nEpoch [40/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.0683\nEpoch [40/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 5.2868\nEpoch [40/100], Step [220/324], Discriminator Loss: 0.1069, Generator Loss: 4.2734\nEpoch [40/100], Step [230/324], Discriminator Loss: 0.0038, Generator Loss: 3.6852\nEpoch [40/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 5.2466\nEpoch [40/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.8765\nEpoch [40/100], Step [260/324], Discriminator Loss: 0.0208, Generator Loss: 4.7770\nEpoch [40/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.5811\nEpoch [40/100], Step [280/324], Discriminator Loss: 0.0005, Generator Loss: 3.4725\nEpoch [40/100], Step [290/324], Discriminator Loss: 0.2281, Generator Loss: 3.6303\nEpoch [40/100], Step [300/324], Discriminator Loss: 0.4323, Generator Loss: 3.9198\nEpoch [40/100], Step [310/324], Discriminator Loss: 0.0112, Generator Loss: 4.1489\nEpoch [40/100], Step [320/324], Discriminator Loss: 0.0171, Generator Loss: 5.3440\nEpoch [41/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 5.7369\nEpoch [41/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 5.6327\nEpoch [41/100], Step [20/324], Discriminator Loss: 0.0674, Generator Loss: 6.6268\nEpoch [41/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 5.0141\nEpoch [41/100], Step [40/324], Discriminator Loss: 0.0222, Generator Loss: 3.8140\nEpoch [41/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.2630\nEpoch [41/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.9363\nEpoch [41/100], Step [70/324], Discriminator Loss: 0.0728, Generator Loss: 4.2374\nEpoch [41/100], Step [80/324], Discriminator Loss: 0.0003, Generator Loss: 4.2908\nEpoch [41/100], Step [90/324], Discriminator Loss: 0.0004, Generator Loss: 4.2656\nEpoch [41/100], Step [100/324], Discriminator Loss: 0.1802, Generator Loss: 3.5570\nEpoch [41/100], Step [110/324], Discriminator Loss: 0.0002, Generator Loss: 4.6609\nEpoch [41/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.9082\nEpoch [41/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.4396\nEpoch [41/100], Step [140/324], Discriminator Loss: 0.2819, Generator Loss: 2.9868\nEpoch [41/100], Step [150/324], Discriminator Loss: 0.0637, Generator Loss: 4.4391\nEpoch [41/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.8027\nEpoch [41/100], Step [170/324], Discriminator Loss: 0.0881, Generator Loss: 3.6150\nEpoch [41/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.3355\nEpoch [41/100], Step [190/324], Discriminator Loss: 0.0007, Generator Loss: 2.6983\nEpoch [41/100], Step [200/324], Discriminator Loss: 0.0599, Generator Loss: 4.3099\nEpoch [41/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.3366\nEpoch [41/100], Step [220/324], Discriminator Loss: 0.2726, Generator Loss: 4.1205\nEpoch [41/100], Step [230/324], Discriminator Loss: 0.0132, Generator Loss: 3.6458\nEpoch [41/100], Step [240/324], Discriminator Loss: 0.1556, Generator Loss: 3.9231\nEpoch [41/100], Step [250/324], Discriminator Loss: 0.1726, Generator Loss: 3.9643\nEpoch [41/100], Step [260/324], Discriminator Loss: 0.0003, Generator Loss: 4.8452\nEpoch [41/100], Step [270/324], Discriminator Loss: 0.6174, Generator Loss: 4.6745\nEpoch [41/100], Step [280/324], Discriminator Loss: 0.0003, Generator Loss: 3.7634\nEpoch [41/100], Step [290/324], Discriminator Loss: 0.0003, Generator Loss: 4.3653\nEpoch [41/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.7211\nEpoch [41/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 3.4239\nEpoch [41/100], Step [320/324], Discriminator Loss: 0.1138, Generator Loss: 6.9631\nEpoch [42/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 5.6285\nEpoch [42/100], Step [10/324], Discriminator Loss: 0.0003, Generator Loss: 3.9304\nEpoch [42/100], Step [20/324], Discriminator Loss: 0.0010, Generator Loss: 4.0468\nEpoch [42/100], Step [30/324], Discriminator Loss: 0.0005, Generator Loss: 3.0189\nEpoch [42/100], Step [40/324], Discriminator Loss: 0.0004, Generator Loss: 3.7004\nEpoch [42/100], Step [50/324], Discriminator Loss: 0.0565, Generator Loss: 3.4111\nEpoch [42/100], Step [60/324], Discriminator Loss: 0.1345, Generator Loss: 4.7897\nEpoch [42/100], Step [70/324], Discriminator Loss: 0.2011, Generator Loss: 4.8181\nEpoch [42/100], Step [80/324], Discriminator Loss: 0.0006, Generator Loss: 3.1606\nEpoch [42/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 4.0003\nEpoch [42/100], Step [100/324], Discriminator Loss: 0.1598, Generator Loss: 3.9033\nEpoch [42/100], Step [110/324], Discriminator Loss: 0.1137, Generator Loss: 3.6274\nEpoch [42/100], Step [120/324], Discriminator Loss: 0.3515, Generator Loss: 4.7642\nEpoch [42/100], Step [130/324], Discriminator Loss: 0.1257, Generator Loss: 3.7859\nEpoch [42/100], Step [140/324], Discriminator Loss: 0.2239, Generator Loss: 4.2761\nEpoch [42/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.5054\nEpoch [42/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.4110\nEpoch [42/100], Step [170/324], Discriminator Loss: 0.0806, Generator Loss: 4.7146\nEpoch [42/100], Step [180/324], Discriminator Loss: 0.5705, Generator Loss: 4.1888\nEpoch [42/100], Step [190/324], Discriminator Loss: 0.1751, Generator Loss: 3.4367\nEpoch [42/100], Step [200/324], Discriminator Loss: 0.0021, Generator Loss: 3.8955\nEpoch [42/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 3.7440\nEpoch [42/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.6791\nEpoch [42/100], Step [230/324], Discriminator Loss: 0.2874, Generator Loss: 3.9478\nEpoch [42/100], Step [240/324], Discriminator Loss: 0.3372, Generator Loss: 4.2695\nEpoch [42/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.1723\nEpoch [42/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.7701\nEpoch [42/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.1809\nEpoch [42/100], Step [280/324], Discriminator Loss: 0.0003, Generator Loss: 3.7659\nEpoch [42/100], Step [290/324], Discriminator Loss: 0.0325, Generator Loss: 2.4116\nEpoch [42/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 6.4429\nEpoch [42/100], Step [310/324], Discriminator Loss: 0.2317, Generator Loss: 6.1159\nEpoch [42/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.8720\nEpoch [43/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.9267\nEpoch [43/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.5545\nEpoch [43/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 4.2280\nEpoch [43/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 3.9449\nEpoch [43/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.6730\nEpoch [43/100], Step [50/324], Discriminator Loss: 0.1858, Generator Loss: 4.2646\nEpoch [43/100], Step [60/324], Discriminator Loss: 0.3656, Generator Loss: 3.8906\nEpoch [43/100], Step [70/324], Discriminator Loss: 0.0341, Generator Loss: 3.7430\nEpoch [43/100], Step [80/324], Discriminator Loss: 0.1369, Generator Loss: 3.7366\nEpoch [43/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.9585\nEpoch [43/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 5.7961\nEpoch [43/100], Step [110/324], Discriminator Loss: 0.6425, Generator Loss: 4.5848\nEpoch [43/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.7916\nEpoch [43/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.3244\nEpoch [43/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 3.8792\nEpoch [43/100], Step [150/324], Discriminator Loss: 0.1305, Generator Loss: 3.3206\nEpoch [43/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.8858\nEpoch [43/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 3.7232\nEpoch [43/100], Step [180/324], Discriminator Loss: 0.2619, Generator Loss: 3.7109\nEpoch [43/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.4886\nEpoch [43/100], Step [200/324], Discriminator Loss: 0.1210, Generator Loss: 3.6870\nEpoch [43/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 3.3136\nEpoch [43/100], Step [220/324], Discriminator Loss: 0.1026, Generator Loss: 3.9450\nEpoch [43/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 4.1493\nEpoch [43/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.1575\nEpoch [43/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.1940\nEpoch [43/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.8454\nEpoch [43/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 3.9228\nEpoch [43/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 3.6021\nEpoch [43/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.6747\nEpoch [43/100], Step [300/324], Discriminator Loss: 0.2065, Generator Loss: 4.1083\nEpoch [43/100], Step [310/324], Discriminator Loss: 0.1019, Generator Loss: 3.9409\nEpoch [43/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.5534\nEpoch [44/100], Step [0/324], Discriminator Loss: 0.5555, Generator Loss: 4.3384\nEpoch [44/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 4.4702\nEpoch [44/100], Step [20/324], Discriminator Loss: 0.0605, Generator Loss: 3.8545\nEpoch [44/100], Step [30/324], Discriminator Loss: 0.3441, Generator Loss: 3.9595\nEpoch [44/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.2133\nEpoch [44/100], Step [50/324], Discriminator Loss: 0.1579, Generator Loss: 3.3974\nEpoch [44/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.8312\nEpoch [44/100], Step [70/324], Discriminator Loss: 0.1286, Generator Loss: 4.2434\nEpoch [44/100], Step [80/324], Discriminator Loss: 0.1950, Generator Loss: 3.8325\nEpoch [44/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 4.6386\nEpoch [44/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.3857\nEpoch [44/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.8441\nEpoch [44/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 3.9197\nEpoch [44/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 2.8594\nEpoch [44/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.3143\nEpoch [44/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 4.4688\nEpoch [44/100], Step [160/324], Discriminator Loss: 0.1589, Generator Loss: 3.7707\nEpoch [44/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.1881\nEpoch [44/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 2.8415\nEpoch [44/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.4207\nEpoch [44/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.5848\nEpoch [44/100], Step [210/324], Discriminator Loss: 0.2854, Generator Loss: 3.6047\nEpoch [44/100], Step [220/324], Discriminator Loss: 0.0944, Generator Loss: 3.9087\nEpoch [44/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 5.3213\nEpoch [44/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.7886\nEpoch [44/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.4925\nEpoch [44/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.9394\nEpoch [44/100], Step [270/324], Discriminator Loss: 0.0107, Generator Loss: 4.7948\nEpoch [44/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 5.3575\nEpoch [44/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 6.0678\nEpoch [44/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 4.1027\nEpoch [44/100], Step [310/324], Discriminator Loss: 0.2239, Generator Loss: 4.3449\nEpoch [44/100], Step [320/324], Discriminator Loss: 0.0004, Generator Loss: 4.8368\nEpoch [45/100], Step [0/324], Discriminator Loss: 0.0932, Generator Loss: 5.1999\nEpoch [45/100], Step [10/324], Discriminator Loss: 0.0013, Generator Loss: 4.6744\nEpoch [45/100], Step [20/324], Discriminator Loss: 0.0015, Generator Loss: 4.5455\nEpoch [45/100], Step [30/324], Discriminator Loss: 0.0004, Generator Loss: 5.7906\nEpoch [45/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 4.1956\nEpoch [45/100], Step [50/324], Discriminator Loss: 0.0004, Generator Loss: 3.9601\nEpoch [45/100], Step [60/324], Discriminator Loss: 1.5627, Generator Loss: 4.4671\nEpoch [45/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 4.1807\nEpoch [45/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.1074\nEpoch [45/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.8146\nEpoch [45/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 3.5025\nEpoch [45/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.0990\nEpoch [45/100], Step [120/324], Discriminator Loss: 0.1767, Generator Loss: 4.7398\nEpoch [45/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 3.7975\nEpoch [45/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 4.0068\nEpoch [45/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 4.6410\nEpoch [45/100], Step [160/324], Discriminator Loss: 0.1890, Generator Loss: 4.0632\nEpoch [45/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 3.7425\nEpoch [45/100], Step [180/324], Discriminator Loss: 0.0003, Generator Loss: 3.9379\nEpoch [45/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 5.1775\nEpoch [45/100], Step [200/324], Discriminator Loss: 0.2805, Generator Loss: 2.7091\nEpoch [45/100], Step [210/324], Discriminator Loss: 0.0119, Generator Loss: 4.1935\nEpoch [45/100], Step [220/324], Discriminator Loss: 0.4749, Generator Loss: 4.5927\nEpoch [45/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.7815\nEpoch [45/100], Step [240/324], Discriminator Loss: 0.0008, Generator Loss: 4.5369\nEpoch [45/100], Step [250/324], Discriminator Loss: 0.0006, Generator Loss: 3.5575\nEpoch [45/100], Step [260/324], Discriminator Loss: 0.0031, Generator Loss: 3.7344\nEpoch [45/100], Step [270/324], Discriminator Loss: 0.0004, Generator Loss: 4.1284\nEpoch [45/100], Step [280/324], Discriminator Loss: 0.0005, Generator Loss: 3.4297\nEpoch [45/100], Step [290/324], Discriminator Loss: 0.0004, Generator Loss: 4.3170\nEpoch [45/100], Step [300/324], Discriminator Loss: 0.1141, Generator Loss: 3.3044\nEpoch [45/100], Step [310/324], Discriminator Loss: 0.0508, Generator Loss: 4.3966\nEpoch [45/100], Step [320/324], Discriminator Loss: 0.2101, Generator Loss: 3.9001\nEpoch [46/100], Step [0/324], Discriminator Loss: 0.0007, Generator Loss: 3.4824\nEpoch [46/100], Step [10/324], Discriminator Loss: 0.4324, Generator Loss: 3.3489\nEpoch [46/100], Step [20/324], Discriminator Loss: 0.0004, Generator Loss: 3.5539\nEpoch [46/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.1924\nEpoch [46/100], Step [40/324], Discriminator Loss: 0.0005, Generator Loss: 3.7198\nEpoch [46/100], Step [50/324], Discriminator Loss: 0.0003, Generator Loss: 3.4394\nEpoch [46/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.2055\nEpoch [46/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.8438\nEpoch [46/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 3.9576\nEpoch [46/100], Step [90/324], Discriminator Loss: 0.3799, Generator Loss: 5.0563\nEpoch [46/100], Step [100/324], Discriminator Loss: 0.0003, Generator Loss: 4.3890\nEpoch [46/100], Step [110/324], Discriminator Loss: 0.0706, Generator Loss: 4.6668\nEpoch [46/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.1802\nEpoch [46/100], Step [130/324], Discriminator Loss: 0.1778, Generator Loss: 3.8288\nEpoch [46/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 4.0319\nEpoch [46/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 4.4449\nEpoch [46/100], Step [160/324], Discriminator Loss: 0.0897, Generator Loss: 3.3293\nEpoch [46/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 3.3456\nEpoch [46/100], Step [180/324], Discriminator Loss: 0.1470, Generator Loss: 4.4686\nEpoch [46/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.1803\nEpoch [46/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 3.6981\nEpoch [46/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.5898\nEpoch [46/100], Step [220/324], Discriminator Loss: 0.0007, Generator Loss: 3.5235\nEpoch [46/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 4.3214\nEpoch [46/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.3542\nEpoch [46/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.7416\nEpoch [46/100], Step [260/324], Discriminator Loss: 0.2504, Generator Loss: 3.8828\nEpoch [46/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 4.1277\nEpoch [46/100], Step [280/324], Discriminator Loss: 0.2327, Generator Loss: 3.1659\nEpoch [46/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 3.7006\nEpoch [46/100], Step [300/324], Discriminator Loss: 0.0003, Generator Loss: 4.9399\nEpoch [46/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 5.5138\nEpoch [46/100], Step [320/324], Discriminator Loss: 0.0004, Generator Loss: 3.4353\nEpoch [47/100], Step [0/324], Discriminator Loss: 0.0010, Generator Loss: 3.3640\nEpoch [47/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 3.5426\nEpoch [47/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.0199\nEpoch [47/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.3109\nEpoch [47/100], Step [40/324], Discriminator Loss: 0.0665, Generator Loss: 5.1600\nEpoch [47/100], Step [50/324], Discriminator Loss: 0.0014, Generator Loss: 3.7614\nEpoch [47/100], Step [60/324], Discriminator Loss: 0.3599, Generator Loss: 4.2746\nEpoch [47/100], Step [70/324], Discriminator Loss: 0.1344, Generator Loss: 3.7580\nEpoch [47/100], Step [80/324], Discriminator Loss: 0.1427, Generator Loss: 2.9852\nEpoch [47/100], Step [90/324], Discriminator Loss: 0.0006, Generator Loss: 4.8234\nEpoch [47/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.4428\nEpoch [47/100], Step [110/324], Discriminator Loss: 0.0002, Generator Loss: 3.3676\nEpoch [47/100], Step [120/324], Discriminator Loss: 0.1754, Generator Loss: 3.9803\nEpoch [47/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.4051\nEpoch [47/100], Step [140/324], Discriminator Loss: 0.1715, Generator Loss: 4.4641\nEpoch [47/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.5298\nEpoch [47/100], Step [160/324], Discriminator Loss: 0.1166, Generator Loss: 3.0765\nEpoch [47/100], Step [170/324], Discriminator Loss: 0.3258, Generator Loss: 4.6158\nEpoch [47/100], Step [180/324], Discriminator Loss: 0.1294, Generator Loss: 4.2531\nEpoch [47/100], Step [190/324], Discriminator Loss: 0.1718, Generator Loss: 4.9656\nEpoch [47/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 5.3721\nEpoch [47/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 5.7948\nEpoch [47/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.2010\nEpoch [47/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.4154\nEpoch [47/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.7449\nEpoch [47/100], Step [250/324], Discriminator Loss: 0.1800, Generator Loss: 3.4128\nEpoch [47/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.5334\nEpoch [47/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.3780\nEpoch [47/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 4.4404\nEpoch [47/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 3.4125\nEpoch [47/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 4.9697\nEpoch [47/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.5612\nEpoch [47/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 5.0759\nEpoch [48/100], Step [0/324], Discriminator Loss: 0.2301, Generator Loss: 3.8511\nEpoch [48/100], Step [10/324], Discriminator Loss: 0.5482, Generator Loss: 4.1834\nEpoch [48/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.6128\nEpoch [48/100], Step [30/324], Discriminator Loss: 0.1422, Generator Loss: 4.1652\nEpoch [48/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 4.8358\nEpoch [48/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.2465\nEpoch [48/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.4000\nEpoch [48/100], Step [70/324], Discriminator Loss: 0.3956, Generator Loss: 3.7363\nEpoch [48/100], Step [80/324], Discriminator Loss: 0.0007, Generator Loss: 3.4072\nEpoch [48/100], Step [90/324], Discriminator Loss: 0.0003, Generator Loss: 3.6543\nEpoch [48/100], Step [100/324], Discriminator Loss: 0.2111, Generator Loss: 3.9180\nEpoch [48/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.5847\nEpoch [48/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 5.2413\nEpoch [48/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.2207\nEpoch [48/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 5.9312\nEpoch [48/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 4.3549\nEpoch [48/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.8794\nEpoch [48/100], Step [170/324], Discriminator Loss: 0.3335, Generator Loss: 4.4514\nEpoch [48/100], Step [180/324], Discriminator Loss: 0.1706, Generator Loss: 3.7392\nEpoch [48/100], Step [190/324], Discriminator Loss: 0.0003, Generator Loss: 2.8634\nEpoch [48/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.8904\nEpoch [48/100], Step [210/324], Discriminator Loss: 0.2445, Generator Loss: 4.0515\nEpoch [48/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 5.1879\nEpoch [48/100], Step [230/324], Discriminator Loss: 0.1859, Generator Loss: 6.2589\nEpoch [48/100], Step [240/324], Discriminator Loss: 0.1043, Generator Loss: 3.3731\nEpoch [48/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 4.3391\nEpoch [48/100], Step [260/324], Discriminator Loss: 0.0002, Generator Loss: 2.8505\nEpoch [48/100], Step [270/324], Discriminator Loss: 0.1772, Generator Loss: 3.8128\nEpoch [48/100], Step [280/324], Discriminator Loss: 0.1573, Generator Loss: 4.4537\nEpoch [48/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 3.6957\nEpoch [48/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 3.5819\nEpoch [48/100], Step [310/324], Discriminator Loss: 0.2194, Generator Loss: 4.4434\nEpoch [48/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 5.0844\nEpoch [49/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 4.1792\nEpoch [49/100], Step [10/324], Discriminator Loss: 0.0587, Generator Loss: 3.7753\nEpoch [49/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 3.6815\nEpoch [49/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.3242\nEpoch [49/100], Step [40/324], Discriminator Loss: 0.2059, Generator Loss: 3.6899\nEpoch [49/100], Step [50/324], Discriminator Loss: 0.1713, Generator Loss: 3.8384\nEpoch [49/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.5433\nEpoch [49/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.1646\nEpoch [49/100], Step [80/324], Discriminator Loss: 0.6164, Generator Loss: 4.6775\nEpoch [49/100], Step [90/324], Discriminator Loss: 0.0009, Generator Loss: 4.9342\nEpoch [49/100], Step [100/324], Discriminator Loss: 0.1836, Generator Loss: 3.9308\nEpoch [49/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.6058\nEpoch [49/100], Step [120/324], Discriminator Loss: 0.2436, Generator Loss: 4.3356\nEpoch [49/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.2166\nEpoch [49/100], Step [140/324], Discriminator Loss: 0.0913, Generator Loss: 4.1593\nEpoch [49/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 3.4977\nEpoch [49/100], Step [160/324], Discriminator Loss: 0.2480, Generator Loss: 4.4399\nEpoch [49/100], Step [170/324], Discriminator Loss: 0.1752, Generator Loss: 4.4626\nEpoch [49/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.6806\nEpoch [49/100], Step [190/324], Discriminator Loss: 0.0314, Generator Loss: 3.4892\nEpoch [49/100], Step [200/324], Discriminator Loss: 0.0006, Generator Loss: 4.9113\nEpoch [49/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 5.2095\nEpoch [49/100], Step [220/324], Discriminator Loss: 0.3950, Generator Loss: 3.6383\nEpoch [49/100], Step [230/324], Discriminator Loss: 0.0081, Generator Loss: 4.7810\nEpoch [49/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 5.1559\nEpoch [49/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 6.7972\nEpoch [49/100], Step [260/324], Discriminator Loss: 0.0757, Generator Loss: 2.1938\nEpoch [49/100], Step [270/324], Discriminator Loss: 0.0335, Generator Loss: 6.2233\nEpoch [49/100], Step [280/324], Discriminator Loss: 0.0011, Generator Loss: 3.9579\nEpoch [49/100], Step [290/324], Discriminator Loss: 0.0023, Generator Loss: 4.4466\nEpoch [49/100], Step [300/324], Discriminator Loss: 0.0670, Generator Loss: 4.3635\nEpoch [49/100], Step [310/324], Discriminator Loss: 0.0072, Generator Loss: 5.1434\nEpoch [49/100], Step [320/324], Discriminator Loss: 0.2310, Generator Loss: 5.0124\nEpoch [50/100], Step [0/324], Discriminator Loss: 0.0026, Generator Loss: 4.3115\nEpoch [50/100], Step [10/324], Discriminator Loss: 0.1723, Generator Loss: 4.0922\nEpoch [50/100], Step [20/324], Discriminator Loss: 0.0458, Generator Loss: 4.1119\nEpoch [50/100], Step [30/324], Discriminator Loss: 0.0007, Generator Loss: 4.4056\nEpoch [50/100], Step [40/324], Discriminator Loss: 0.0007, Generator Loss: 3.9694\nEpoch [50/100], Step [50/324], Discriminator Loss: 0.0003, Generator Loss: 4.1523\nEpoch [50/100], Step [60/324], Discriminator Loss: 0.2123, Generator Loss: 3.6991\nEpoch [50/100], Step [70/324], Discriminator Loss: 0.3641, Generator Loss: 4.3900\nEpoch [50/100], Step [80/324], Discriminator Loss: 0.4433, Generator Loss: 3.3327\nEpoch [50/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 4.2052\nEpoch [50/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 5.1317\nEpoch [50/100], Step [110/324], Discriminator Loss: 0.1983, Generator Loss: 3.8210\nEpoch [50/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.1375\nEpoch [50/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.1561\nEpoch [50/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.6231\nEpoch [50/100], Step [150/324], Discriminator Loss: 0.0010, Generator Loss: 3.3892\nEpoch [50/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 5.2058\nEpoch [50/100], Step [170/324], Discriminator Loss: 0.2747, Generator Loss: 3.8400\nEpoch [50/100], Step [180/324], Discriminator Loss: 0.0003, Generator Loss: 4.2933\nEpoch [50/100], Step [190/324], Discriminator Loss: 0.2681, Generator Loss: 3.5854\nEpoch [50/100], Step [200/324], Discriminator Loss: 0.0003, Generator Loss: 3.6139\nEpoch [50/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 4.9937\nEpoch [50/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.9977\nEpoch [50/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.7649\nEpoch [50/100], Step [240/324], Discriminator Loss: 0.0009, Generator Loss: 3.4305\nEpoch [50/100], Step [250/324], Discriminator Loss: 0.1338, Generator Loss: 2.9733\nEpoch [50/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.8946\nEpoch [50/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.4069\nEpoch [50/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.8553\nEpoch [50/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 5.1492\nEpoch [50/100], Step [300/324], Discriminator Loss: 0.1378, Generator Loss: 3.2126\nEpoch [50/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.0248\nEpoch [50/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 3.9311\nEpoch [51/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 3.8661\nEpoch [51/100], Step [10/324], Discriminator Loss: 0.0622, Generator Loss: 4.3188\nEpoch [51/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.2809\nEpoch [51/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 4.5273\nEpoch [51/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.2621\nEpoch [51/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.1619\nEpoch [51/100], Step [60/324], Discriminator Loss: 0.0009, Generator Loss: 4.4436\nEpoch [51/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.5487\nEpoch [51/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 4.6568\nEpoch [51/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 3.8514\nEpoch [51/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.4253\nEpoch [51/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 3.7404\nEpoch [51/100], Step [120/324], Discriminator Loss: 0.3960, Generator Loss: 4.0572\nEpoch [51/100], Step [130/324], Discriminator Loss: 0.2211, Generator Loss: 3.6515\nEpoch [51/100], Step [140/324], Discriminator Loss: 0.1849, Generator Loss: 3.3127\nEpoch [51/100], Step [150/324], Discriminator Loss: 0.0008, Generator Loss: 2.8288\nEpoch [51/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.9280\nEpoch [51/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.3856\nEpoch [51/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.7700\nEpoch [51/100], Step [190/324], Discriminator Loss: 0.1959, Generator Loss: 3.6830\nEpoch [51/100], Step [200/324], Discriminator Loss: 0.3058, Generator Loss: 4.3324\nEpoch [51/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.5050\nEpoch [51/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 4.0270\nEpoch [51/100], Step [230/324], Discriminator Loss: 0.0673, Generator Loss: 4.0861\nEpoch [51/100], Step [240/324], Discriminator Loss: 0.1116, Generator Loss: 4.2361\nEpoch [51/100], Step [250/324], Discriminator Loss: 0.1687, Generator Loss: 3.6838\nEpoch [51/100], Step [260/324], Discriminator Loss: 0.0002, Generator Loss: 3.4447\nEpoch [51/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.3207\nEpoch [51/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 3.0025\nEpoch [51/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.7513\nEpoch [51/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 3.7100\nEpoch [51/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 5.0339\nEpoch [51/100], Step [320/324], Discriminator Loss: 0.1909, Generator Loss: 3.7953\nEpoch [52/100], Step [0/324], Discriminator Loss: 0.0015, Generator Loss: 4.0814\nEpoch [52/100], Step [10/324], Discriminator Loss: 0.0005, Generator Loss: 3.0420\nEpoch [52/100], Step [20/324], Discriminator Loss: 0.0023, Generator Loss: 3.5002\nEpoch [52/100], Step [30/324], Discriminator Loss: 0.0068, Generator Loss: 4.3876\nEpoch [52/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.1990\nEpoch [52/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.5780\nEpoch [52/100], Step [60/324], Discriminator Loss: 0.2049, Generator Loss: 3.8677\nEpoch [52/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 3.7812\nEpoch [52/100], Step [80/324], Discriminator Loss: 0.5611, Generator Loss: 3.3258\nEpoch [52/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 3.8923\nEpoch [52/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 5.2076\nEpoch [52/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 2.7229\nEpoch [52/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.1669\nEpoch [52/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.5940\nEpoch [52/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.7621\nEpoch [52/100], Step [150/324], Discriminator Loss: 0.1949, Generator Loss: 4.0007\nEpoch [52/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.0174\nEpoch [52/100], Step [170/324], Discriminator Loss: 0.1905, Generator Loss: 3.1410\nEpoch [52/100], Step [180/324], Discriminator Loss: 0.3022, Generator Loss: 3.8804\nEpoch [52/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.2123\nEpoch [52/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 3.8575\nEpoch [52/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 4.3282\nEpoch [52/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 3.8704\nEpoch [52/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 3.8308\nEpoch [52/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.0788\nEpoch [52/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.0021\nEpoch [52/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 3.4758\nEpoch [52/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.5959\nEpoch [52/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.6340\nEpoch [52/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 4.2342\nEpoch [52/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 4.8063\nEpoch [52/100], Step [310/324], Discriminator Loss: 0.2273, Generator Loss: 3.5041\nEpoch [52/100], Step [320/324], Discriminator Loss: 0.1240, Generator Loss: 4.3744\nEpoch [53/100], Step [0/324], Discriminator Loss: 0.1368, Generator Loss: 4.8826\nEpoch [53/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 4.5464\nEpoch [53/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 3.9319\nEpoch [53/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 3.9657\nEpoch [53/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.7981\nEpoch [53/100], Step [50/324], Discriminator Loss: 0.3424, Generator Loss: 4.8805\nEpoch [53/100], Step [60/324], Discriminator Loss: 0.1812, Generator Loss: 4.3713\nEpoch [53/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 3.5562\nEpoch [53/100], Step [80/324], Discriminator Loss: 0.1645, Generator Loss: 3.6371\nEpoch [53/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 4.4416\nEpoch [53/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.4976\nEpoch [53/100], Step [110/324], Discriminator Loss: 0.2349, Generator Loss: 3.8457\nEpoch [53/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 3.5236\nEpoch [53/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 3.7717\nEpoch [53/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.8388\nEpoch [53/100], Step [150/324], Discriminator Loss: 0.3685, Generator Loss: 4.4315\nEpoch [53/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.3935\nEpoch [53/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 3.6971\nEpoch [53/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 3.9855\nEpoch [53/100], Step [190/324], Discriminator Loss: 0.1317, Generator Loss: 3.4986\nEpoch [53/100], Step [200/324], Discriminator Loss: 0.4122, Generator Loss: 4.0008\nEpoch [53/100], Step [210/324], Discriminator Loss: 0.1338, Generator Loss: 3.1905\nEpoch [53/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 4.5612\nEpoch [53/100], Step [230/324], Discriminator Loss: 0.3394, Generator Loss: 3.5923\nEpoch [53/100], Step [240/324], Discriminator Loss: 0.1418, Generator Loss: 4.5370\nEpoch [53/100], Step [250/324], Discriminator Loss: 0.3137, Generator Loss: 3.8281\nEpoch [53/100], Step [260/324], Discriminator Loss: 0.2128, Generator Loss: 3.6089\nEpoch [53/100], Step [270/324], Discriminator Loss: 0.0877, Generator Loss: 4.1123\nEpoch [53/100], Step [280/324], Discriminator Loss: 0.2724, Generator Loss: 4.8943\nEpoch [53/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.7569\nEpoch [53/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.3687\nEpoch [53/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 3.4876\nEpoch [53/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.4278\nEpoch [54/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.7887\nEpoch [54/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.5380\nEpoch [54/100], Step [20/324], Discriminator Loss: 0.3376, Generator Loss: 4.0282\nEpoch [54/100], Step [30/324], Discriminator Loss: 0.6438, Generator Loss: 3.0026\nEpoch [54/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 3.9549\nEpoch [54/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 5.0509\nEpoch [54/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.6651\nEpoch [54/100], Step [70/324], Discriminator Loss: 0.1709, Generator Loss: 3.9001\nEpoch [54/100], Step [80/324], Discriminator Loss: 0.4374, Generator Loss: 3.9218\nEpoch [54/100], Step [90/324], Discriminator Loss: 0.3649, Generator Loss: 4.1906\nEpoch [54/100], Step [100/324], Discriminator Loss: 0.0003, Generator Loss: 3.0461\nEpoch [54/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.6919\nEpoch [54/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 5.1510\nEpoch [54/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 5.7551\nEpoch [54/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 3.1074\nEpoch [54/100], Step [150/324], Discriminator Loss: 0.0004, Generator Loss: 4.2145\nEpoch [54/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.7877\nEpoch [54/100], Step [170/324], Discriminator Loss: 0.1046, Generator Loss: 3.2939\nEpoch [54/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.3151\nEpoch [54/100], Step [190/324], Discriminator Loss: 0.2716, Generator Loss: 4.7471\nEpoch [54/100], Step [200/324], Discriminator Loss: 0.1395, Generator Loss: 4.0591\nEpoch [54/100], Step [210/324], Discriminator Loss: 0.1464, Generator Loss: 3.7766\nEpoch [54/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 4.3685\nEpoch [54/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 4.6299\nEpoch [54/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 6.0123\nEpoch [54/100], Step [250/324], Discriminator Loss: 0.2996, Generator Loss: 4.8950\nEpoch [54/100], Step [260/324], Discriminator Loss: 0.0002, Generator Loss: 4.2917\nEpoch [54/100], Step [270/324], Discriminator Loss: 0.1724, Generator Loss: 4.4203\nEpoch [54/100], Step [280/324], Discriminator Loss: 0.0006, Generator Loss: 3.9827\nEpoch [54/100], Step [290/324], Discriminator Loss: 0.5190, Generator Loss: 4.7026\nEpoch [54/100], Step [300/324], Discriminator Loss: 0.2384, Generator Loss: 3.7718\nEpoch [54/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 3.9023\nEpoch [54/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 4.4831\nEpoch [55/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.7017\nEpoch [55/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 4.2886\nEpoch [55/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 4.4962\nEpoch [55/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 5.8647\nEpoch [55/100], Step [40/324], Discriminator Loss: 0.0402, Generator Loss: 3.8596\nEpoch [55/100], Step [50/324], Discriminator Loss: 0.0006, Generator Loss: 4.4644\nEpoch [55/100], Step [60/324], Discriminator Loss: 0.0709, Generator Loss: 3.6193\nEpoch [55/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.9733\nEpoch [55/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 3.6774\nEpoch [55/100], Step [90/324], Discriminator Loss: 0.0003, Generator Loss: 4.5793\nEpoch [55/100], Step [100/324], Discriminator Loss: 0.0007, Generator Loss: 3.3868\nEpoch [55/100], Step [110/324], Discriminator Loss: 0.0004, Generator Loss: 3.8606\nEpoch [55/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 2.6197\nEpoch [55/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 6.5085\nEpoch [55/100], Step [140/324], Discriminator Loss: 0.0008, Generator Loss: 5.0982\nEpoch [55/100], Step [150/324], Discriminator Loss: 0.4050, Generator Loss: 3.7708\nEpoch [55/100], Step [160/324], Discriminator Loss: 0.4067, Generator Loss: 3.9038\nEpoch [55/100], Step [170/324], Discriminator Loss: 0.0008, Generator Loss: 4.8544\nEpoch [55/100], Step [180/324], Discriminator Loss: 0.0592, Generator Loss: 4.6275\nEpoch [55/100], Step [190/324], Discriminator Loss: 0.0004, Generator Loss: 4.8473\nEpoch [55/100], Step [200/324], Discriminator Loss: 0.0007, Generator Loss: 4.2288\nEpoch [55/100], Step [210/324], Discriminator Loss: 0.0024, Generator Loss: 3.2714\nEpoch [55/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 3.6238\nEpoch [55/100], Step [230/324], Discriminator Loss: 0.1946, Generator Loss: 4.5098\nEpoch [55/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 3.4128\nEpoch [55/100], Step [250/324], Discriminator Loss: 0.1587, Generator Loss: 3.2734\nEpoch [55/100], Step [260/324], Discriminator Loss: 0.1663, Generator Loss: 4.8290\nEpoch [55/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.2664\nEpoch [55/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 4.8574\nEpoch [55/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.5096\nEpoch [55/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 3.3372\nEpoch [55/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 4.0329\nEpoch [55/100], Step [320/324], Discriminator Loss: 0.1839, Generator Loss: 3.0577\nEpoch [56/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 2.8819\nEpoch [56/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.6376\nEpoch [56/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 3.7907\nEpoch [56/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 4.5162\nEpoch [56/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 5.2459\nEpoch [56/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.7820\nEpoch [56/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.8028\nEpoch [56/100], Step [70/324], Discriminator Loss: 0.3681, Generator Loss: 3.7519\nEpoch [56/100], Step [80/324], Discriminator Loss: 0.1776, Generator Loss: 3.8226\nEpoch [56/100], Step [90/324], Discriminator Loss: 0.0767, Generator Loss: 3.0382\nEpoch [56/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.3032\nEpoch [56/100], Step [110/324], Discriminator Loss: 0.5348, Generator Loss: 3.9364\nEpoch [56/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.8926\nEpoch [56/100], Step [130/324], Discriminator Loss: 0.3419, Generator Loss: 5.4059\nEpoch [56/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.0127\nEpoch [56/100], Step [150/324], Discriminator Loss: 0.2606, Generator Loss: 3.7073\nEpoch [56/100], Step [160/324], Discriminator Loss: 0.3245, Generator Loss: 3.9895\nEpoch [56/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 3.5242\nEpoch [56/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 5.3251\nEpoch [56/100], Step [190/324], Discriminator Loss: 0.2227, Generator Loss: 4.2092\nEpoch [56/100], Step [200/324], Discriminator Loss: 0.2770, Generator Loss: 3.6844\nEpoch [56/100], Step [210/324], Discriminator Loss: 0.0004, Generator Loss: 3.9552\nEpoch [56/100], Step [220/324], Discriminator Loss: 0.2084, Generator Loss: 3.6287\nEpoch [56/100], Step [230/324], Discriminator Loss: 0.1863, Generator Loss: 3.4771\nEpoch [56/100], Step [240/324], Discriminator Loss: 0.0005, Generator Loss: 3.9315\nEpoch [56/100], Step [250/324], Discriminator Loss: 0.0005, Generator Loss: 4.1975\nEpoch [56/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.5584\nEpoch [56/100], Step [270/324], Discriminator Loss: 0.0744, Generator Loss: 4.0990\nEpoch [56/100], Step [280/324], Discriminator Loss: 0.2647, Generator Loss: 3.4151\nEpoch [56/100], Step [290/324], Discriminator Loss: 0.0185, Generator Loss: 4.5022\nEpoch [56/100], Step [300/324], Discriminator Loss: 0.0003, Generator Loss: 4.7584\nEpoch [56/100], Step [310/324], Discriminator Loss: 0.0011, Generator Loss: 4.2573\nEpoch [56/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 4.7725\nEpoch [57/100], Step [0/324], Discriminator Loss: 0.0007, Generator Loss: 4.4999\nEpoch [57/100], Step [10/324], Discriminator Loss: 0.0012, Generator Loss: 4.1271\nEpoch [57/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.8678\nEpoch [57/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.6904\nEpoch [57/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 4.3022\nEpoch [57/100], Step [50/324], Discriminator Loss: 0.4641, Generator Loss: 4.2229\nEpoch [57/100], Step [60/324], Discriminator Loss: 0.0007, Generator Loss: 3.6554\nEpoch [57/100], Step [70/324], Discriminator Loss: 0.0004, Generator Loss: 4.6370\nEpoch [57/100], Step [80/324], Discriminator Loss: 0.0007, Generator Loss: 3.8594\nEpoch [57/100], Step [90/324], Discriminator Loss: 0.3115, Generator Loss: 3.7597\nEpoch [57/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.1514\nEpoch [57/100], Step [110/324], Discriminator Loss: 0.1596, Generator Loss: 4.2428\nEpoch [57/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.2555\nEpoch [57/100], Step [130/324], Discriminator Loss: 0.0343, Generator Loss: 3.1692\nEpoch [57/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 4.0267\nEpoch [57/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 5.9172\nEpoch [57/100], Step [160/324], Discriminator Loss: 0.2635, Generator Loss: 4.5868\nEpoch [57/100], Step [170/324], Discriminator Loss: 0.1366, Generator Loss: 5.4312\nEpoch [57/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 5.8078\nEpoch [57/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 6.4425\nEpoch [57/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 6.5691\nEpoch [57/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 5.7924\nEpoch [57/100], Step [220/324], Discriminator Loss: 0.1491, Generator Loss: 3.1289\nEpoch [57/100], Step [230/324], Discriminator Loss: 0.1568, Generator Loss: 3.9568\nEpoch [57/100], Step [240/324], Discriminator Loss: 0.0031, Generator Loss: 4.5282\nEpoch [57/100], Step [250/324], Discriminator Loss: 0.0484, Generator Loss: 3.6093\nEpoch [57/100], Step [260/324], Discriminator Loss: 0.2243, Generator Loss: 5.0614\nEpoch [57/100], Step [270/324], Discriminator Loss: 0.0802, Generator Loss: 4.8631\nEpoch [57/100], Step [280/324], Discriminator Loss: 0.0007, Generator Loss: 5.8836\nEpoch [57/100], Step [290/324], Discriminator Loss: 0.1022, Generator Loss: 5.7693\nEpoch [57/100], Step [300/324], Discriminator Loss: 0.5680, Generator Loss: 4.1682\nEpoch [57/100], Step [310/324], Discriminator Loss: 0.0123, Generator Loss: 4.0555\nEpoch [57/100], Step [320/324], Discriminator Loss: 0.1235, Generator Loss: 4.1235\nEpoch [58/100], Step [0/324], Discriminator Loss: 1.5648, Generator Loss: 4.2543\nEpoch [58/100], Step [10/324], Discriminator Loss: 0.2775, Generator Loss: 3.8794\nEpoch [58/100], Step [20/324], Discriminator Loss: 0.0004, Generator Loss: 4.8733\nEpoch [58/100], Step [30/324], Discriminator Loss: 0.0004, Generator Loss: 5.1890\nEpoch [58/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 4.5310\nEpoch [58/100], Step [50/324], Discriminator Loss: 0.3679, Generator Loss: 5.2270\nEpoch [58/100], Step [60/324], Discriminator Loss: 0.1471, Generator Loss: 4.2612\nEpoch [58/100], Step [70/324], Discriminator Loss: 0.0024, Generator Loss: 4.4848\nEpoch [58/100], Step [80/324], Discriminator Loss: 0.0025, Generator Loss: 4.1729\nEpoch [58/100], Step [90/324], Discriminator Loss: 0.0022, Generator Loss: 3.7008\nEpoch [58/100], Step [100/324], Discriminator Loss: 0.0004, Generator Loss: 5.3133\nEpoch [58/100], Step [110/324], Discriminator Loss: 0.2191, Generator Loss: 4.0141\nEpoch [58/100], Step [120/324], Discriminator Loss: 0.0013, Generator Loss: 4.0722\nEpoch [58/100], Step [130/324], Discriminator Loss: 0.0003, Generator Loss: 4.4047\nEpoch [58/100], Step [140/324], Discriminator Loss: 0.0016, Generator Loss: 3.5166\nEpoch [58/100], Step [150/324], Discriminator Loss: 0.0005, Generator Loss: 4.3485\nEpoch [58/100], Step [160/324], Discriminator Loss: 0.0003, Generator Loss: 4.5490\nEpoch [58/100], Step [170/324], Discriminator Loss: 0.0467, Generator Loss: 3.8828\nEpoch [58/100], Step [180/324], Discriminator Loss: 0.0004, Generator Loss: 4.5715\nEpoch [58/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 2.9639\nEpoch [58/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 6.3114\nEpoch [58/100], Step [210/324], Discriminator Loss: 0.7674, Generator Loss: 5.0892\nEpoch [58/100], Step [220/324], Discriminator Loss: 0.0050, Generator Loss: 3.6453\nEpoch [58/100], Step [230/324], Discriminator Loss: 0.0005, Generator Loss: 3.9703\nEpoch [58/100], Step [240/324], Discriminator Loss: 0.0003, Generator Loss: 3.9303\nEpoch [58/100], Step [250/324], Discriminator Loss: 0.0005, Generator Loss: 3.3970\nEpoch [58/100], Step [260/324], Discriminator Loss: 0.1474, Generator Loss: 3.7675\nEpoch [58/100], Step [270/324], Discriminator Loss: 0.2750, Generator Loss: 3.8868\nEpoch [58/100], Step [280/324], Discriminator Loss: 0.0012, Generator Loss: 3.5856\nEpoch [58/100], Step [290/324], Discriminator Loss: 0.0003, Generator Loss: 4.0532\nEpoch [58/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 5.1274\nEpoch [58/100], Step [310/324], Discriminator Loss: 0.1305, Generator Loss: 3.7261\nEpoch [58/100], Step [320/324], Discriminator Loss: 0.0572, Generator Loss: 4.0699\nEpoch [59/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.6124\nEpoch [59/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.1927\nEpoch [59/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 3.8932\nEpoch [59/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.7055\nEpoch [59/100], Step [40/324], Discriminator Loss: 0.1246, Generator Loss: 4.1174\nEpoch [59/100], Step [50/324], Discriminator Loss: 0.1917, Generator Loss: 4.2878\nEpoch [59/100], Step [60/324], Discriminator Loss: 0.0003, Generator Loss: 4.1898\nEpoch [59/100], Step [70/324], Discriminator Loss: 0.0006, Generator Loss: 3.3892\nEpoch [59/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 3.8068\nEpoch [59/100], Step [90/324], Discriminator Loss: 0.0004, Generator Loss: 3.9558\nEpoch [59/100], Step [100/324], Discriminator Loss: 0.3157, Generator Loss: 3.2386\nEpoch [59/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.8763\nEpoch [59/100], Step [120/324], Discriminator Loss: 0.0644, Generator Loss: 4.1207\nEpoch [59/100], Step [130/324], Discriminator Loss: 0.1416, Generator Loss: 3.2681\nEpoch [59/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.0911\nEpoch [59/100], Step [150/324], Discriminator Loss: 1.5626, Generator Loss: 4.4000\nEpoch [59/100], Step [160/324], Discriminator Loss: 0.1088, Generator Loss: 4.9975\nEpoch [59/100], Step [170/324], Discriminator Loss: 0.0880, Generator Loss: 5.4310\nEpoch [59/100], Step [180/324], Discriminator Loss: 0.4119, Generator Loss: 4.7970\nEpoch [59/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.9458\nEpoch [59/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.1980\nEpoch [59/100], Step [210/324], Discriminator Loss: 0.0003, Generator Loss: 3.8243\nEpoch [59/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 3.5399\nEpoch [59/100], Step [230/324], Discriminator Loss: 0.4282, Generator Loss: 4.0406\nEpoch [59/100], Step [240/324], Discriminator Loss: 0.2744, Generator Loss: 3.7169\nEpoch [59/100], Step [250/324], Discriminator Loss: 0.4017, Generator Loss: 3.3425\nEpoch [59/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.3916\nEpoch [59/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.0172\nEpoch [59/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 4.1386\nEpoch [59/100], Step [290/324], Discriminator Loss: 0.2318, Generator Loss: 4.1296\nEpoch [59/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 4.5422\nEpoch [59/100], Step [310/324], Discriminator Loss: 0.2679, Generator Loss: 3.9888\nEpoch [59/100], Step [320/324], Discriminator Loss: 0.4858, Generator Loss: 3.2890\nEpoch [60/100], Step [0/324], Discriminator Loss: 0.0003, Generator Loss: 3.4616\nEpoch [60/100], Step [10/324], Discriminator Loss: 0.2017, Generator Loss: 4.3530\nEpoch [60/100], Step [20/324], Discriminator Loss: 0.1942, Generator Loss: 3.9684\nEpoch [60/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.1116\nEpoch [60/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 3.3919\nEpoch [60/100], Step [50/324], Discriminator Loss: 0.1830, Generator Loss: 3.7203\nEpoch [60/100], Step [60/324], Discriminator Loss: 0.1334, Generator Loss: 4.0781\nEpoch [60/100], Step [70/324], Discriminator Loss: 0.4040, Generator Loss: 5.0649\nEpoch [60/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.8636\nEpoch [60/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.3018\nEpoch [60/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 5.3007\nEpoch [60/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.8098\nEpoch [60/100], Step [120/324], Discriminator Loss: 0.2340, Generator Loss: 3.7762\nEpoch [60/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 3.3224\nEpoch [60/100], Step [140/324], Discriminator Loss: 0.2343, Generator Loss: 3.7488\nEpoch [60/100], Step [150/324], Discriminator Loss: 0.0003, Generator Loss: 3.5467\nEpoch [60/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.6544\nEpoch [60/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.2442\nEpoch [60/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.5380\nEpoch [60/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 3.3924\nEpoch [60/100], Step [200/324], Discriminator Loss: 0.0003, Generator Loss: 3.5633\nEpoch [60/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.1166\nEpoch [60/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.0155\nEpoch [60/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 4.3796\nEpoch [60/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.1872\nEpoch [60/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.5829\nEpoch [60/100], Step [260/324], Discriminator Loss: 0.0643, Generator Loss: 4.2036\nEpoch [60/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.1164\nEpoch [60/100], Step [280/324], Discriminator Loss: 0.1873, Generator Loss: 3.8600\nEpoch [60/100], Step [290/324], Discriminator Loss: 0.2599, Generator Loss: 4.2548\nEpoch [60/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 3.3485\nEpoch [60/100], Step [310/324], Discriminator Loss: 0.5558, Generator Loss: 4.0081\nEpoch [60/100], Step [320/324], Discriminator Loss: 0.4391, Generator Loss: 3.4628\nEpoch [61/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.4545\nEpoch [61/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.4741\nEpoch [61/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 4.5972\nEpoch [61/100], Step [30/324], Discriminator Loss: 0.3211, Generator Loss: 5.0133\nEpoch [61/100], Step [40/324], Discriminator Loss: 0.1281, Generator Loss: 4.2227\nEpoch [61/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.3946\nEpoch [61/100], Step [60/324], Discriminator Loss: 0.2777, Generator Loss: 4.6282\nEpoch [61/100], Step [70/324], Discriminator Loss: 0.5458, Generator Loss: 3.2958\nEpoch [61/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.6496\nEpoch [61/100], Step [90/324], Discriminator Loss: 0.1922, Generator Loss: 4.1750\nEpoch [61/100], Step [100/324], Discriminator Loss: 0.4103, Generator Loss: 3.5962\nEpoch [61/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.7311\nEpoch [61/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.4460\nEpoch [61/100], Step [130/324], Discriminator Loss: 0.1832, Generator Loss: 3.9074\nEpoch [61/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.6356\nEpoch [61/100], Step [150/324], Discriminator Loss: 0.0003, Generator Loss: 3.6470\nEpoch [61/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.3542\nEpoch [61/100], Step [170/324], Discriminator Loss: 0.1798, Generator Loss: 3.9294\nEpoch [61/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.8814\nEpoch [61/100], Step [190/324], Discriminator Loss: 0.1955, Generator Loss: 4.7503\nEpoch [61/100], Step [200/324], Discriminator Loss: 0.0706, Generator Loss: 4.4041\nEpoch [61/100], Step [210/324], Discriminator Loss: 0.0003, Generator Loss: 3.7765\nEpoch [61/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.7142\nEpoch [61/100], Step [230/324], Discriminator Loss: 0.1245, Generator Loss: 4.0298\nEpoch [61/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 4.0522\nEpoch [61/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 3.8342\nEpoch [61/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.8869\nEpoch [61/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.2816\nEpoch [61/100], Step [280/324], Discriminator Loss: 0.1704, Generator Loss: 3.8834\nEpoch [61/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 4.1583\nEpoch [61/100], Step [300/324], Discriminator Loss: 0.2262, Generator Loss: 4.8142\nEpoch [61/100], Step [310/324], Discriminator Loss: 0.0007, Generator Loss: 3.1024\nEpoch [61/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 3.7561\nEpoch [62/100], Step [0/324], Discriminator Loss: 0.0004, Generator Loss: 3.6850\nEpoch [62/100], Step [10/324], Discriminator Loss: 0.1023, Generator Loss: 3.2795\nEpoch [62/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 3.9108\nEpoch [62/100], Step [30/324], Discriminator Loss: 0.1667, Generator Loss: 3.8215\nEpoch [62/100], Step [40/324], Discriminator Loss: 0.3365, Generator Loss: 4.4371\nEpoch [62/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.8844\nEpoch [62/100], Step [60/324], Discriminator Loss: 1.7839, Generator Loss: 3.4131\nEpoch [62/100], Step [70/324], Discriminator Loss: 0.3588, Generator Loss: 3.2790\nEpoch [62/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.6242\nEpoch [62/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.4466\nEpoch [62/100], Step [100/324], Discriminator Loss: 0.0002, Generator Loss: 4.0791\nEpoch [62/100], Step [110/324], Discriminator Loss: 0.1060, Generator Loss: 3.2971\nEpoch [62/100], Step [120/324], Discriminator Loss: 0.0965, Generator Loss: 3.5750\nEpoch [62/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.0134\nEpoch [62/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.1007\nEpoch [62/100], Step [150/324], Discriminator Loss: 0.2318, Generator Loss: 3.3286\nEpoch [62/100], Step [160/324], Discriminator Loss: 0.4705, Generator Loss: 4.7217\nEpoch [62/100], Step [170/324], Discriminator Loss: 0.0625, Generator Loss: 4.4234\nEpoch [62/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 4.1335\nEpoch [62/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 4.2335\nEpoch [62/100], Step [200/324], Discriminator Loss: 0.2793, Generator Loss: 3.8905\nEpoch [62/100], Step [210/324], Discriminator Loss: 0.0006, Generator Loss: 3.5320\nEpoch [62/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 4.4453\nEpoch [62/100], Step [230/324], Discriminator Loss: 0.1952, Generator Loss: 4.2088\nEpoch [62/100], Step [240/324], Discriminator Loss: 0.1861, Generator Loss: 3.7162\nEpoch [62/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.2905\nEpoch [62/100], Step [260/324], Discriminator Loss: 0.0003, Generator Loss: 4.4378\nEpoch [62/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.5601\nEpoch [62/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 3.8620\nEpoch [62/100], Step [290/324], Discriminator Loss: 0.0007, Generator Loss: 4.0742\nEpoch [62/100], Step [300/324], Discriminator Loss: 0.2547, Generator Loss: 5.0822\nEpoch [62/100], Step [310/324], Discriminator Loss: 0.5364, Generator Loss: 5.9528\nEpoch [62/100], Step [320/324], Discriminator Loss: 0.0976, Generator Loss: 3.6473\nEpoch [63/100], Step [0/324], Discriminator Loss: 0.0029, Generator Loss: 3.7095\nEpoch [63/100], Step [10/324], Discriminator Loss: 0.0264, Generator Loss: 4.6324\nEpoch [63/100], Step [20/324], Discriminator Loss: 0.0095, Generator Loss: 4.5684\nEpoch [63/100], Step [30/324], Discriminator Loss: 0.0118, Generator Loss: 4.1745\nEpoch [63/100], Step [40/324], Discriminator Loss: 0.1857, Generator Loss: 3.6777\nEpoch [63/100], Step [50/324], Discriminator Loss: 0.3449, Generator Loss: 3.7103\nEpoch [63/100], Step [60/324], Discriminator Loss: 0.1849, Generator Loss: 4.2489\nEpoch [63/100], Step [70/324], Discriminator Loss: 0.0006, Generator Loss: 4.3185\nEpoch [63/100], Step [80/324], Discriminator Loss: 0.0536, Generator Loss: 3.6150\nEpoch [63/100], Step [90/324], Discriminator Loss: 0.0014, Generator Loss: 4.4223\nEpoch [63/100], Step [100/324], Discriminator Loss: 0.0060, Generator Loss: 4.0758\nEpoch [63/100], Step [110/324], Discriminator Loss: 0.2099, Generator Loss: 4.0473\nEpoch [63/100], Step [120/324], Discriminator Loss: 0.0028, Generator Loss: 3.5254\nEpoch [63/100], Step [130/324], Discriminator Loss: 0.0047, Generator Loss: 3.3413\nEpoch [63/100], Step [140/324], Discriminator Loss: 0.0613, Generator Loss: 4.1008\nEpoch [63/100], Step [150/324], Discriminator Loss: 0.0009, Generator Loss: 4.5159\nEpoch [63/100], Step [160/324], Discriminator Loss: 0.0036, Generator Loss: 3.7530\nEpoch [63/100], Step [170/324], Discriminator Loss: 0.0004, Generator Loss: 4.4586\nEpoch [63/100], Step [180/324], Discriminator Loss: 0.0004, Generator Loss: 4.2566\nEpoch [63/100], Step [190/324], Discriminator Loss: 0.2345, Generator Loss: 3.8395\nEpoch [63/100], Step [200/324], Discriminator Loss: 0.0005, Generator Loss: 4.2007\nEpoch [63/100], Step [210/324], Discriminator Loss: 0.4775, Generator Loss: 5.1003\nEpoch [63/100], Step [220/324], Discriminator Loss: 0.1820, Generator Loss: 3.9989\nEpoch [63/100], Step [230/324], Discriminator Loss: 0.3145, Generator Loss: 4.2103\nEpoch [63/100], Step [240/324], Discriminator Loss: 0.1627, Generator Loss: 3.6039\nEpoch [63/100], Step [250/324], Discriminator Loss: 0.0005, Generator Loss: 3.7367\nEpoch [63/100], Step [260/324], Discriminator Loss: 0.0008, Generator Loss: 3.9036\nEpoch [63/100], Step [270/324], Discriminator Loss: 0.4280, Generator Loss: 3.2382\nEpoch [63/100], Step [280/324], Discriminator Loss: 0.0005, Generator Loss: 4.0430\nEpoch [63/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 4.6024\nEpoch [63/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 4.4134\nEpoch [63/100], Step [310/324], Discriminator Loss: 0.0003, Generator Loss: 3.7318\nEpoch [63/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 3.7036\nEpoch [64/100], Step [0/324], Discriminator Loss: 0.2478, Generator Loss: 3.9909\nEpoch [64/100], Step [10/324], Discriminator Loss: 0.0005, Generator Loss: 3.4781\nEpoch [64/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 5.0764\nEpoch [64/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.5134\nEpoch [64/100], Step [40/324], Discriminator Loss: 0.0004, Generator Loss: 3.6878\nEpoch [64/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.9119\nEpoch [64/100], Step [60/324], Discriminator Loss: 0.0004, Generator Loss: 3.2154\nEpoch [64/100], Step [70/324], Discriminator Loss: 0.0003, Generator Loss: 3.8840\nEpoch [64/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 5.3144\nEpoch [64/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 6.1688\nEpoch [64/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.4939\nEpoch [64/100], Step [110/324], Discriminator Loss: 0.0003, Generator Loss: 3.7281\nEpoch [64/100], Step [120/324], Discriminator Loss: 0.0005, Generator Loss: 4.2066\nEpoch [64/100], Step [130/324], Discriminator Loss: 0.1447, Generator Loss: 4.3061\nEpoch [64/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.0805\nEpoch [64/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.5614\nEpoch [64/100], Step [160/324], Discriminator Loss: 0.0454, Generator Loss: 3.8116\nEpoch [64/100], Step [170/324], Discriminator Loss: 0.2035, Generator Loss: 2.7331\nEpoch [64/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.9388\nEpoch [64/100], Step [190/324], Discriminator Loss: 0.0761, Generator Loss: 4.6706\nEpoch [64/100], Step [200/324], Discriminator Loss: 0.2610, Generator Loss: 4.2892\nEpoch [64/100], Step [210/324], Discriminator Loss: 0.3075, Generator Loss: 4.0396\nEpoch [64/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.3607\nEpoch [64/100], Step [230/324], Discriminator Loss: 0.0005, Generator Loss: 4.0110\nEpoch [64/100], Step [240/324], Discriminator Loss: 0.2281, Generator Loss: 3.5048\nEpoch [64/100], Step [250/324], Discriminator Loss: 0.0688, Generator Loss: 4.3631\nEpoch [64/100], Step [260/324], Discriminator Loss: 0.0002, Generator Loss: 3.8180\nEpoch [64/100], Step [270/324], Discriminator Loss: 0.1101, Generator Loss: 3.4116\nEpoch [64/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 3.3089\nEpoch [64/100], Step [290/324], Discriminator Loss: 0.0004, Generator Loss: 4.1158\nEpoch [64/100], Step [300/324], Discriminator Loss: 0.0006, Generator Loss: 4.2914\nEpoch [64/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.4087\nEpoch [64/100], Step [320/324], Discriminator Loss: 0.2427, Generator Loss: 3.9268\nEpoch [65/100], Step [0/324], Discriminator Loss: 0.1821, Generator Loss: 3.9835\nEpoch [65/100], Step [10/324], Discriminator Loss: 0.1217, Generator Loss: 4.0303\nEpoch [65/100], Step [20/324], Discriminator Loss: 0.0005, Generator Loss: 4.1676\nEpoch [65/100], Step [30/324], Discriminator Loss: 0.1798, Generator Loss: 3.8615\nEpoch [65/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 3.7729\nEpoch [65/100], Step [50/324], Discriminator Loss: 0.1271, Generator Loss: 4.0348\nEpoch [65/100], Step [60/324], Discriminator Loss: 0.0663, Generator Loss: 4.2409\nEpoch [65/100], Step [70/324], Discriminator Loss: 0.0003, Generator Loss: 3.7726\nEpoch [65/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.7386\nEpoch [65/100], Step [90/324], Discriminator Loss: 0.2193, Generator Loss: 4.5768\nEpoch [65/100], Step [100/324], Discriminator Loss: 0.0002, Generator Loss: 3.9208\nEpoch [65/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.5787\nEpoch [65/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.2313\nEpoch [65/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.5397\nEpoch [65/100], Step [140/324], Discriminator Loss: 0.3629, Generator Loss: 3.9124\nEpoch [65/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.0367\nEpoch [65/100], Step [160/324], Discriminator Loss: 0.0003, Generator Loss: 3.9069\nEpoch [65/100], Step [170/324], Discriminator Loss: 0.3098, Generator Loss: 4.7849\nEpoch [65/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.7469\nEpoch [65/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.8853\nEpoch [65/100], Step [200/324], Discriminator Loss: 0.2564, Generator Loss: 4.1350\nEpoch [65/100], Step [210/324], Discriminator Loss: 0.2796, Generator Loss: 3.4686\nEpoch [65/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.0571\nEpoch [65/100], Step [230/324], Discriminator Loss: 0.1862, Generator Loss: 2.9990\nEpoch [65/100], Step [240/324], Discriminator Loss: 0.0007, Generator Loss: 3.5022\nEpoch [65/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 3.9162\nEpoch [65/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.9135\nEpoch [65/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.2654\nEpoch [65/100], Step [280/324], Discriminator Loss: 0.0003, Generator Loss: 3.8106\nEpoch [65/100], Step [290/324], Discriminator Loss: 0.0003, Generator Loss: 4.1770\nEpoch [65/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 4.9743\nEpoch [65/100], Step [310/324], Discriminator Loss: 0.0953, Generator Loss: 3.4033\nEpoch [65/100], Step [320/324], Discriminator Loss: 0.0004, Generator Loss: 3.5994\nEpoch [66/100], Step [0/324], Discriminator Loss: 0.0009, Generator Loss: 3.6041\nEpoch [66/100], Step [10/324], Discriminator Loss: 0.0579, Generator Loss: 4.0518\nEpoch [66/100], Step [20/324], Discriminator Loss: 0.0004, Generator Loss: 3.7492\nEpoch [66/100], Step [30/324], Discriminator Loss: 0.2637, Generator Loss: 3.5683\nEpoch [66/100], Step [40/324], Discriminator Loss: 0.0005, Generator Loss: 3.9584\nEpoch [66/100], Step [50/324], Discriminator Loss: 0.0003, Generator Loss: 4.0955\nEpoch [66/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 2.9039\nEpoch [66/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 3.9617\nEpoch [66/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.6340\nEpoch [66/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 3.8315\nEpoch [66/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.5244\nEpoch [66/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 5.6165\nEpoch [66/100], Step [120/324], Discriminator Loss: 0.2508, Generator Loss: 3.2949\nEpoch [66/100], Step [130/324], Discriminator Loss: 0.0006, Generator Loss: 3.5652\nEpoch [66/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.1960\nEpoch [66/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.9065\nEpoch [66/100], Step [160/324], Discriminator Loss: 0.3892, Generator Loss: 3.8535\nEpoch [66/100], Step [170/324], Discriminator Loss: 0.0626, Generator Loss: 4.0545\nEpoch [66/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.8449\nEpoch [66/100], Step [190/324], Discriminator Loss: 0.3740, Generator Loss: 4.0572\nEpoch [66/100], Step [200/324], Discriminator Loss: 0.5527, Generator Loss: 3.3961\nEpoch [66/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 4.8026\nEpoch [66/100], Step [220/324], Discriminator Loss: 0.0004, Generator Loss: 4.3196\nEpoch [66/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.6929\nEpoch [66/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.1401\nEpoch [66/100], Step [250/324], Discriminator Loss: 0.1156, Generator Loss: 3.7630\nEpoch [66/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 3.8950\nEpoch [66/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.5376\nEpoch [66/100], Step [280/324], Discriminator Loss: 0.1111, Generator Loss: 3.7039\nEpoch [66/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 4.0370\nEpoch [66/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 3.5437\nEpoch [66/100], Step [310/324], Discriminator Loss: 1.5626, Generator Loss: 4.2780\nEpoch [66/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 3.3999\nEpoch [67/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.5599\nEpoch [67/100], Step [10/324], Discriminator Loss: 0.1914, Generator Loss: 4.1349\nEpoch [67/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.6917\nEpoch [67/100], Step [30/324], Discriminator Loss: 0.1108, Generator Loss: 3.7520\nEpoch [67/100], Step [40/324], Discriminator Loss: 0.2024, Generator Loss: 4.3298\nEpoch [67/100], Step [50/324], Discriminator Loss: 0.1994, Generator Loss: 4.0792\nEpoch [67/100], Step [60/324], Discriminator Loss: 0.0004, Generator Loss: 3.5452\nEpoch [67/100], Step [70/324], Discriminator Loss: 0.1013, Generator Loss: 3.6038\nEpoch [67/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.7459\nEpoch [67/100], Step [90/324], Discriminator Loss: 0.1243, Generator Loss: 3.9362\nEpoch [67/100], Step [100/324], Discriminator Loss: 0.0002, Generator Loss: 4.2715\nEpoch [67/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.6297\nEpoch [67/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.1816\nEpoch [67/100], Step [130/324], Discriminator Loss: 0.2469, Generator Loss: 3.8976\nEpoch [67/100], Step [140/324], Discriminator Loss: 0.0003, Generator Loss: 3.6269\nEpoch [67/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.9117\nEpoch [67/100], Step [160/324], Discriminator Loss: 0.1720, Generator Loss: 3.5613\nEpoch [67/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.4464\nEpoch [67/100], Step [180/324], Discriminator Loss: 0.0010, Generator Loss: 3.7848\nEpoch [67/100], Step [190/324], Discriminator Loss: 0.1875, Generator Loss: 3.0442\nEpoch [67/100], Step [200/324], Discriminator Loss: 0.1564, Generator Loss: 3.5379\nEpoch [67/100], Step [210/324], Discriminator Loss: 0.0586, Generator Loss: 3.9047\nEpoch [67/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 4.4487\nEpoch [67/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 4.6887\nEpoch [67/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.0960\nEpoch [67/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.7904\nEpoch [67/100], Step [260/324], Discriminator Loss: 0.2440, Generator Loss: 4.8219\nEpoch [67/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.8659\nEpoch [67/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 5.4269\nEpoch [67/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 3.5580\nEpoch [67/100], Step [300/324], Discriminator Loss: 0.0004, Generator Loss: 4.0797\nEpoch [67/100], Step [310/324], Discriminator Loss: 0.0005, Generator Loss: 3.5335\nEpoch [67/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 3.5214\nEpoch [68/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.9839\nEpoch [68/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.0692\nEpoch [68/100], Step [20/324], Discriminator Loss: 0.0003, Generator Loss: 3.0861\nEpoch [68/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 5.1218\nEpoch [68/100], Step [40/324], Discriminator Loss: 0.3629, Generator Loss: 4.3166\nEpoch [68/100], Step [50/324], Discriminator Loss: 0.0082, Generator Loss: 3.7560\nEpoch [68/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 5.2575\nEpoch [68/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 4.2530\nEpoch [68/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 4.5038\nEpoch [68/100], Step [90/324], Discriminator Loss: 0.0004, Generator Loss: 3.7501\nEpoch [68/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 5.7933\nEpoch [68/100], Step [110/324], Discriminator Loss: 0.4926, Generator Loss: 4.1414\nEpoch [68/100], Step [120/324], Discriminator Loss: 0.0004, Generator Loss: 4.0265\nEpoch [68/100], Step [130/324], Discriminator Loss: 0.0004, Generator Loss: 4.3477\nEpoch [68/100], Step [140/324], Discriminator Loss: 0.3996, Generator Loss: 4.3450\nEpoch [68/100], Step [150/324], Discriminator Loss: 0.1618, Generator Loss: 3.4606\nEpoch [68/100], Step [160/324], Discriminator Loss: 0.0995, Generator Loss: 4.1657\nEpoch [68/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.6025\nEpoch [68/100], Step [180/324], Discriminator Loss: 0.0009, Generator Loss: 4.1780\nEpoch [68/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.5347\nEpoch [68/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 4.2321\nEpoch [68/100], Step [210/324], Discriminator Loss: 0.2582, Generator Loss: 3.9589\nEpoch [68/100], Step [220/324], Discriminator Loss: 0.2621, Generator Loss: 3.8605\nEpoch [68/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.9251\nEpoch [68/100], Step [240/324], Discriminator Loss: 0.0004, Generator Loss: 3.5579\nEpoch [68/100], Step [250/324], Discriminator Loss: 0.0006, Generator Loss: 3.5629\nEpoch [68/100], Step [260/324], Discriminator Loss: 0.1691, Generator Loss: 4.1831\nEpoch [68/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 3.8635\nEpoch [68/100], Step [280/324], Discriminator Loss: 0.0003, Generator Loss: 3.5548\nEpoch [68/100], Step [290/324], Discriminator Loss: 0.3666, Generator Loss: 4.2929\nEpoch [68/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.2404\nEpoch [68/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 4.1841\nEpoch [68/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 2.7189\nEpoch [69/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.3720\nEpoch [69/100], Step [10/324], Discriminator Loss: 0.0576, Generator Loss: 3.5294\nEpoch [69/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 4.7950\nEpoch [69/100], Step [30/324], Discriminator Loss: 0.1527, Generator Loss: 4.1892\nEpoch [69/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 3.5764\nEpoch [69/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 5.0178\nEpoch [69/100], Step [60/324], Discriminator Loss: 0.5689, Generator Loss: 7.1118\nEpoch [69/100], Step [70/324], Discriminator Loss: 0.0004, Generator Loss: 5.2377\nEpoch [69/100], Step [80/324], Discriminator Loss: 0.0810, Generator Loss: 4.7423\nEpoch [69/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 4.8668\nEpoch [69/100], Step [100/324], Discriminator Loss: 0.0004, Generator Loss: 4.2373\nEpoch [69/100], Step [110/324], Discriminator Loss: 0.0008, Generator Loss: 4.1620\nEpoch [69/100], Step [120/324], Discriminator Loss: 0.0003, Generator Loss: 3.7593\nEpoch [69/100], Step [130/324], Discriminator Loss: 0.0004, Generator Loss: 4.1463\nEpoch [69/100], Step [140/324], Discriminator Loss: 0.0208, Generator Loss: 4.3702\nEpoch [69/100], Step [150/324], Discriminator Loss: 0.1906, Generator Loss: 3.9079\nEpoch [69/100], Step [160/324], Discriminator Loss: 0.0010, Generator Loss: 3.9841\nEpoch [69/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.7105\nEpoch [69/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 4.5250\nEpoch [69/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 4.4830\nEpoch [69/100], Step [200/324], Discriminator Loss: 0.3294, Generator Loss: 3.2795\nEpoch [69/100], Step [210/324], Discriminator Loss: 0.3536, Generator Loss: 3.1766\nEpoch [69/100], Step [220/324], Discriminator Loss: 0.1066, Generator Loss: 3.6000\nEpoch [69/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.4715\nEpoch [69/100], Step [240/324], Discriminator Loss: 0.3604, Generator Loss: 3.9409\nEpoch [69/100], Step [250/324], Discriminator Loss: 0.2130, Generator Loss: 3.1550\nEpoch [69/100], Step [260/324], Discriminator Loss: 0.1009, Generator Loss: 3.8566\nEpoch [69/100], Step [270/324], Discriminator Loss: 0.0554, Generator Loss: 3.8136\nEpoch [69/100], Step [280/324], Discriminator Loss: 0.0002, Generator Loss: 4.4083\nEpoch [69/100], Step [290/324], Discriminator Loss: 0.3411, Generator Loss: 3.4140\nEpoch [69/100], Step [300/324], Discriminator Loss: 0.0005, Generator Loss: 3.8139\nEpoch [69/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.9305\nEpoch [69/100], Step [320/324], Discriminator Loss: 0.2512, Generator Loss: 4.0681\nEpoch [70/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.8247\nEpoch [70/100], Step [10/324], Discriminator Loss: 0.0003, Generator Loss: 3.8611\nEpoch [70/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.3053\nEpoch [70/100], Step [30/324], Discriminator Loss: 0.0443, Generator Loss: 2.7040\nEpoch [70/100], Step [40/324], Discriminator Loss: 0.1213, Generator Loss: 4.0018\nEpoch [70/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.0373\nEpoch [70/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.5489\nEpoch [70/100], Step [70/324], Discriminator Loss: 0.1901, Generator Loss: 4.2365\nEpoch [70/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 4.3503\nEpoch [70/100], Step [90/324], Discriminator Loss: 0.2772, Generator Loss: 4.3029\nEpoch [70/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.0904\nEpoch [70/100], Step [110/324], Discriminator Loss: 0.1431, Generator Loss: 3.1254\nEpoch [70/100], Step [120/324], Discriminator Loss: 0.4487, Generator Loss: 4.0026\nEpoch [70/100], Step [130/324], Discriminator Loss: 0.0004, Generator Loss: 4.2342\nEpoch [70/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 5.0908\nEpoch [70/100], Step [150/324], Discriminator Loss: 0.2134, Generator Loss: 3.3840\nEpoch [70/100], Step [160/324], Discriminator Loss: 0.0002, Generator Loss: 4.2663\nEpoch [70/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.4905\nEpoch [70/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.1927\nEpoch [70/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 3.4690\nEpoch [70/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 3.8304\nEpoch [70/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.5980\nEpoch [70/100], Step [220/324], Discriminator Loss: 0.3313, Generator Loss: 3.5008\nEpoch [70/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.4419\nEpoch [70/100], Step [240/324], Discriminator Loss: 0.0003, Generator Loss: 3.6459\nEpoch [70/100], Step [250/324], Discriminator Loss: 0.0004, Generator Loss: 3.7845\nEpoch [70/100], Step [260/324], Discriminator Loss: 0.3033, Generator Loss: 4.0955\nEpoch [70/100], Step [270/324], Discriminator Loss: 0.1924, Generator Loss: 3.7351\nEpoch [70/100], Step [280/324], Discriminator Loss: 0.1285, Generator Loss: 4.2660\nEpoch [70/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.8759\nEpoch [70/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.6469\nEpoch [70/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 5.7456\nEpoch [70/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 5.2463\nEpoch [71/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.3116\nEpoch [71/100], Step [10/324], Discriminator Loss: 0.2969, Generator Loss: 3.5584\nEpoch [71/100], Step [20/324], Discriminator Loss: 0.0005, Generator Loss: 3.2534\nEpoch [71/100], Step [30/324], Discriminator Loss: 0.1470, Generator Loss: 3.7695\nEpoch [71/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.2872\nEpoch [71/100], Step [50/324], Discriminator Loss: 0.1925, Generator Loss: 4.0363\nEpoch [71/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.8108\nEpoch [71/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 3.5466\nEpoch [71/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 4.7166\nEpoch [71/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.7079\nEpoch [71/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.7125\nEpoch [71/100], Step [110/324], Discriminator Loss: 0.2130, Generator Loss: 4.8759\nEpoch [71/100], Step [120/324], Discriminator Loss: 0.5722, Generator Loss: 4.2631\nEpoch [71/100], Step [130/324], Discriminator Loss: 0.1783, Generator Loss: 4.0463\nEpoch [71/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.4238\nEpoch [71/100], Step [150/324], Discriminator Loss: 0.2364, Generator Loss: 3.2856\nEpoch [71/100], Step [160/324], Discriminator Loss: 0.0002, Generator Loss: 3.9065\nEpoch [71/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 3.5930\nEpoch [71/100], Step [180/324], Discriminator Loss: 0.1820, Generator Loss: 4.1472\nEpoch [71/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.9312\nEpoch [71/100], Step [200/324], Discriminator Loss: 0.1856, Generator Loss: 4.0109\nEpoch [71/100], Step [210/324], Discriminator Loss: 0.0624, Generator Loss: 4.1429\nEpoch [71/100], Step [220/324], Discriminator Loss: 0.2350, Generator Loss: 4.7341\nEpoch [71/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.8374\nEpoch [71/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 3.8338\nEpoch [71/100], Step [250/324], Discriminator Loss: 0.4156, Generator Loss: 4.0002\nEpoch [71/100], Step [260/324], Discriminator Loss: 0.3057, Generator Loss: 3.1157\nEpoch [71/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.4465\nEpoch [71/100], Step [280/324], Discriminator Loss: 0.2123, Generator Loss: 3.9717\nEpoch [71/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.6361\nEpoch [71/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 4.0865\nEpoch [71/100], Step [310/324], Discriminator Loss: 0.2374, Generator Loss: 3.9447\nEpoch [71/100], Step [320/324], Discriminator Loss: 0.2360, Generator Loss: 3.7568\nEpoch [72/100], Step [0/324], Discriminator Loss: 0.0597, Generator Loss: 3.8678\nEpoch [72/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.6457\nEpoch [72/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 4.3419\nEpoch [72/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 3.4174\nEpoch [72/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 3.7316\nEpoch [72/100], Step [50/324], Discriminator Loss: 0.0546, Generator Loss: 3.6334\nEpoch [72/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.3464\nEpoch [72/100], Step [70/324], Discriminator Loss: 0.2397, Generator Loss: 5.1486\nEpoch [72/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 3.9074\nEpoch [72/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.8214\nEpoch [72/100], Step [100/324], Discriminator Loss: 0.2934, Generator Loss: 3.8437\nEpoch [72/100], Step [110/324], Discriminator Loss: 0.5296, Generator Loss: 3.5597\nEpoch [72/100], Step [120/324], Discriminator Loss: 0.1957, Generator Loss: 3.4176\nEpoch [72/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.2125\nEpoch [72/100], Step [140/324], Discriminator Loss: 0.2001, Generator Loss: 4.3042\nEpoch [72/100], Step [150/324], Discriminator Loss: 0.2843, Generator Loss: 4.4215\nEpoch [72/100], Step [160/324], Discriminator Loss: 0.0520, Generator Loss: 3.5313\nEpoch [72/100], Step [170/324], Discriminator Loss: 0.2210, Generator Loss: 4.9595\nEpoch [72/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.3351\nEpoch [72/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.3627\nEpoch [72/100], Step [200/324], Discriminator Loss: 0.3603, Generator Loss: 3.8967\nEpoch [72/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.1919\nEpoch [72/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.6302\nEpoch [72/100], Step [230/324], Discriminator Loss: 0.2496, Generator Loss: 4.2312\nEpoch [72/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.1605\nEpoch [72/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.8090\nEpoch [72/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.9295\nEpoch [72/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.8315\nEpoch [72/100], Step [280/324], Discriminator Loss: 0.3296, Generator Loss: 3.6858\nEpoch [72/100], Step [290/324], Discriminator Loss: 0.2324, Generator Loss: 3.9360\nEpoch [72/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 3.7707\nEpoch [72/100], Step [310/324], Discriminator Loss: 0.0005, Generator Loss: 4.5767\nEpoch [72/100], Step [320/324], Discriminator Loss: 0.0791, Generator Loss: 4.5593\nEpoch [73/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.1569\nEpoch [73/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.6271\nEpoch [73/100], Step [20/324], Discriminator Loss: 0.1487, Generator Loss: 3.5760\nEpoch [73/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.8856\nEpoch [73/100], Step [40/324], Discriminator Loss: 0.3994, Generator Loss: 4.4642\nEpoch [73/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.4543\nEpoch [73/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.5841\nEpoch [73/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.1294\nEpoch [73/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 3.7901\nEpoch [73/100], Step [90/324], Discriminator Loss: 0.2354, Generator Loss: 3.6188\nEpoch [73/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 3.4731\nEpoch [73/100], Step [110/324], Discriminator Loss: 0.1414, Generator Loss: 4.2238\nEpoch [73/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.6684\nEpoch [73/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.7512\nEpoch [73/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.0834\nEpoch [73/100], Step [150/324], Discriminator Loss: 0.3820, Generator Loss: 4.3906\nEpoch [73/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.8402\nEpoch [73/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 4.9289\nEpoch [73/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.4600\nEpoch [73/100], Step [190/324], Discriminator Loss: 0.3596, Generator Loss: 3.9936\nEpoch [73/100], Step [200/324], Discriminator Loss: 0.2458, Generator Loss: 3.2680\nEpoch [73/100], Step [210/324], Discriminator Loss: 0.1139, Generator Loss: 4.0167\nEpoch [73/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.4828\nEpoch [73/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.6633\nEpoch [73/100], Step [240/324], Discriminator Loss: 0.0673, Generator Loss: 4.0940\nEpoch [73/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.5776\nEpoch [73/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.0810\nEpoch [73/100], Step [270/324], Discriminator Loss: 0.1804, Generator Loss: 3.7551\nEpoch [73/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.9183\nEpoch [73/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.2165\nEpoch [73/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 3.9989\nEpoch [73/100], Step [310/324], Discriminator Loss: 0.1268, Generator Loss: 3.7159\nEpoch [73/100], Step [320/324], Discriminator Loss: 0.1836, Generator Loss: 3.9975\nEpoch [74/100], Step [0/324], Discriminator Loss: 0.1815, Generator Loss: 3.8259\nEpoch [74/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 3.6828\nEpoch [74/100], Step [20/324], Discriminator Loss: 0.0572, Generator Loss: 4.0800\nEpoch [74/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 5.2678\nEpoch [74/100], Step [40/324], Discriminator Loss: 0.3480, Generator Loss: 4.3064\nEpoch [74/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.4280\nEpoch [74/100], Step [60/324], Discriminator Loss: 0.3094, Generator Loss: 3.9477\nEpoch [74/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.9614\nEpoch [74/100], Step [80/324], Discriminator Loss: 0.2007, Generator Loss: 3.9948\nEpoch [74/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.3552\nEpoch [74/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.0255\nEpoch [74/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.1485\nEpoch [74/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.2344\nEpoch [74/100], Step [130/324], Discriminator Loss: 0.4011, Generator Loss: 4.7827\nEpoch [74/100], Step [140/324], Discriminator Loss: 0.0002, Generator Loss: 3.5545\nEpoch [74/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.0185\nEpoch [74/100], Step [160/324], Discriminator Loss: 0.1234, Generator Loss: 3.9075\nEpoch [74/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.3894\nEpoch [74/100], Step [180/324], Discriminator Loss: 0.7276, Generator Loss: 4.0640\nEpoch [74/100], Step [190/324], Discriminator Loss: 0.0580, Generator Loss: 3.7722\nEpoch [74/100], Step [200/324], Discriminator Loss: 0.1544, Generator Loss: 3.5496\nEpoch [74/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.6562\nEpoch [74/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.8598\nEpoch [74/100], Step [230/324], Discriminator Loss: 0.2414, Generator Loss: 3.1944\nEpoch [74/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.0930\nEpoch [74/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.8820\nEpoch [74/100], Step [260/324], Discriminator Loss: 0.2127, Generator Loss: 3.6347\nEpoch [74/100], Step [270/324], Discriminator Loss: 0.1305, Generator Loss: 4.1274\nEpoch [74/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 4.9842\nEpoch [74/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.6441\nEpoch [74/100], Step [300/324], Discriminator Loss: 0.3327, Generator Loss: 3.4037\nEpoch [74/100], Step [310/324], Discriminator Loss: 0.0003, Generator Loss: 3.8753\nEpoch [74/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 4.5300\nEpoch [75/100], Step [0/324], Discriminator Loss: 0.2679, Generator Loss: 4.5814\nEpoch [75/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.0388\nEpoch [75/100], Step [20/324], Discriminator Loss: 0.1805, Generator Loss: 4.0510\nEpoch [75/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.4289\nEpoch [75/100], Step [40/324], Discriminator Loss: 0.2024, Generator Loss: 3.3292\nEpoch [75/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 4.2055\nEpoch [75/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.4413\nEpoch [75/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.3327\nEpoch [75/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.9520\nEpoch [75/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.3551\nEpoch [75/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.9966\nEpoch [75/100], Step [110/324], Discriminator Loss: 0.1326, Generator Loss: 4.0607\nEpoch [75/100], Step [120/324], Discriminator Loss: 0.2126, Generator Loss: 3.3514\nEpoch [75/100], Step [130/324], Discriminator Loss: 0.0450, Generator Loss: 3.1984\nEpoch [75/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.6806\nEpoch [75/100], Step [150/324], Discriminator Loss: 0.0000, Generator Loss: 5.4483\nEpoch [75/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.5436\nEpoch [75/100], Step [170/324], Discriminator Loss: 0.1138, Generator Loss: 3.4153\nEpoch [75/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 3.9117\nEpoch [75/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.0283\nEpoch [75/100], Step [200/324], Discriminator Loss: 0.1653, Generator Loss: 3.4886\nEpoch [75/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.5321\nEpoch [75/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 3.8206\nEpoch [75/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.4845\nEpoch [75/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 5.0833\nEpoch [75/100], Step [250/324], Discriminator Loss: 0.3530, Generator Loss: 4.2804\nEpoch [75/100], Step [260/324], Discriminator Loss: 0.0009, Generator Loss: 2.9103\nEpoch [75/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.0546\nEpoch [75/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.9633\nEpoch [75/100], Step [290/324], Discriminator Loss: 0.1162, Generator Loss: 3.5162\nEpoch [75/100], Step [300/324], Discriminator Loss: 0.0616, Generator Loss: 4.0131\nEpoch [75/100], Step [310/324], Discriminator Loss: 0.1379, Generator Loss: 4.3247\nEpoch [75/100], Step [320/324], Discriminator Loss: 0.0004, Generator Loss: 3.3478\nEpoch [76/100], Step [0/324], Discriminator Loss: 0.2299, Generator Loss: 3.6139\nEpoch [76/100], Step [10/324], Discriminator Loss: 0.0615, Generator Loss: 3.7824\nEpoch [76/100], Step [20/324], Discriminator Loss: 0.1821, Generator Loss: 3.7028\nEpoch [76/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 3.3915\nEpoch [76/100], Step [40/324], Discriminator Loss: 0.1754, Generator Loss: 3.9379\nEpoch [76/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.9091\nEpoch [76/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.9097\nEpoch [76/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.0350\nEpoch [76/100], Step [80/324], Discriminator Loss: 0.1175, Generator Loss: 4.2838\nEpoch [76/100], Step [90/324], Discriminator Loss: 0.0585, Generator Loss: 4.1799\nEpoch [76/100], Step [100/324], Discriminator Loss: 0.2206, Generator Loss: 4.6177\nEpoch [76/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.2761\nEpoch [76/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 4.5881\nEpoch [76/100], Step [130/324], Discriminator Loss: 0.1622, Generator Loss: 3.4975\nEpoch [76/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.9219\nEpoch [76/100], Step [150/324], Discriminator Loss: 0.2410, Generator Loss: 3.9369\nEpoch [76/100], Step [160/324], Discriminator Loss: 0.2986, Generator Loss: 4.6312\nEpoch [76/100], Step [170/324], Discriminator Loss: 0.3601, Generator Loss: 4.7782\nEpoch [76/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.0950\nEpoch [76/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.2802\nEpoch [76/100], Step [200/324], Discriminator Loss: 0.2054, Generator Loss: 4.5154\nEpoch [76/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.3781\nEpoch [76/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 3.7263\nEpoch [76/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.9273\nEpoch [76/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 3.6583\nEpoch [76/100], Step [250/324], Discriminator Loss: 0.0631, Generator Loss: 4.3023\nEpoch [76/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.2467\nEpoch [76/100], Step [270/324], Discriminator Loss: 0.3325, Generator Loss: 2.9464\nEpoch [76/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.6800\nEpoch [76/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 4.0575\nEpoch [76/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 3.7777\nEpoch [76/100], Step [310/324], Discriminator Loss: 0.1990, Generator Loss: 3.4549\nEpoch [76/100], Step [320/324], Discriminator Loss: 0.3542, Generator Loss: 4.4609\nEpoch [77/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.3167\nEpoch [77/100], Step [10/324], Discriminator Loss: 0.2000, Generator Loss: 3.7044\nEpoch [77/100], Step [20/324], Discriminator Loss: 0.0004, Generator Loss: 3.1566\nEpoch [77/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.9026\nEpoch [77/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.0462\nEpoch [77/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.2671\nEpoch [77/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 3.9889\nEpoch [77/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.1083\nEpoch [77/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.0928\nEpoch [77/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.6201\nEpoch [77/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.7203\nEpoch [77/100], Step [110/324], Discriminator Loss: 0.3545, Generator Loss: 5.7724\nEpoch [77/100], Step [120/324], Discriminator Loss: 0.2233, Generator Loss: 3.5017\nEpoch [77/100], Step [130/324], Discriminator Loss: 0.0003, Generator Loss: 3.9961\nEpoch [77/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.7576\nEpoch [77/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 3.8978\nEpoch [77/100], Step [160/324], Discriminator Loss: 0.1520, Generator Loss: 3.1585\nEpoch [77/100], Step [170/324], Discriminator Loss: 0.2093, Generator Loss: 3.8648\nEpoch [77/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.8041\nEpoch [77/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.0898\nEpoch [77/100], Step [200/324], Discriminator Loss: 0.1633, Generator Loss: 4.3434\nEpoch [77/100], Step [210/324], Discriminator Loss: 0.0955, Generator Loss: 3.6536\nEpoch [77/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.4212\nEpoch [77/100], Step [230/324], Discriminator Loss: 0.4577, Generator Loss: 3.9397\nEpoch [77/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.0783\nEpoch [77/100], Step [250/324], Discriminator Loss: 0.0005, Generator Loss: 4.0659\nEpoch [77/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.0306\nEpoch [77/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.1898\nEpoch [77/100], Step [280/324], Discriminator Loss: 0.6779, Generator Loss: 4.0127\nEpoch [77/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 3.8576\nEpoch [77/100], Step [300/324], Discriminator Loss: 0.2515, Generator Loss: 3.8774\nEpoch [77/100], Step [310/324], Discriminator Loss: 0.3686, Generator Loss: 3.9011\nEpoch [77/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 4.4781\nEpoch [78/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.9346\nEpoch [78/100], Step [10/324], Discriminator Loss: 0.5980, Generator Loss: 4.4819\nEpoch [78/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 3.4718\nEpoch [78/100], Step [30/324], Discriminator Loss: 0.2563, Generator Loss: 4.0832\nEpoch [78/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.1222\nEpoch [78/100], Step [50/324], Discriminator Loss: 0.2128, Generator Loss: 4.4729\nEpoch [78/100], Step [60/324], Discriminator Loss: 0.3616, Generator Loss: 4.4036\nEpoch [78/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 3.2083\nEpoch [78/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.7402\nEpoch [78/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.7087\nEpoch [78/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.2198\nEpoch [78/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.0470\nEpoch [78/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.1485\nEpoch [78/100], Step [130/324], Discriminator Loss: 0.3757, Generator Loss: 3.5818\nEpoch [78/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.4091\nEpoch [78/100], Step [150/324], Discriminator Loss: 0.2645, Generator Loss: 4.5903\nEpoch [78/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 3.9617\nEpoch [78/100], Step [170/324], Discriminator Loss: 0.0004, Generator Loss: 3.3078\nEpoch [78/100], Step [180/324], Discriminator Loss: 0.2638, Generator Loss: 4.3989\nEpoch [78/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.5506\nEpoch [78/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.0169\nEpoch [78/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.0010\nEpoch [78/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 5.0220\nEpoch [78/100], Step [230/324], Discriminator Loss: 0.0000, Generator Loss: 3.4623\nEpoch [78/100], Step [240/324], Discriminator Loss: 0.1160, Generator Loss: 4.2551\nEpoch [78/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.1400\nEpoch [78/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.0278\nEpoch [78/100], Step [270/324], Discriminator Loss: 0.2192, Generator Loss: 3.7482\nEpoch [78/100], Step [280/324], Discriminator Loss: 0.2249, Generator Loss: 3.7635\nEpoch [78/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 3.3836\nEpoch [78/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 5.0824\nEpoch [78/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 5.1223\nEpoch [78/100], Step [320/324], Discriminator Loss: 0.1522, Generator Loss: 4.9106\nEpoch [79/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 4.6974\nEpoch [79/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 4.1726\nEpoch [79/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 3.8710\nEpoch [79/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.7945\nEpoch [79/100], Step [40/324], Discriminator Loss: 0.1958, Generator Loss: 4.1472\nEpoch [79/100], Step [50/324], Discriminator Loss: 0.2620, Generator Loss: 4.3266\nEpoch [79/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.5477\nEpoch [79/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 3.3857\nEpoch [79/100], Step [80/324], Discriminator Loss: 0.2296, Generator Loss: 3.7748\nEpoch [79/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.7094\nEpoch [79/100], Step [100/324], Discriminator Loss: 0.0020, Generator Loss: 3.8295\nEpoch [79/100], Step [110/324], Discriminator Loss: 0.3668, Generator Loss: 4.6711\nEpoch [79/100], Step [120/324], Discriminator Loss: 0.0005, Generator Loss: 3.7549\nEpoch [79/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 3.6224\nEpoch [79/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.3658\nEpoch [79/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.1839\nEpoch [79/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.4289\nEpoch [79/100], Step [170/324], Discriminator Loss: 0.2188, Generator Loss: 4.3679\nEpoch [79/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 3.7431\nEpoch [79/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 3.5999\nEpoch [79/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 3.6617\nEpoch [79/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.1069\nEpoch [79/100], Step [220/324], Discriminator Loss: 0.0503, Generator Loss: 4.3202\nEpoch [79/100], Step [230/324], Discriminator Loss: 0.1476, Generator Loss: 3.5506\nEpoch [79/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 5.4154\nEpoch [79/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.3082\nEpoch [79/100], Step [260/324], Discriminator Loss: 0.0009, Generator Loss: 3.5960\nEpoch [79/100], Step [270/324], Discriminator Loss: 0.0437, Generator Loss: 4.2436\nEpoch [79/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.3619\nEpoch [79/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 4.7430\nEpoch [79/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 4.6198\nEpoch [79/100], Step [310/324], Discriminator Loss: 0.0000, Generator Loss: 4.2160\nEpoch [79/100], Step [320/324], Discriminator Loss: 0.3197, Generator Loss: 3.8505\nEpoch [80/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.5333\nEpoch [80/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.8652\nEpoch [80/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.9409\nEpoch [80/100], Step [30/324], Discriminator Loss: 0.0003, Generator Loss: 4.6506\nEpoch [80/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 5.0030\nEpoch [80/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.8247\nEpoch [80/100], Step [60/324], Discriminator Loss: 0.1505, Generator Loss: 3.3009\nEpoch [80/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 3.4833\nEpoch [80/100], Step [80/324], Discriminator Loss: 0.3106, Generator Loss: 4.2240\nEpoch [80/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 3.7427\nEpoch [80/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.7739\nEpoch [80/100], Step [110/324], Discriminator Loss: 0.0003, Generator Loss: 3.3130\nEpoch [80/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 3.6001\nEpoch [80/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.7633\nEpoch [80/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.6500\nEpoch [80/100], Step [150/324], Discriminator Loss: 0.1319, Generator Loss: 4.1607\nEpoch [80/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.3552\nEpoch [80/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 4.9121\nEpoch [80/100], Step [180/324], Discriminator Loss: 0.1699, Generator Loss: 3.3199\nEpoch [80/100], Step [190/324], Discriminator Loss: 0.2835, Generator Loss: 3.1119\nEpoch [80/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.2927\nEpoch [80/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.1552\nEpoch [80/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 5.2080\nEpoch [80/100], Step [230/324], Discriminator Loss: 0.1946, Generator Loss: 3.9296\nEpoch [80/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.3547\nEpoch [80/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.1646\nEpoch [80/100], Step [260/324], Discriminator Loss: 0.1549, Generator Loss: 3.6531\nEpoch [80/100], Step [270/324], Discriminator Loss: 0.0003, Generator Loss: 3.8431\nEpoch [80/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.8289\nEpoch [80/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.8247\nEpoch [80/100], Step [300/324], Discriminator Loss: 0.1383, Generator Loss: 4.1709\nEpoch [80/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.7142\nEpoch [80/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 4.0035\nEpoch [81/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.0935\nEpoch [81/100], Step [10/324], Discriminator Loss: 0.3062, Generator Loss: 4.1721\nEpoch [81/100], Step [20/324], Discriminator Loss: 0.0003, Generator Loss: 3.2582\nEpoch [81/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.1166\nEpoch [81/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.0545\nEpoch [81/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 5.4433\nEpoch [81/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 4.5742\nEpoch [81/100], Step [70/324], Discriminator Loss: 0.0006, Generator Loss: 3.8639\nEpoch [81/100], Step [80/324], Discriminator Loss: 0.0008, Generator Loss: 4.2396\nEpoch [81/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 5.7077\nEpoch [81/100], Step [100/324], Discriminator Loss: 0.2089, Generator Loss: 4.7046\nEpoch [81/100], Step [110/324], Discriminator Loss: 0.0018, Generator Loss: 3.9929\nEpoch [81/100], Step [120/324], Discriminator Loss: 0.0010, Generator Loss: 4.1633\nEpoch [81/100], Step [130/324], Discriminator Loss: 0.3192, Generator Loss: 3.9098\nEpoch [81/100], Step [140/324], Discriminator Loss: 0.0042, Generator Loss: 3.6795\nEpoch [81/100], Step [150/324], Discriminator Loss: 0.0010, Generator Loss: 3.9107\nEpoch [81/100], Step [160/324], Discriminator Loss: 0.2351, Generator Loss: 5.0144\nEpoch [81/100], Step [170/324], Discriminator Loss: 0.2518, Generator Loss: 5.1919\nEpoch [81/100], Step [180/324], Discriminator Loss: 0.0015, Generator Loss: 3.2858\nEpoch [81/100], Step [190/324], Discriminator Loss: 0.0024, Generator Loss: 3.6811\nEpoch [81/100], Step [200/324], Discriminator Loss: 0.0005, Generator Loss: 3.3817\nEpoch [81/100], Step [210/324], Discriminator Loss: 0.0003, Generator Loss: 4.0918\nEpoch [81/100], Step [220/324], Discriminator Loss: 0.2317, Generator Loss: 5.3008\nEpoch [81/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.9274\nEpoch [81/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 4.3419\nEpoch [81/100], Step [250/324], Discriminator Loss: 0.0005, Generator Loss: 3.6548\nEpoch [81/100], Step [260/324], Discriminator Loss: 0.0008, Generator Loss: 3.2589\nEpoch [81/100], Step [270/324], Discriminator Loss: 0.0003, Generator Loss: 3.7263\nEpoch [81/100], Step [280/324], Discriminator Loss: 0.0009, Generator Loss: 3.3051\nEpoch [81/100], Step [290/324], Discriminator Loss: 0.1148, Generator Loss: 3.9638\nEpoch [81/100], Step [300/324], Discriminator Loss: 0.0002, Generator Loss: 4.5977\nEpoch [81/100], Step [310/324], Discriminator Loss: 0.3488, Generator Loss: 3.9495\nEpoch [81/100], Step [320/324], Discriminator Loss: 0.2185, Generator Loss: 3.5524\nEpoch [82/100], Step [0/324], Discriminator Loss: 0.0004, Generator Loss: 3.4274\nEpoch [82/100], Step [10/324], Discriminator Loss: 0.0005, Generator Loss: 3.5932\nEpoch [82/100], Step [20/324], Discriminator Loss: 0.0005, Generator Loss: 3.5826\nEpoch [82/100], Step [30/324], Discriminator Loss: 0.1675, Generator Loss: 3.8807\nEpoch [82/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.7844\nEpoch [82/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.9155\nEpoch [82/100], Step [60/324], Discriminator Loss: 0.0806, Generator Loss: 4.0202\nEpoch [82/100], Step [70/324], Discriminator Loss: 0.1392, Generator Loss: 4.5555\nEpoch [82/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 4.1434\nEpoch [82/100], Step [90/324], Discriminator Loss: 0.2382, Generator Loss: 3.8498\nEpoch [82/100], Step [100/324], Discriminator Loss: 0.0005, Generator Loss: 3.2983\nEpoch [82/100], Step [110/324], Discriminator Loss: 0.0004, Generator Loss: 4.1842\nEpoch [82/100], Step [120/324], Discriminator Loss: 0.0010, Generator Loss: 2.8535\nEpoch [82/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.8801\nEpoch [82/100], Step [140/324], Discriminator Loss: 0.2395, Generator Loss: 3.8896\nEpoch [82/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.4646\nEpoch [82/100], Step [160/324], Discriminator Loss: 0.0488, Generator Loss: 3.1691\nEpoch [82/100], Step [170/324], Discriminator Loss: 0.1953, Generator Loss: 4.0875\nEpoch [82/100], Step [180/324], Discriminator Loss: 0.0004, Generator Loss: 3.1300\nEpoch [82/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.0074\nEpoch [82/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.2694\nEpoch [82/100], Step [210/324], Discriminator Loss: 0.0005, Generator Loss: 3.4895\nEpoch [82/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 3.7494\nEpoch [82/100], Step [230/324], Discriminator Loss: 0.1242, Generator Loss: 4.2106\nEpoch [82/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 4.6280\nEpoch [82/100], Step [250/324], Discriminator Loss: 0.0002, Generator Loss: 3.8678\nEpoch [82/100], Step [260/324], Discriminator Loss: 0.3009, Generator Loss: 3.8633\nEpoch [82/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 4.0401\nEpoch [82/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 4.6592\nEpoch [82/100], Step [290/324], Discriminator Loss: 0.1876, Generator Loss: 4.1554\nEpoch [82/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.7855\nEpoch [82/100], Step [310/324], Discriminator Loss: 0.3502, Generator Loss: 5.4360\nEpoch [82/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 4.5136\nEpoch [83/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 4.1718\nEpoch [83/100], Step [10/324], Discriminator Loss: 0.1851, Generator Loss: 4.0105\nEpoch [83/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.0702\nEpoch [83/100], Step [30/324], Discriminator Loss: 0.2403, Generator Loss: 3.9979\nEpoch [83/100], Step [40/324], Discriminator Loss: 0.0004, Generator Loss: 3.9484\nEpoch [83/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.6068\nEpoch [83/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.3397\nEpoch [83/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 4.5353\nEpoch [83/100], Step [80/324], Discriminator Loss: 0.0002, Generator Loss: 4.4736\nEpoch [83/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.3415\nEpoch [83/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 3.2608\nEpoch [83/100], Step [110/324], Discriminator Loss: 0.2237, Generator Loss: 4.2149\nEpoch [83/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 3.9334\nEpoch [83/100], Step [130/324], Discriminator Loss: 0.2751, Generator Loss: 3.5214\nEpoch [83/100], Step [140/324], Discriminator Loss: 0.1068, Generator Loss: 3.8264\nEpoch [83/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.3602\nEpoch [83/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.2284\nEpoch [83/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 4.2631\nEpoch [83/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 5.2496\nEpoch [83/100], Step [190/324], Discriminator Loss: 0.0007, Generator Loss: 3.7304\nEpoch [83/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 4.0656\nEpoch [83/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.2092\nEpoch [83/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 3.7615\nEpoch [83/100], Step [230/324], Discriminator Loss: 0.1496, Generator Loss: 5.3668\nEpoch [83/100], Step [240/324], Discriminator Loss: 0.5047, Generator Loss: 5.1748\nEpoch [83/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.2827\nEpoch [83/100], Step [260/324], Discriminator Loss: 0.2264, Generator Loss: 3.7422\nEpoch [83/100], Step [270/324], Discriminator Loss: 0.2234, Generator Loss: 3.7751\nEpoch [83/100], Step [280/324], Discriminator Loss: 0.2245, Generator Loss: 4.6282\nEpoch [83/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.5940\nEpoch [83/100], Step [300/324], Discriminator Loss: 0.1032, Generator Loss: 3.4867\nEpoch [83/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.8613\nEpoch [83/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 3.9700\nEpoch [84/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.7126\nEpoch [84/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 3.5901\nEpoch [84/100], Step [20/324], Discriminator Loss: 0.0706, Generator Loss: 4.2209\nEpoch [84/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.5154\nEpoch [84/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 3.7114\nEpoch [84/100], Step [50/324], Discriminator Loss: 0.3014, Generator Loss: 3.9276\nEpoch [84/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.3589\nEpoch [84/100], Step [70/324], Discriminator Loss: 0.2163, Generator Loss: 5.0408\nEpoch [84/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.1695\nEpoch [84/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 3.3983\nEpoch [84/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.0408\nEpoch [84/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.4836\nEpoch [84/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.4186\nEpoch [84/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.2236\nEpoch [84/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.3699\nEpoch [84/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.1299\nEpoch [84/100], Step [160/324], Discriminator Loss: 0.1234, Generator Loss: 3.9452\nEpoch [84/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 3.7899\nEpoch [84/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.7634\nEpoch [84/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 4.5852\nEpoch [84/100], Step [200/324], Discriminator Loss: 0.3876, Generator Loss: 3.6214\nEpoch [84/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 3.4384\nEpoch [84/100], Step [220/324], Discriminator Loss: 0.0574, Generator Loss: 3.7034\nEpoch [84/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 4.5196\nEpoch [84/100], Step [240/324], Discriminator Loss: 0.2746, Generator Loss: 4.4877\nEpoch [84/100], Step [250/324], Discriminator Loss: 0.2607, Generator Loss: 3.3890\nEpoch [84/100], Step [260/324], Discriminator Loss: 0.1150, Generator Loss: 3.6687\nEpoch [84/100], Step [270/324], Discriminator Loss: 0.0552, Generator Loss: 3.7500\nEpoch [84/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.0609\nEpoch [84/100], Step [290/324], Discriminator Loss: 0.3709, Generator Loss: 4.6026\nEpoch [84/100], Step [300/324], Discriminator Loss: 0.3694, Generator Loss: 3.9541\nEpoch [84/100], Step [310/324], Discriminator Loss: 0.2371, Generator Loss: 3.7607\nEpoch [84/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 4.2517\nEpoch [85/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.1866\nEpoch [85/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.5829\nEpoch [85/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.8080\nEpoch [85/100], Step [30/324], Discriminator Loss: 0.4761, Generator Loss: 3.9224\nEpoch [85/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 3.2346\nEpoch [85/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 3.8675\nEpoch [85/100], Step [60/324], Discriminator Loss: 0.1178, Generator Loss: 3.5758\nEpoch [85/100], Step [70/324], Discriminator Loss: 0.3112, Generator Loss: 3.4651\nEpoch [85/100], Step [80/324], Discriminator Loss: 0.2854, Generator Loss: 3.6257\nEpoch [85/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.3106\nEpoch [85/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 5.1351\nEpoch [85/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.4482\nEpoch [85/100], Step [120/324], Discriminator Loss: 0.2601, Generator Loss: 4.2047\nEpoch [85/100], Step [130/324], Discriminator Loss: 0.5514, Generator Loss: 3.4187\nEpoch [85/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.2139\nEpoch [85/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.8005\nEpoch [85/100], Step [160/324], Discriminator Loss: 0.0002, Generator Loss: 3.6333\nEpoch [85/100], Step [170/324], Discriminator Loss: 0.1210, Generator Loss: 3.9274\nEpoch [85/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 3.6812\nEpoch [85/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 3.8416\nEpoch [85/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 3.8224\nEpoch [85/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.9366\nEpoch [85/100], Step [220/324], Discriminator Loss: 0.0002, Generator Loss: 3.4923\nEpoch [85/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.8462\nEpoch [85/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.4928\nEpoch [85/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.6639\nEpoch [85/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.8053\nEpoch [85/100], Step [270/324], Discriminator Loss: 0.4856, Generator Loss: 3.5982\nEpoch [85/100], Step [280/324], Discriminator Loss: 0.1521, Generator Loss: 3.5934\nEpoch [85/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 5.0200\nEpoch [85/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.5152\nEpoch [85/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.6371\nEpoch [85/100], Step [320/324], Discriminator Loss: 0.2233, Generator Loss: 3.3293\nEpoch [86/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.4208\nEpoch [86/100], Step [10/324], Discriminator Loss: 0.0003, Generator Loss: 3.9308\nEpoch [86/100], Step [20/324], Discriminator Loss: 0.2210, Generator Loss: 3.5929\nEpoch [86/100], Step [30/324], Discriminator Loss: 0.4530, Generator Loss: 3.0922\nEpoch [86/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 3.6234\nEpoch [86/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 5.1494\nEpoch [86/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 5.1214\nEpoch [86/100], Step [70/324], Discriminator Loss: 0.2284, Generator Loss: 4.5834\nEpoch [86/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.1506\nEpoch [86/100], Step [90/324], Discriminator Loss: 0.0599, Generator Loss: 4.1917\nEpoch [86/100], Step [100/324], Discriminator Loss: 0.2364, Generator Loss: 3.8269\nEpoch [86/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 5.0054\nEpoch [86/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.1599\nEpoch [86/100], Step [130/324], Discriminator Loss: 0.0002, Generator Loss: 4.4673\nEpoch [86/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.4752\nEpoch [86/100], Step [150/324], Discriminator Loss: 0.0002, Generator Loss: 3.4331\nEpoch [86/100], Step [160/324], Discriminator Loss: 0.0000, Generator Loss: 4.4407\nEpoch [86/100], Step [170/324], Discriminator Loss: 0.3235, Generator Loss: 3.5776\nEpoch [86/100], Step [180/324], Discriminator Loss: 0.1998, Generator Loss: 3.4327\nEpoch [86/100], Step [190/324], Discriminator Loss: 0.1071, Generator Loss: 3.4099\nEpoch [86/100], Step [200/324], Discriminator Loss: 0.2122, Generator Loss: 4.5912\nEpoch [86/100], Step [210/324], Discriminator Loss: 0.2736, Generator Loss: 4.3443\nEpoch [86/100], Step [220/324], Discriminator Loss: 0.3190, Generator Loss: 4.3034\nEpoch [86/100], Step [230/324], Discriminator Loss: 0.1946, Generator Loss: 4.0812\nEpoch [86/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 3.7930\nEpoch [86/100], Step [250/324], Discriminator Loss: 0.1822, Generator Loss: 3.8608\nEpoch [86/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.3517\nEpoch [86/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.2132\nEpoch [86/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.2493\nEpoch [86/100], Step [290/324], Discriminator Loss: 0.1428, Generator Loss: 2.9588\nEpoch [86/100], Step [300/324], Discriminator Loss: 0.1009, Generator Loss: 3.9026\nEpoch [86/100], Step [310/324], Discriminator Loss: 0.2005, Generator Loss: 4.5473\nEpoch [86/100], Step [320/324], Discriminator Loss: 0.1005, Generator Loss: 3.2507\nEpoch [87/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.2005\nEpoch [87/100], Step [10/324], Discriminator Loss: 0.2057, Generator Loss: 4.3443\nEpoch [87/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.8887\nEpoch [87/100], Step [30/324], Discriminator Loss: 0.2742, Generator Loss: 4.4056\nEpoch [87/100], Step [40/324], Discriminator Loss: 0.0003, Generator Loss: 4.7810\nEpoch [87/100], Step [50/324], Discriminator Loss: 0.1770, Generator Loss: 4.7875\nEpoch [87/100], Step [60/324], Discriminator Loss: 0.4728, Generator Loss: 3.2504\nEpoch [87/100], Step [70/324], Discriminator Loss: 0.0002, Generator Loss: 3.5589\nEpoch [87/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.6421\nEpoch [87/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.4875\nEpoch [87/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.3966\nEpoch [87/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.3859\nEpoch [87/100], Step [120/324], Discriminator Loss: 0.1471, Generator Loss: 3.2635\nEpoch [87/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.1393\nEpoch [87/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 4.2703\nEpoch [87/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.3249\nEpoch [87/100], Step [160/324], Discriminator Loss: 0.1572, Generator Loss: 4.2656\nEpoch [87/100], Step [170/324], Discriminator Loss: 0.1575, Generator Loss: 2.8867\nEpoch [87/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.6210\nEpoch [87/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 5.3257\nEpoch [87/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.7020\nEpoch [87/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 5.0390\nEpoch [87/100], Step [220/324], Discriminator Loss: 0.0754, Generator Loss: 4.8722\nEpoch [87/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.8613\nEpoch [87/100], Step [240/324], Discriminator Loss: 0.1619, Generator Loss: 3.0074\nEpoch [87/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.4586\nEpoch [87/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.7352\nEpoch [87/100], Step [270/324], Discriminator Loss: 0.2906, Generator Loss: 3.2602\nEpoch [87/100], Step [280/324], Discriminator Loss: 0.1737, Generator Loss: 4.7620\nEpoch [87/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.4359\nEpoch [87/100], Step [300/324], Discriminator Loss: 0.0000, Generator Loss: 5.8724\nEpoch [87/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 3.4169\nEpoch [87/100], Step [320/324], Discriminator Loss: 1.7271, Generator Loss: 3.6975\nEpoch [88/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 3.6029\nEpoch [88/100], Step [10/324], Discriminator Loss: 0.3243, Generator Loss: 3.4487\nEpoch [88/100], Step [20/324], Discriminator Loss: 0.1941, Generator Loss: 4.3653\nEpoch [88/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.5427\nEpoch [88/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 4.0620\nEpoch [88/100], Step [50/324], Discriminator Loss: 0.2591, Generator Loss: 4.5990\nEpoch [88/100], Step [60/324], Discriminator Loss: 0.0004, Generator Loss: 3.3369\nEpoch [88/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.3083\nEpoch [88/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.3795\nEpoch [88/100], Step [90/324], Discriminator Loss: 0.0001, Generator Loss: 4.8918\nEpoch [88/100], Step [100/324], Discriminator Loss: 0.6546, Generator Loss: 3.4624\nEpoch [88/100], Step [110/324], Discriminator Loss: 0.0005, Generator Loss: 3.1553\nEpoch [88/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.7684\nEpoch [88/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.7279\nEpoch [88/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.8418\nEpoch [88/100], Step [150/324], Discriminator Loss: 0.0003, Generator Loss: 3.9704\nEpoch [88/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.3474\nEpoch [88/100], Step [170/324], Discriminator Loss: 0.0002, Generator Loss: 4.4425\nEpoch [88/100], Step [180/324], Discriminator Loss: 1.5630, Generator Loss: 3.4629\nEpoch [88/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 4.1986\nEpoch [88/100], Step [200/324], Discriminator Loss: 0.0002, Generator Loss: 3.8023\nEpoch [88/100], Step [210/324], Discriminator Loss: 0.2612, Generator Loss: 4.0411\nEpoch [88/100], Step [220/324], Discriminator Loss: 0.3720, Generator Loss: 3.6059\nEpoch [88/100], Step [230/324], Discriminator Loss: 0.0007, Generator Loss: 3.4601\nEpoch [88/100], Step [240/324], Discriminator Loss: 0.0008, Generator Loss: 4.1609\nEpoch [88/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.9080\nEpoch [88/100], Step [260/324], Discriminator Loss: 0.0002, Generator Loss: 3.6104\nEpoch [88/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.7936\nEpoch [88/100], Step [280/324], Discriminator Loss: 0.2524, Generator Loss: 4.7690\nEpoch [88/100], Step [290/324], Discriminator Loss: 0.1397, Generator Loss: 4.2996\nEpoch [88/100], Step [300/324], Discriminator Loss: 0.0469, Generator Loss: 3.2414\nEpoch [88/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 4.3265\nEpoch [88/100], Step [320/324], Discriminator Loss: 0.0006, Generator Loss: 3.9528\nEpoch [89/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.1500\nEpoch [89/100], Step [10/324], Discriminator Loss: 0.0003, Generator Loss: 5.0905\nEpoch [89/100], Step [20/324], Discriminator Loss: 0.1443, Generator Loss: 4.1799\nEpoch [89/100], Step [30/324], Discriminator Loss: 0.2446, Generator Loss: 3.8052\nEpoch [89/100], Step [40/324], Discriminator Loss: 0.0002, Generator Loss: 3.9206\nEpoch [89/100], Step [50/324], Discriminator Loss: 0.0004, Generator Loss: 3.9050\nEpoch [89/100], Step [60/324], Discriminator Loss: 0.0007, Generator Loss: 3.3678\nEpoch [89/100], Step [70/324], Discriminator Loss: 0.0003, Generator Loss: 3.5288\nEpoch [89/100], Step [80/324], Discriminator Loss: 0.0003, Generator Loss: 4.5562\nEpoch [89/100], Step [90/324], Discriminator Loss: 0.2903, Generator Loss: 4.5393\nEpoch [89/100], Step [100/324], Discriminator Loss: 0.1544, Generator Loss: 3.3178\nEpoch [89/100], Step [110/324], Discriminator Loss: 0.0003, Generator Loss: 4.1116\nEpoch [89/100], Step [120/324], Discriminator Loss: 0.6547, Generator Loss: 4.2006\nEpoch [89/100], Step [130/324], Discriminator Loss: 0.0005, Generator Loss: 3.7891\nEpoch [89/100], Step [140/324], Discriminator Loss: 0.0003, Generator Loss: 3.2934\nEpoch [89/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.0133\nEpoch [89/100], Step [160/324], Discriminator Loss: 0.5131, Generator Loss: 3.9283\nEpoch [89/100], Step [170/324], Discriminator Loss: 0.2303, Generator Loss: 3.5523\nEpoch [89/100], Step [180/324], Discriminator Loss: 0.0002, Generator Loss: 3.8188\nEpoch [89/100], Step [190/324], Discriminator Loss: 0.0002, Generator Loss: 3.7053\nEpoch [89/100], Step [200/324], Discriminator Loss: 0.2663, Generator Loss: 4.2438\nEpoch [89/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 4.4731\nEpoch [89/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.1551\nEpoch [89/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.9034\nEpoch [89/100], Step [240/324], Discriminator Loss: 0.0003, Generator Loss: 3.0677\nEpoch [89/100], Step [250/324], Discriminator Loss: 0.1922, Generator Loss: 4.0147\nEpoch [89/100], Step [260/324], Discriminator Loss: 0.0002, Generator Loss: 4.1841\nEpoch [89/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.3461\nEpoch [89/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 4.3808\nEpoch [89/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.9242\nEpoch [89/100], Step [300/324], Discriminator Loss: 0.3477, Generator Loss: 3.4923\nEpoch [89/100], Step [310/324], Discriminator Loss: 0.0003, Generator Loss: 3.6869\nEpoch [89/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 3.8201\nEpoch [90/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.9036\nEpoch [90/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 3.9731\nEpoch [90/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.9922\nEpoch [90/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.6733\nEpoch [90/100], Step [40/324], Discriminator Loss: 0.1054, Generator Loss: 3.9917\nEpoch [90/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 3.7006\nEpoch [90/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.9456\nEpoch [90/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.1341\nEpoch [90/100], Step [80/324], Discriminator Loss: 0.2317, Generator Loss: 3.8947\nEpoch [90/100], Step [90/324], Discriminator Loss: 0.1262, Generator Loss: 3.7341\nEpoch [90/100], Step [100/324], Discriminator Loss: 0.8135, Generator Loss: 3.9816\nEpoch [90/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 4.0213\nEpoch [90/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.3284\nEpoch [90/100], Step [130/324], Discriminator Loss: 0.2213, Generator Loss: 3.6121\nEpoch [90/100], Step [140/324], Discriminator Loss: 0.0003, Generator Loss: 3.9659\nEpoch [90/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.5918\nEpoch [90/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.2233\nEpoch [90/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 4.2831\nEpoch [90/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.4179\nEpoch [90/100], Step [190/324], Discriminator Loss: 0.1916, Generator Loss: 3.9639\nEpoch [90/100], Step [200/324], Discriminator Loss: 0.0001, Generator Loss: 4.0750\nEpoch [90/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 4.3869\nEpoch [90/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.8128\nEpoch [90/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.1289\nEpoch [90/100], Step [240/324], Discriminator Loss: 0.2033, Generator Loss: 3.3487\nEpoch [90/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.3890\nEpoch [90/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.0670\nEpoch [90/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 4.0728\nEpoch [90/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 3.9608\nEpoch [90/100], Step [290/324], Discriminator Loss: 0.1017, Generator Loss: 3.2555\nEpoch [90/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 3.8208\nEpoch [90/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.6103\nEpoch [90/100], Step [320/324], Discriminator Loss: 0.2318, Generator Loss: 3.8896\nEpoch [91/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.0308\nEpoch [91/100], Step [10/324], Discriminator Loss: 0.0000, Generator Loss: 3.9269\nEpoch [91/100], Step [20/324], Discriminator Loss: 0.0000, Generator Loss: 5.3499\nEpoch [91/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 3.5627\nEpoch [91/100], Step [40/324], Discriminator Loss: 0.3240, Generator Loss: 4.0955\nEpoch [91/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.2605\nEpoch [91/100], Step [60/324], Discriminator Loss: 0.2004, Generator Loss: 4.2633\nEpoch [91/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 3.6951\nEpoch [91/100], Step [80/324], Discriminator Loss: 0.1417, Generator Loss: 4.3815\nEpoch [91/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 4.3913\nEpoch [91/100], Step [100/324], Discriminator Loss: 0.0004, Generator Loss: 3.2619\nEpoch [91/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.9409\nEpoch [91/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.9240\nEpoch [91/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.8377\nEpoch [91/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.2180\nEpoch [91/100], Step [150/324], Discriminator Loss: 0.2183, Generator Loss: 4.5199\nEpoch [91/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.1210\nEpoch [91/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 4.3091\nEpoch [91/100], Step [180/324], Discriminator Loss: 0.1894, Generator Loss: 4.1044\nEpoch [91/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.8253\nEpoch [91/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.4016\nEpoch [91/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 4.0380\nEpoch [91/100], Step [220/324], Discriminator Loss: 0.3603, Generator Loss: 3.2138\nEpoch [91/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.2316\nEpoch [91/100], Step [240/324], Discriminator Loss: 0.0539, Generator Loss: 3.7657\nEpoch [91/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 4.7700\nEpoch [91/100], Step [260/324], Discriminator Loss: 0.3700, Generator Loss: 4.3142\nEpoch [91/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 3.3745\nEpoch [91/100], Step [280/324], Discriminator Loss: 0.2516, Generator Loss: 3.3276\nEpoch [91/100], Step [290/324], Discriminator Loss: 0.1858, Generator Loss: 3.7541\nEpoch [91/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.4847\nEpoch [91/100], Step [310/324], Discriminator Loss: 0.0003, Generator Loss: 3.7305\nEpoch [91/100], Step [320/324], Discriminator Loss: 0.4929, Generator Loss: 3.7857\nEpoch [92/100], Step [0/324], Discriminator Loss: 0.0003, Generator Loss: 3.4519\nEpoch [92/100], Step [10/324], Discriminator Loss: 0.1199, Generator Loss: 4.2858\nEpoch [92/100], Step [20/324], Discriminator Loss: 0.3022, Generator Loss: 4.1015\nEpoch [92/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 4.1652\nEpoch [92/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.9502\nEpoch [92/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 4.3164\nEpoch [92/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 5.0900\nEpoch [92/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.1421\nEpoch [92/100], Step [80/324], Discriminator Loss: 0.4683, Generator Loss: 4.1214\nEpoch [92/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 3.4938\nEpoch [92/100], Step [100/324], Discriminator Loss: 0.1689, Generator Loss: 3.6086\nEpoch [92/100], Step [110/324], Discriminator Loss: 0.3984, Generator Loss: 4.4020\nEpoch [92/100], Step [120/324], Discriminator Loss: 0.1618, Generator Loss: 3.5875\nEpoch [92/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.6716\nEpoch [92/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.7645\nEpoch [92/100], Step [150/324], Discriminator Loss: 0.1813, Generator Loss: 3.9146\nEpoch [92/100], Step [160/324], Discriminator Loss: 0.1684, Generator Loss: 3.6401\nEpoch [92/100], Step [170/324], Discriminator Loss: 0.0001, Generator Loss: 3.2828\nEpoch [92/100], Step [180/324], Discriminator Loss: 0.0484, Generator Loss: 3.3902\nEpoch [92/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 3.7650\nEpoch [92/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 3.8549\nEpoch [92/100], Step [210/324], Discriminator Loss: 0.0594, Generator Loss: 3.6111\nEpoch [92/100], Step [220/324], Discriminator Loss: 0.1945, Generator Loss: 4.2448\nEpoch [92/100], Step [230/324], Discriminator Loss: 0.0003, Generator Loss: 3.7530\nEpoch [92/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 3.6439\nEpoch [92/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.8628\nEpoch [92/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.0860\nEpoch [92/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.5420\nEpoch [92/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 5.1129\nEpoch [92/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 3.5781\nEpoch [92/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.2212\nEpoch [92/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 4.0209\nEpoch [92/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 3.6979\nEpoch [93/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 4.0257\nEpoch [93/100], Step [10/324], Discriminator Loss: 0.1497, Generator Loss: 4.7166\nEpoch [93/100], Step [20/324], Discriminator Loss: 0.3593, Generator Loss: 4.1808\nEpoch [93/100], Step [30/324], Discriminator Loss: 0.0002, Generator Loss: 3.5260\nEpoch [93/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.2091\nEpoch [93/100], Step [50/324], Discriminator Loss: 0.2559, Generator Loss: 3.9457\nEpoch [93/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 3.5356\nEpoch [93/100], Step [70/324], Discriminator Loss: 0.0003, Generator Loss: 3.5714\nEpoch [93/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.6190\nEpoch [93/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 4.5438\nEpoch [93/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.7116\nEpoch [93/100], Step [110/324], Discriminator Loss: 0.0002, Generator Loss: 3.7632\nEpoch [93/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.2428\nEpoch [93/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.9886\nEpoch [93/100], Step [140/324], Discriminator Loss: 0.4316, Generator Loss: 4.0574\nEpoch [93/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 4.1288\nEpoch [93/100], Step [160/324], Discriminator Loss: 0.0434, Generator Loss: 3.7779\nEpoch [93/100], Step [170/324], Discriminator Loss: 0.0505, Generator Loss: 4.0222\nEpoch [93/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 4.4970\nEpoch [93/100], Step [190/324], Discriminator Loss: 0.3958, Generator Loss: 4.4948\nEpoch [93/100], Step [200/324], Discriminator Loss: 0.1713, Generator Loss: 4.1746\nEpoch [93/100], Step [210/324], Discriminator Loss: 0.0003, Generator Loss: 3.4165\nEpoch [93/100], Step [220/324], Discriminator Loss: 0.3731, Generator Loss: 4.4677\nEpoch [93/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 4.2425\nEpoch [93/100], Step [240/324], Discriminator Loss: 0.2139, Generator Loss: 1.7357\nEpoch [93/100], Step [250/324], Discriminator Loss: 0.0044, Generator Loss: 4.8751\nEpoch [93/100], Step [260/324], Discriminator Loss: 0.4762, Generator Loss: 3.9313\nEpoch [93/100], Step [270/324], Discriminator Loss: 0.1931, Generator Loss: 3.7641\nEpoch [93/100], Step [280/324], Discriminator Loss: 0.0494, Generator Loss: 3.7804\nEpoch [93/100], Step [290/324], Discriminator Loss: 0.0009, Generator Loss: 3.5879\nEpoch [93/100], Step [300/324], Discriminator Loss: 0.0084, Generator Loss: 3.4659\nEpoch [93/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 4.2756\nEpoch [93/100], Step [320/324], Discriminator Loss: 0.0000, Generator Loss: 5.5496\nEpoch [94/100], Step [0/324], Discriminator Loss: 0.0001, Generator Loss: 5.6131\nEpoch [94/100], Step [10/324], Discriminator Loss: 0.0001, Generator Loss: 4.6600\nEpoch [94/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 3.8183\nEpoch [94/100], Step [30/324], Discriminator Loss: 0.1004, Generator Loss: 3.4340\nEpoch [94/100], Step [40/324], Discriminator Loss: 0.0001, Generator Loss: 4.0750\nEpoch [94/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.3825\nEpoch [94/100], Step [60/324], Discriminator Loss: 0.0001, Generator Loss: 4.2562\nEpoch [94/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.1797\nEpoch [94/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 3.2006\nEpoch [94/100], Step [90/324], Discriminator Loss: 0.1660, Generator Loss: 3.5977\nEpoch [94/100], Step [100/324], Discriminator Loss: 0.0657, Generator Loss: 4.2739\nEpoch [94/100], Step [110/324], Discriminator Loss: 0.0001, Generator Loss: 3.5149\nEpoch [94/100], Step [120/324], Discriminator Loss: 0.0001, Generator Loss: 4.0227\nEpoch [94/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.4892\nEpoch [94/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.3979\nEpoch [94/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.7865\nEpoch [94/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.0613\nEpoch [94/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 4.5694\nEpoch [94/100], Step [180/324], Discriminator Loss: 0.2013, Generator Loss: 4.2749\nEpoch [94/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.6054\nEpoch [94/100], Step [200/324], Discriminator Loss: 0.1275, Generator Loss: 4.1901\nEpoch [94/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 4.1783\nEpoch [94/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.6220\nEpoch [94/100], Step [230/324], Discriminator Loss: 0.2020, Generator Loss: 4.2235\nEpoch [94/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 3.6906\nEpoch [94/100], Step [250/324], Discriminator Loss: 0.0003, Generator Loss: 3.1244\nEpoch [94/100], Step [260/324], Discriminator Loss: 0.0003, Generator Loss: 3.8421\nEpoch [94/100], Step [270/324], Discriminator Loss: 0.4088, Generator Loss: 4.3856\nEpoch [94/100], Step [280/324], Discriminator Loss: 0.6502, Generator Loss: 3.9541\nEpoch [94/100], Step [290/324], Discriminator Loss: 0.0002, Generator Loss: 3.0175\nEpoch [94/100], Step [300/324], Discriminator Loss: 0.0001, Generator Loss: 4.1622\nEpoch [94/100], Step [310/324], Discriminator Loss: 0.2957, Generator Loss: 4.6307\nEpoch [94/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 3.8592\nEpoch [95/100], Step [0/324], Discriminator Loss: 0.0003, Generator Loss: 3.7539\nEpoch [95/100], Step [10/324], Discriminator Loss: 0.0003, Generator Loss: 3.7731\nEpoch [95/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.3432\nEpoch [95/100], Step [30/324], Discriminator Loss: 0.4637, Generator Loss: 3.7401\nEpoch [95/100], Step [40/324], Discriminator Loss: 0.1850, Generator Loss: 3.6959\nEpoch [95/100], Step [50/324], Discriminator Loss: 0.0002, Generator Loss: 4.0912\nEpoch [95/100], Step [60/324], Discriminator Loss: 0.0004, Generator Loss: 3.5490\nEpoch [95/100], Step [70/324], Discriminator Loss: 0.4794, Generator Loss: 4.0144\nEpoch [95/100], Step [80/324], Discriminator Loss: 0.0001, Generator Loss: 4.0391\nEpoch [95/100], Step [90/324], Discriminator Loss: 0.0002, Generator Loss: 3.5485\nEpoch [95/100], Step [100/324], Discriminator Loss: 0.2241, Generator Loss: 4.6708\nEpoch [95/100], Step [110/324], Discriminator Loss: 0.0733, Generator Loss: 4.4087\nEpoch [95/100], Step [120/324], Discriminator Loss: 0.0002, Generator Loss: 3.9020\nEpoch [95/100], Step [130/324], Discriminator Loss: 0.0546, Generator Loss: 3.9446\nEpoch [95/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 4.4956\nEpoch [95/100], Step [150/324], Discriminator Loss: 0.2191, Generator Loss: 3.8745\nEpoch [95/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.1156\nEpoch [95/100], Step [170/324], Discriminator Loss: 0.2451, Generator Loss: 3.8653\nEpoch [95/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.4392\nEpoch [95/100], Step [190/324], Discriminator Loss: 0.0006, Generator Loss: 2.7151\nEpoch [95/100], Step [200/324], Discriminator Loss: 0.2620, Generator Loss: 5.2440\nEpoch [95/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.3642\nEpoch [95/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 4.2013\nEpoch [95/100], Step [230/324], Discriminator Loss: 0.0010, Generator Loss: 3.4310\nEpoch [95/100], Step [240/324], Discriminator Loss: 0.0000, Generator Loss: 4.5719\nEpoch [95/100], Step [250/324], Discriminator Loss: 0.0023, Generator Loss: 3.6381\nEpoch [95/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.8637\nEpoch [95/100], Step [270/324], Discriminator Loss: 0.0002, Generator Loss: 4.0553\nEpoch [95/100], Step [280/324], Discriminator Loss: 0.1438, Generator Loss: 4.3988\nEpoch [95/100], Step [290/324], Discriminator Loss: 0.4735, Generator Loss: 4.1029\nEpoch [95/100], Step [300/324], Discriminator Loss: 0.3015, Generator Loss: 3.9882\nEpoch [95/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 4.3889\nEpoch [95/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 3.5517\nEpoch [96/100], Step [0/324], Discriminator Loss: 0.0004, Generator Loss: 3.6857\nEpoch [96/100], Step [10/324], Discriminator Loss: 0.0006, Generator Loss: 3.3341\nEpoch [96/100], Step [20/324], Discriminator Loss: 0.0002, Generator Loss: 3.2297\nEpoch [96/100], Step [30/324], Discriminator Loss: 0.0000, Generator Loss: 4.2203\nEpoch [96/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.1652\nEpoch [96/100], Step [50/324], Discriminator Loss: 0.0000, Generator Loss: 5.2356\nEpoch [96/100], Step [60/324], Discriminator Loss: 0.0000, Generator Loss: 4.9800\nEpoch [96/100], Step [70/324], Discriminator Loss: 0.0000, Generator Loss: 4.3020\nEpoch [96/100], Step [80/324], Discriminator Loss: 0.0694, Generator Loss: 4.5289\nEpoch [96/100], Step [90/324], Discriminator Loss: 0.1200, Generator Loss: 3.9009\nEpoch [96/100], Step [100/324], Discriminator Loss: 0.0000, Generator Loss: 4.3671\nEpoch [96/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 4.0192\nEpoch [96/100], Step [120/324], Discriminator Loss: 0.1737, Generator Loss: 4.3727\nEpoch [96/100], Step [130/324], Discriminator Loss: 0.0003, Generator Loss: 3.2774\nEpoch [96/100], Step [140/324], Discriminator Loss: 0.3091, Generator Loss: 3.5934\nEpoch [96/100], Step [150/324], Discriminator Loss: 0.1842, Generator Loss: 3.2679\nEpoch [96/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.1876\nEpoch [96/100], Step [170/324], Discriminator Loss: 0.1631, Generator Loss: 5.1707\nEpoch [96/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 4.2548\nEpoch [96/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 3.6355\nEpoch [96/100], Step [200/324], Discriminator Loss: 0.0611, Generator Loss: 3.9459\nEpoch [96/100], Step [210/324], Discriminator Loss: 0.0002, Generator Loss: 3.4801\nEpoch [96/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 3.7924\nEpoch [96/100], Step [230/324], Discriminator Loss: 0.1711, Generator Loss: 3.7207\nEpoch [96/100], Step [240/324], Discriminator Loss: 0.2865, Generator Loss: 3.4577\nEpoch [96/100], Step [250/324], Discriminator Loss: 0.0001, Generator Loss: 3.8812\nEpoch [96/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 3.6659\nEpoch [96/100], Step [270/324], Discriminator Loss: 0.0001, Generator Loss: 3.7266\nEpoch [96/100], Step [280/324], Discriminator Loss: 0.0000, Generator Loss: 4.7210\nEpoch [96/100], Step [290/324], Discriminator Loss: 0.0001, Generator Loss: 5.4005\nEpoch [96/100], Step [300/324], Discriminator Loss: 0.0008, Generator Loss: 4.4233\nEpoch [96/100], Step [310/324], Discriminator Loss: 0.0011, Generator Loss: 3.9866\nEpoch [96/100], Step [320/324], Discriminator Loss: 0.0003, Generator Loss: 4.1809\nEpoch [97/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 4.2775\nEpoch [97/100], Step [10/324], Discriminator Loss: 0.2421, Generator Loss: 4.3782\nEpoch [97/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 3.8656\nEpoch [97/100], Step [30/324], Discriminator Loss: 0.2244, Generator Loss: 3.4825\nEpoch [97/100], Step [40/324], Discriminator Loss: 0.0000, Generator Loss: 4.0576\nEpoch [97/100], Step [50/324], Discriminator Loss: 0.0005, Generator Loss: 3.3288\nEpoch [97/100], Step [60/324], Discriminator Loss: 0.0003, Generator Loss: 3.6859\nEpoch [97/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 3.9715\nEpoch [97/100], Step [80/324], Discriminator Loss: 0.2984, Generator Loss: 3.7069\nEpoch [97/100], Step [90/324], Discriminator Loss: 0.1476, Generator Loss: 3.8492\nEpoch [97/100], Step [100/324], Discriminator Loss: 0.0003, Generator Loss: 3.6549\nEpoch [97/100], Step [110/324], Discriminator Loss: 0.1150, Generator Loss: 4.0214\nEpoch [97/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.2579\nEpoch [97/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 4.2948\nEpoch [97/100], Step [140/324], Discriminator Loss: 0.0000, Generator Loss: 5.3772\nEpoch [97/100], Step [150/324], Discriminator Loss: 0.1944, Generator Loss: 4.0474\nEpoch [97/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 3.6787\nEpoch [97/100], Step [170/324], Discriminator Loss: 0.1869, Generator Loss: 4.1766\nEpoch [97/100], Step [180/324], Discriminator Loss: 0.0001, Generator Loss: 3.3591\nEpoch [97/100], Step [190/324], Discriminator Loss: 0.0001, Generator Loss: 3.5491\nEpoch [97/100], Step [200/324], Discriminator Loss: 0.3478, Generator Loss: 3.9488\nEpoch [97/100], Step [210/324], Discriminator Loss: 0.0000, Generator Loss: 5.1310\nEpoch [97/100], Step [220/324], Discriminator Loss: 0.2007, Generator Loss: 4.3225\nEpoch [97/100], Step [230/324], Discriminator Loss: 0.1865, Generator Loss: 4.0386\nEpoch [97/100], Step [240/324], Discriminator Loss: 0.0002, Generator Loss: 3.4093\nEpoch [97/100], Step [250/324], Discriminator Loss: 0.1895, Generator Loss: 4.0517\nEpoch [97/100], Step [260/324], Discriminator Loss: 0.0000, Generator Loss: 4.1453\nEpoch [97/100], Step [270/324], Discriminator Loss: 0.5034, Generator Loss: 4.9155\nEpoch [97/100], Step [280/324], Discriminator Loss: 0.2486, Generator Loss: 4.0509\nEpoch [97/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 3.8763\nEpoch [97/100], Step [300/324], Discriminator Loss: 0.4471, Generator Loss: 3.8568\nEpoch [97/100], Step [310/324], Discriminator Loss: 0.0001, Generator Loss: 3.9268\nEpoch [97/100], Step [320/324], Discriminator Loss: 0.0001, Generator Loss: 4.8637\nEpoch [98/100], Step [0/324], Discriminator Loss: 0.0000, Generator Loss: 4.8811\nEpoch [98/100], Step [10/324], Discriminator Loss: 0.0002, Generator Loss: 3.6972\nEpoch [98/100], Step [20/324], Discriminator Loss: 0.0006, Generator Loss: 3.5261\nEpoch [98/100], Step [30/324], Discriminator Loss: 0.0007, Generator Loss: 3.6724\nEpoch [98/100], Step [40/324], Discriminator Loss: 0.0005, Generator Loss: 3.1579\nEpoch [98/100], Step [50/324], Discriminator Loss: 0.0001, Generator Loss: 4.3167\nEpoch [98/100], Step [60/324], Discriminator Loss: 0.3667, Generator Loss: 5.2034\nEpoch [98/100], Step [70/324], Discriminator Loss: 0.1561, Generator Loss: 4.7777\nEpoch [98/100], Step [80/324], Discriminator Loss: 0.0000, Generator Loss: 4.8060\nEpoch [98/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 4.9040\nEpoch [98/100], Step [100/324], Discriminator Loss: 0.4088, Generator Loss: 3.8848\nEpoch [98/100], Step [110/324], Discriminator Loss: 0.0000, Generator Loss: 3.9740\nEpoch [98/100], Step [120/324], Discriminator Loss: 0.0000, Generator Loss: 4.8261\nEpoch [98/100], Step [130/324], Discriminator Loss: 0.0000, Generator Loss: 4.2936\nEpoch [98/100], Step [140/324], Discriminator Loss: 0.1960, Generator Loss: 3.1546\nEpoch [98/100], Step [150/324], Discriminator Loss: 0.0590, Generator Loss: 3.9961\nEpoch [98/100], Step [160/324], Discriminator Loss: 0.0001, Generator Loss: 4.2204\nEpoch [98/100], Step [170/324], Discriminator Loss: 0.2447, Generator Loss: 4.0256\nEpoch [98/100], Step [180/324], Discriminator Loss: 0.0000, Generator Loss: 3.8482\nEpoch [98/100], Step [190/324], Discriminator Loss: 0.0000, Generator Loss: 4.7095\nEpoch [98/100], Step [200/324], Discriminator Loss: 0.0000, Generator Loss: 4.6274\nEpoch [98/100], Step [210/324], Discriminator Loss: 0.1422, Generator Loss: 3.2381\nEpoch [98/100], Step [220/324], Discriminator Loss: 0.0001, Generator Loss: 3.5219\nEpoch [98/100], Step [230/324], Discriminator Loss: 0.0001, Generator Loss: 3.2161\nEpoch [98/100], Step [240/324], Discriminator Loss: 0.0001, Generator Loss: 3.9877\nEpoch [98/100], Step [250/324], Discriminator Loss: 0.0000, Generator Loss: 4.3108\nEpoch [98/100], Step [260/324], Discriminator Loss: 0.0001, Generator Loss: 4.4482\nEpoch [98/100], Step [270/324], Discriminator Loss: 0.0000, Generator Loss: 4.3722\nEpoch [98/100], Step [280/324], Discriminator Loss: 0.0001, Generator Loss: 3.5883\nEpoch [98/100], Step [290/324], Discriminator Loss: 0.0000, Generator Loss: 4.9181\nEpoch [98/100], Step [300/324], Discriminator Loss: 0.1066, Generator Loss: 3.1671\nEpoch [98/100], Step [310/324], Discriminator Loss: 0.0002, Generator Loss: 3.7305\nEpoch [98/100], Step [320/324], Discriminator Loss: 0.1973, Generator Loss: 4.0088\nEpoch [99/100], Step [0/324], Discriminator Loss: 0.0002, Generator Loss: 3.5931\nEpoch [99/100], Step [10/324], Discriminator Loss: 0.1113, Generator Loss: 3.7792\nEpoch [99/100], Step [20/324], Discriminator Loss: 0.0001, Generator Loss: 4.5973\nEpoch [99/100], Step [30/324], Discriminator Loss: 0.0001, Generator Loss: 4.4805\nEpoch [99/100], Step [40/324], Discriminator Loss: 0.1530, Generator Loss: 3.5362\nEpoch [99/100], Step [50/324], Discriminator Loss: 0.0004, Generator Loss: 3.2266\nEpoch [99/100], Step [60/324], Discriminator Loss: 0.0002, Generator Loss: 3.3070\nEpoch [99/100], Step [70/324], Discriminator Loss: 0.0001, Generator Loss: 4.2589\nEpoch [99/100], Step [80/324], Discriminator Loss: 0.1655, Generator Loss: 5.1826\nEpoch [99/100], Step [90/324], Discriminator Loss: 0.0000, Generator Loss: 4.8257\nEpoch [99/100], Step [100/324], Discriminator Loss: 0.0001, Generator Loss: 4.2070\nEpoch [99/100], Step [110/324], Discriminator Loss: 0.3375, Generator Loss: 4.1885\nEpoch [99/100], Step [120/324], Discriminator Loss: 0.0003, Generator Loss: 2.8766\nEpoch [99/100], Step [130/324], Discriminator Loss: 0.0001, Generator Loss: 3.6405\nEpoch [99/100], Step [140/324], Discriminator Loss: 0.0001, Generator Loss: 3.8171\nEpoch [99/100], Step [150/324], Discriminator Loss: 0.0001, Generator Loss: 3.9682\nEpoch [99/100], Step [160/324], Discriminator Loss: 0.0511, Generator Loss: 5.1227\nEpoch [99/100], Step [170/324], Discriminator Loss: 0.0000, Generator Loss: 5.0870\nEpoch [99/100], Step [180/324], Discriminator Loss: 0.0469, Generator Loss: 4.1927\nEpoch [99/100], Step [190/324], Discriminator Loss: 0.2666, Generator Loss: 4.0996\nEpoch [99/100], Step [200/324], Discriminator Loss: 0.0020, Generator Loss: 4.0658\nEpoch [99/100], Step [210/324], Discriminator Loss: 0.0001, Generator Loss: 6.0274\nEpoch [99/100], Step [220/324], Discriminator Loss: 0.0000, Generator Loss: 4.9702\nEpoch [99/100], Step [230/324], Discriminator Loss: 0.0002, Generator Loss: 3.6978\nEpoch [99/100], Step [240/324], Discriminator Loss: 0.1703, Generator Loss: 3.6767\nEpoch [99/100], Step [250/324], Discriminator Loss: 0.0006, Generator Loss: 3.5392\nEpoch [99/100], Step [260/324], Discriminator Loss: 0.2321, Generator Loss: 3.7163\nEpoch [99/100], Step [270/324], Discriminator Loss: 0.1746, Generator Loss: 3.6807\nEpoch [99/100], Step [280/324], Discriminator Loss: 0.2123, Generator Loss: 3.4369\nEpoch [99/100], Step [290/324], Discriminator Loss: 0.2014, Generator Loss: 3.3786\nEpoch [99/100], Step [300/324], Discriminator Loss: 0.0004, Generator Loss: 3.3058\nEpoch [99/100], Step [310/324], Discriminator Loss: 0.3877, Generator Loss: 3.6064\nEpoch [99/100], Step [320/324], Discriminator Loss: 0.0002, Generator Loss: 4.0711\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trained_generator_new.state_dict(), '/kaggle/working/trained_generator_Faulttype.pth')\n",
        "torch.save(trained_discriminator.state_dict(), '/kaggle/working/trained_discriminator_Faulttype.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T17:53:55.391557Z",
          "iopub.execute_input": "2024-02-03T17:53:55.392052Z",
          "iopub.status.idle": "2024-02-03T17:53:55.404481Z",
          "shell.execute_reply.started": "2024-02-03T17:53:55.392010Z",
          "shell.execute_reply": "2024-02-03T17:53:55.402953Z"
        },
        "trusted": true,
        "id": "dXw3Xh9DXcmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise4 = torch.randn(800, 16, 51)\n",
        "\n",
        "generated_data4 = trained_generator_new(noise4)\n",
        "\n",
        "surrogate_outputs = model5(generated_data4)\n",
        "\n",
        "# Get the predicted class labels for each sample in the generated data\n",
        "predicted_labels = torch.argmax(surrogate_outputs, dim=1)\n",
        "print(predicted_labels)\n",
        "# Print the predicted labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T17:45:16.173815Z",
          "iopub.execute_input": "2024-02-03T17:45:16.174324Z",
          "iopub.status.idle": "2024-02-03T17:45:16.740426Z",
          "shell.execute_reply.started": "2024-02-03T17:45:16.174289Z",
          "shell.execute_reply": "2024-02-03T17:45:16.739294Z"
        },
        "trusted": true,
        "id": "Y_9b_gZtXcmZ",
        "outputId": "1d5086fa-4d36-4fea-da0a-722abf3058ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([ 0,  0,  5,  5,  2,  0,  6,  6,  0,  3,  3,  0,  0,  2,  2,  0,  2,  6,\n         6,  2,  0,  0,  0,  0,  2,  2,  2,  0,  7,  2,  2,  0,  0,  0, 10,  6,\n         0,  3,  2,  6,  0,  2,  7,  6,  0,  0,  0,  0,  2,  9,  0,  2,  0,  0,\n         0,  0,  0,  2,  0,  7,  0,  2,  3,  0,  2,  2,  0,  2,  0,  6,  2,  0,\n         2,  2,  6,  2,  2,  2,  3,  0,  0,  0,  2,  5,  2,  2,  8,  6,  2,  0,\n         2,  5,  6,  0,  0,  5,  6,  3,  0,  9,  0,  2,  2,  0,  7,  0,  2,  2,\n         3,  6,  7, 10,  2,  0,  3,  0,  5,  2,  9,  0,  0,  0,  0,  0,  3,  0,\n         0,  2,  0,  2,  0,  0,  3,  0,  0,  2,  0,  2,  0,  2,  0,  0,  0,  0,\n         2,  2,  7,  0,  7,  2,  0,  3,  8,  6,  0,  0,  2,  2,  2,  9,  6,  0,\n         0,  0,  2,  2,  9,  0,  2,  2,  0,  0,  7,  3,  0,  0,  0,  2,  0,  0,\n         2,  0,  0,  3,  9,  0,  2,  0,  2,  0,  0,  3,  0,  3,  2,  6,  2,  9,\n         2,  0,  5,  0,  0,  0,  2,  0,  5,  9,  5,  6,  0,  2,  2,  2,  0,  0,\n         8,  0,  0,  6,  2,  0,  2,  0,  3,  3,  0,  6,  3,  5,  0,  0,  0,  0,\n         6,  0,  2,  2,  8,  0,  2,  2,  2,  0,  2,  2,  2,  2,  2,  2,  3,  0,\n         2,  3,  0,  2,  2,  2,  2,  2,  2,  0,  0,  6,  2,  7,  0,  0,  2,  0,\n         0,  2,  7,  0,  7,  2,  9,  6,  0,  0,  0,  2,  0,  0,  6,  0,  0,  0,\n         2,  0,  6,  2,  2,  0,  0,  2,  0,  0,  2,  2,  0,  0,  2,  0,  0,  8,\n         0,  8,  3,  6,  0,  0,  2,  2,  7,  2,  2,  9,  0,  2,  6,  0,  2,  9,\n         3,  2,  0,  0,  9,  2,  8,  6,  0,  3,  2,  2,  2,  0,  2,  0,  0,  5,\n         2,  2,  2,  2,  2,  2,  0,  0,  0,  4,  6,  8,  0,  5,  3,  0,  0,  0,\n         0,  2,  2,  0,  2,  0,  7,  0,  0,  0,  2,  0,  2,  9,  0,  2,  2,  0,\n         0,  3,  3,  0,  0,  2,  2,  2,  0,  0,  2,  6,  0,  0,  3,  2,  0, 10,\n         0,  9,  0,  0,  2,  2,  6,  3,  2,  0,  0,  0,  7,  0,  2,  2,  3,  3,\n         7,  2,  0,  7, 10,  0,  2,  2,  9,  0,  0,  0,  7,  2,  2,  2,  7,  0,\n         2,  2,  9,  2,  3,  0,  3,  0,  9,  7,  2,  2,  3,  2,  7,  0,  9,  0,\n         0,  0,  0,  2,  9,  0,  2,  0,  0,  0,  0,  0,  2,  3,  0,  9,  9,  9,\n         6,  0,  2,  0,  0,  0,  0,  7,  2,  0,  7,  5,  0,  0,  7,  6,  2,  0,\n         6,  3,  0,  0,  9,  0,  2,  2,  2,  0,  0,  2,  7,  0, 10,  6,  7,  0,\n         3,  3,  2,  0,  0,  0,  6,  6,  0,  0,  7,  2,  2,  0,  0,  6,  2,  0,\n         2,  2,  2, 10,  6,  3,  2,  6,  2,  9,  6,  9,  0,  2,  3,  0,  0,  3,\n         0,  2,  6,  0,  5,  2,  0,  2,  0,  0,  0,  0,  0,  2,  0,  2,  7,  2,\n         7,  2,  2,  0,  0,  2,  2,  9,  7,  0,  2,  2,  6,  2,  0,  0,  2,  2,\n         4,  7,  0,  2,  0,  0,  0,  0,  2,  6,  0,  0,  2,  2,  0,  7,  2,  0,\n         0,  3,  0,  2,  6,  7,  0,  6,  0,  2,  0,  0,  2,  0,  0,  2,  0,  2,\n         0,  0,  0,  2,  0,  0,  6,  3,  2,  0,  2,  6,  0,  0,  0,  4,  0,  2,\n         0,  0,  2,  2,  3,  0,  0,  0,  2,  2,  6,  7,  2,  0,  2,  6,  0,  2,\n         0,  2,  2,  3,  9,  2,  5, 10,  0,  2,  2,  3, 10,  0,  0,  2,  0,  0,\n         0,  0,  0,  7,  0,  2,  2,  9,  2,  0,  2,  0,  2,  4,  7,  0,  2,  2,\n         2,  2,  2,  0,  0,  2,  3,  0,  0,  0,  0,  7,  2,  2,  0,  9,  0,  0,\n         0,  0,  3,  0,  6,  0,  9,  0,  0,  3,  0,  0,  0,  5,  0,  2,  0,  0,\n         3,  0,  0,  2,  7,  0,  0,  0,  0,  0,  8,  2,  2,  0,  3,  0,  0,  5,\n         0,  2,  8,  0,  0,  7,  0,  0,  7,  3,  2,  0,  9,  0,  0,  0,  0, 10,\n         2,  0,  2,  2,  6,  3,  0,  2,  0,  7,  7,  2,  0,  3,  2,  3,  4,  3,\n         0,  2,  0,  8,  2,  2,  8,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  5,\n         6,  0,  0,  0,  2,  0,  7,  0])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store predicted class labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "trained_discriminator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "\n",
        "        # Get the discriminator's output for the current batch\n",
        "        surrogate_outputs = trained_discriminator(inputs)\n",
        "\n",
        "        # Apply thresholding to determine class labels\n",
        "        threshold = 0.45\n",
        "        batch_predicted_labels = (surrogate_outputs >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "        predicted_labels.append(batch_predicted_labels)\n",
        "\n",
        "# Convert the list of predicted labels to a single tensor\n",
        "predicted_labels = torch.cat(predicted_labels, dim=0)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T17:49:19.555235Z",
          "iopub.execute_input": "2024-02-03T17:49:19.556386Z",
          "iopub.status.idle": "2024-02-03T17:49:19.601471Z",
          "shell.execute_reply.started": "2024-02-03T17:49:19.556345Z",
          "shell.execute_reply": "2024-02-03T17:49:19.600349Z"
        },
        "trusted": true,
        "id": "6suWLeZWXcmZ",
        "outputId": "efcab7be-a5d7-436f-c379-cc3b55e5f251"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[1],\n         [1],\n         [1],\n         ...,\n         [1],\n         [1],\n         [1]],\n\n        [[1],\n         [1],\n         [1],\n         ...,\n         [1],\n         [1],\n         [1]],\n\n        [[1],\n         [1],\n         [1],\n         ...,\n         [1],\n         [1],\n         [1]],\n\n        ...,\n\n        [[1],\n         [1],\n         [1],\n         ...,\n         [1],\n         [1],\n         [1]],\n\n        [[1],\n         [1],\n         [1],\n         ...,\n         [1],\n         [1],\n         [1]],\n\n        [[1],\n         [1],\n         [1],\n         ...,\n         [1],\n         [1],\n         [1]]], dtype=torch.int32)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels (all 1)\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T17:49:22.279850Z",
          "iopub.execute_input": "2024-02-03T17:49:22.281264Z",
          "iopub.status.idle": "2024-02-03T17:49:22.291102Z",
          "shell.execute_reply.started": "2024-02-03T17:49:22.281207Z",
          "shell.execute_reply": "2024-02-03T17:49:22.289817Z"
        },
        "trusted": true,
        "id": "9FkONsJTXcmZ",
        "outputId": "28d0e7b1-e9bf-4898-e924-d410fff025f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 98.32%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noise4 = torch.randn(1500, 16, 51)\n",
        "\n",
        "generated_data4 = trained_generator_new(noise4)\n",
        "\n",
        "surrogate_outputs = trained_discriminator(generated_data4)\n",
        "predicted_labels = []\n",
        "\n",
        "# Apply thresholding to determine class labels\n",
        "threshold = 0.45\n",
        "batch_predicted_labels = (surrogate_outputs >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "predicted_labels.append(batch_predicted_labels)\n",
        "\n",
        "# Convert the list of predicted labels to a single tensor\n",
        "predicted_labels = torch.cat(predicted_labels, dim=0)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(predicted_labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T17:49:24.226905Z",
          "iopub.execute_input": "2024-02-03T17:49:24.227376Z",
          "iopub.status.idle": "2024-02-03T17:49:24.397336Z",
          "shell.execute_reply.started": "2024-02-03T17:49:24.227344Z",
          "shell.execute_reply": "2024-02-03T17:49:24.396165Z"
        },
        "trusted": true,
        "id": "7xs-xufkXcmZ",
        "outputId": "19ddc10d-76d1-4684-8021-d13854da71ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]], dtype=torch.int32)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T17:49:26.639604Z",
          "iopub.execute_input": "2024-02-03T17:49:26.640052Z",
          "iopub.status.idle": "2024-02-03T17:49:26.648518Z",
          "shell.execute_reply.started": "2024-02-03T17:49:26.640008Z",
          "shell.execute_reply": "2024-02-03T17:49:26.647197Z"
        },
        "trusted": true,
        "id": "Zuva2r9BXcmZ",
        "outputId": "09d1005d-d883-4c76-ec48-b22a008ad534"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 100.00%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "import torchattacks\n",
        "\n",
        "# Load the pre-trained model\n",
        "model5.eval()\n",
        "predicted_labels_fgsm= []\n",
        "predicted_labels_bim= []\n",
        "predicted_labels_cw= []\n",
        "predicted_labels_RFGSM=[]\n",
        "predicted_labels_PGD=[]\n",
        "# Assuming you have a DataLoader for the test set called 'test_loader'\n",
        "# Adjust this based on your data loading procedure\n",
        "# Also, make sure your test set is properly normalized\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.5 # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.5# Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.5# Perturbation magnitude for C&W\n",
        "\n",
        "threshold = 0.5\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = model5(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, labels)\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, labels)\n",
        "\n",
        "    # C&W: Craft adversarial example\n",
        "    attack_cw = torchattacks.CW(model5, c=epsilon_cw, kappa=0)\n",
        "    adversarial_inputs_cw = attack_cw(inputs, labels)\n",
        "\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, labels)\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, labels)\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = trained_discriminator(adversarial_inputs_fgsm)\n",
        "    batch_predicted_labels1 = (outputs_adversarial_fgsm >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "    predicted_labels_fgsm.append(batch_predicted_labels1)\n",
        "    outputs_adversarial_bim = trained_discriminator(adversarial_inputs_bim)\n",
        "    batch_predicted_labels2 = (outputs_adversarial_bim >= threshold).int()\n",
        "    predicted_labels_bim.append(batch_predicted_labels2)\n",
        "    outputs_adversarial_cw = trained_discriminator(adversarial_inputs_cw)\n",
        "    batch_predicted_labels3 = (outputs_adversarial_cw >= threshold).int()\n",
        "    predicted_labels_cw.append(batch_predicted_labels3)\n",
        "    outputs_adversarial_RFGSM = trained_discriminator(adversarial_inputs_RFGSM)\n",
        "    batch_predicted_labels4 = (outputs_adversarial_RFGSM >= threshold).int()\n",
        "    predicted_labels_RFGSM.append(batch_predicted_labels4)\n",
        "    outputs_adversarial_PGD = trained_discriminator(adversarial_inputs_PGD)\n",
        "    batch_predicted_labels5 = (outputs_adversarial_PGD >= threshold).int()\n",
        "    predicted_labels_PGD.append(batch_predicted_labels5)\n",
        "\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels_fgsm, dim=0)\n",
        "predicted_labels1 = torch.cat(predicted_labels_bim, dim=0)\n",
        "predicted_labels2= torch.cat(predicted_labels_cw, dim=0)\n",
        "predicted_labels3= torch.cat(predicted_labels_RFGSM, dim=0)\n",
        "predicted_labels4= torch.cat(predicted_labels_PGD, dim=0)\n",
        "\n",
        "print(predicted_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T18:05:22.450403Z",
          "iopub.execute_input": "2024-02-03T18:05:22.450841Z",
          "iopub.status.idle": "2024-02-03T18:05:53.381839Z",
          "shell.execute_reply.started": "2024-02-03T18:05:22.450809Z",
          "shell.execute_reply": "2024-02-03T18:05:53.380374Z"
        },
        "trusted": true,
        "id": "W-nSBJpVXcmZ",
        "outputId": "6a2835c0-04f4-45e5-f4de-ca18efe6d719"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        ...,\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]],\n\n        [[0],\n         [0],\n         [0],\n         ...,\n         [0],\n         [0],\n         [0]]], dtype=torch.int32)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T18:05:57.126531Z",
          "iopub.execute_input": "2024-02-03T18:05:57.128098Z",
          "iopub.status.idle": "2024-02-03T18:05:57.138495Z",
          "shell.execute_reply.started": "2024-02-03T18:05:57.128019Z",
          "shell.execute_reply": "2024-02-03T18:05:57.136656Z"
        },
        "trusted": true,
        "id": "yUT7SxQ9Xcma",
        "outputId": "70287fd4-3a8c-43e3-d552-a9781d757c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 100.00%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels1)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels1 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T18:05:58.505053Z",
          "iopub.execute_input": "2024-02-03T18:05:58.506328Z",
          "iopub.status.idle": "2024-02-03T18:05:58.516138Z",
          "shell.execute_reply.started": "2024-02-03T18:05:58.506278Z",
          "shell.execute_reply": "2024-02-03T18:05:58.514545Z"
        },
        "trusted": true,
        "id": "RgX10-8AXcma",
        "outputId": "95fc5c7b-26c9-4a24-8acf-74d877c7c8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 100.00%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels2)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels2 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T18:05:59.688550Z",
          "iopub.execute_input": "2024-02-03T18:05:59.689016Z",
          "iopub.status.idle": "2024-02-03T18:05:59.697443Z",
          "shell.execute_reply.started": "2024-02-03T18:05:59.688982Z",
          "shell.execute_reply": "2024-02-03T18:05:59.695757Z"
        },
        "trusted": true,
        "id": "2af4ZG2NXcma",
        "outputId": "532cddab-2d7d-437f-9fef-7a68c3ce9f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 89.78%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels3)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels3 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T18:06:01.357100Z",
          "iopub.execute_input": "2024-02-03T18:06:01.357578Z",
          "iopub.status.idle": "2024-02-03T18:06:01.366158Z",
          "shell.execute_reply.started": "2024-02-03T18:06:01.357533Z",
          "shell.execute_reply": "2024-02-03T18:06:01.364376Z"
        },
        "trusted": true,
        "id": "8sFttIOFXcma",
        "outputId": "ac4af715-877c-48da-e3c4-9aa6c0efd4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 100.00%\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels4)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels4 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T18:06:02.992789Z",
          "iopub.execute_input": "2024-02-03T18:06:02.993259Z",
          "iopub.status.idle": "2024-02-03T18:06:03.002232Z",
          "shell.execute_reply.started": "2024-02-03T18:06:02.993225Z",
          "shell.execute_reply": "2024-02-03T18:06:03.000631Z"
        },
        "trusted": true,
        "id": "-lCRVpN_Xcma",
        "outputId": "8152dbf6-ab54-4b72-8f13-32ac69e11b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 100.00%\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}