{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:24.857335Z",
          "iopub.status.busy": "2024-02-06T15:05:24.856900Z",
          "iopub.status.idle": "2024-02-06T15:05:31.368626Z",
          "shell.execute_reply": "2024-02-06T15:05:31.367397Z",
          "shell.execute_reply.started": "2024-02-06T15:05:24.857295Z"
        },
        "id": "IxLQoP8PYLcy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:31.372363Z",
          "iopub.status.busy": "2024-02-06T15:05:31.371382Z",
          "iopub.status.idle": "2024-02-06T15:05:31.770671Z",
          "shell.execute_reply": "2024-02-06T15:05:31.768943Z",
          "shell.execute_reply.started": "2024-02-06T15:05:31.372314Z"
        },
        "id": "6ZFVL1KjYLcz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Set the path to the directory containing the datasets\n",
        "dataset_path = '/kaggle/input/fault-detection'\n",
        "\n",
        "# Get the list of files in the directory\n",
        "files = os.listdir(dataset_path)\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through the files and read them into DataFrames\n",
        "for file in files[:3]:  # Assuming you want to read the first 15 datasets\n",
        "    file_path = os.path.join(dataset_path, file)\n",
        "    df= pd.read_csv(file_path)\n",
        "    # df['class'] = 'faultySignal'  # Change the file reading method based on your file format\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into one\n",
        "final_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:31.772594Z",
          "iopub.status.busy": "2024-02-06T15:05:31.772175Z",
          "iopub.status.idle": "2024-02-06T15:05:31.821979Z",
          "shell.execute_reply": "2024-02-06T15:05:31.820920Z",
          "shell.execute_reply.started": "2024-02-06T15:05:31.772560Z"
        },
        "id": "4BCTAJ7mYLc0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "classes_to_drop=['faultLabel']\n",
        "final_df.drop(classes_to_drop,inplace=True, axis=1)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:31.824520Z",
          "iopub.status.busy": "2024-02-06T15:05:31.824148Z",
          "iopub.status.idle": "2024-02-06T15:05:33.115824Z",
          "shell.execute_reply": "2024-02-06T15:05:33.114309Z",
          "shell.execute_reply.started": "2024-02-06T15:05:31.824490Z"
        },
        "id": "uSAFZ2u1YLc0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "final_df.to_csv('new_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:55.353604Z",
          "iopub.status.busy": "2024-02-06T15:05:55.352194Z",
          "iopub.status.idle": "2024-02-06T15:05:55.362212Z",
          "shell.execute_reply": "2024-02-06T15:05:55.360680Z",
          "shell.execute_reply.started": "2024-02-06T15:05:55.353561Z"
        },
        "id": "l03R4iSYYLc0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Path of the dataset\n",
        "datasetPath = '/content/drive/MyDrive/Dataset.csv'\n",
        "\n",
        "# Path of the model (saved/to save)\n",
        "modelPath = '/content/new-RNN (3).pth'\n",
        "\n",
        "# When True, retrain the whole model\n",
        "retrain = False\n",
        "\n",
        "# Size of the split\n",
        "trainSize = 0.85\n",
        "valSize = 0.05\n",
        "testSize = 0.1\n",
        "\n",
        "# Specify number of seconds for the window. Default: 16\n",
        "window_size = 16\n",
        "\n",
        "# Model hyper-parameters\n",
        "batch_size = 4\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 80\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# When True create graphs (takes more time)\n",
        "makeGraphs = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:56.820511Z",
          "iopub.status.busy": "2024-02-06T15:05:56.819467Z",
          "iopub.status.idle": "2024-02-06T15:05:56.826767Z",
          "shell.execute_reply": "2024-02-06T15:05:56.825805Z",
          "shell.execute_reply.started": "2024-02-06T15:05:56.820451Z"
        },
        "id": "zG4t6LlgYLc1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "classes_to_drop=['locLabel']\n",
        "target_classes = final_df[['locLabel']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:05:59.854852Z",
          "iopub.status.busy": "2024-02-06T15:05:59.854393Z",
          "iopub.status.idle": "2024-02-06T15:05:59.880999Z",
          "shell.execute_reply": "2024-02-06T15:05:59.879738Z",
          "shell.execute_reply.started": "2024-02-06T15:05:59.854818Z"
        },
        "id": "Rh-3qLj1YLc1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def min_max_norm(self,col):\n",
        "    self._data[col]=(self._data[col]-self._data[col].min())/(self._data[col].max()-self._data[col].min())\n",
        "\n",
        "\n",
        "def std_scaler(self,col):\n",
        "    self._data[col]=(self._data[col]-self._data[col].mean())/(self._data[col].std())\n",
        "\n",
        "def f1(test_loader, model):\n",
        "    f1 = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, labels) in enumerate(test_loader):\n",
        "            outputs = model(data)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            f1 += f1_score(labels, pred, average='macro')\n",
        "    avg_f1 = f1/len(test_loader)\n",
        "    return (avg_f1)\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path='/kaggle/working/new_data.csv', classes_to_drop=classes_to_drop, window_size=window_size, normalize=True, normalize_method='mean_std'):\n",
        "\n",
        "\n",
        "        self._window_size=window_size\n",
        "        self._data=pd.read_csv(file_path)\n",
        "\n",
        "        # The data is sorted by Class A,B,C the indexes of the dataframe have restarted by ignore index\n",
        "        self._data = self._data.sort_values(by=['locLabel'], inplace=False,ignore_index = True)\n",
        "\n",
        "        # class_uniq contains the letters of the drivers A,B and it loops across all of them\n",
        "        for class_uniq in list(self._data['locLabel'].unique()):\n",
        "            # Find the total number of elements belonging to a class\n",
        "            tot_number=sum(self._data['locLabel']==class_uniq)\n",
        "            # Number of elements to drop so that the class element is divisible by window size\n",
        "            to_drop=tot_number%window_size\n",
        "            # Returns the index of the first element of the class\n",
        "            index_to_start_removing=self._data[self._data['locLabel']==class_uniq].index[0]\n",
        "            # Drop element from first element to the element required\n",
        "            self._data.drop(self._data.index[index_to_start_removing:index_to_start_removing+to_drop],inplace=True)\n",
        "\n",
        "\n",
        "        # Resetting index of dataframe after dropping values\n",
        "        self._data = self._data.reset_index()\n",
        "        self._data = self._data.drop(['index'], axis=1)\n",
        "\n",
        "        index_starting_class=[] # This array contains the starting index of each class in the df\n",
        "        for class_uniq in list(self._data['locLabel'].unique()):\n",
        "            # Appending the index of first element of each clas\n",
        "            index_starting_class.append(self._data[self._data['locLabel']==class_uniq].index[0])\n",
        "\n",
        "        # Create the sequence of indexs of the windows\n",
        "        sequences=[]\n",
        "        for i in range(len(index_starting_class)):\n",
        "            # Check if beginning of next class is there\n",
        "            if i!=len(index_starting_class)-1:\n",
        "                ranges=np.arange(index_starting_class[i], index_starting_class[i+1])\n",
        "            else:\n",
        "                ranges = np.arange(index_starting_class[i], len(self._data))\n",
        "            for j in range(0,len(ranges),int(self._window_size/2)):\n",
        "                if len(ranges[j:j+self._window_size])==16:\n",
        "                    sequences.append(ranges[j:j+self._window_size])\n",
        "        self._sequences=sequences\n",
        "\n",
        "\n",
        "        # Take only the 'Class' which are the actual labels and store it in the labels of self\n",
        "        self._labels=self._data['locLabel']\n",
        "        # Dropping columns which have constant measurements because they would return nan in std\n",
        "        self._data.drop(classes_to_drop, inplace=True, axis=1)\n",
        "\n",
        "        # Function to normalize the data either with min_max or mean_std\n",
        "        if normalize:\n",
        "            for col in self._data.columns:\n",
        "                if normalize_method=='min_max':\n",
        "                    min_max_norm(self,col)\n",
        "                elif normalize_method==\"mean_std\":\n",
        "                    std_scaler(self,col)\n",
        "\n",
        "        # Create the array holding the windowed multidimensional arrays\n",
        "        X=np.empty((len(sequences), self._window_size, len(self._data.columns)))\n",
        "        y=[]\n",
        "\n",
        "        for n_row, sequence in enumerate(sequences):\n",
        "            X[n_row,:,:]=self._data.iloc[sequence]\n",
        "            # The corresponding driver of the sequence is the driver at first sequence\n",
        "            y.append(self._labels[sequence[0]])\n",
        "\n",
        "\n",
        "        assert len(y)==len(X)\n",
        "        #Assing the windowed dataset to the X of self\n",
        "        self._X= X\n",
        "\n",
        "        # Targets is a transformed version of y with drivers are encoded into 0 to 9\n",
        "        targets = preprocessing.LabelEncoder().fit_transform(y)\n",
        "        targets = torch.as_tensor(targets)  # Just converting it to a pytorch tensor\n",
        "        self._y=targets # Assign it to y of self\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._X)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return torch.FloatTensor(self._X[index,:,:]), self._y[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xABm6QlmYLc1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:06:05.037907Z",
          "iopub.status.busy": "2024-02-06T15:06:05.037417Z",
          "iopub.status.idle": "2024-02-06T15:06:07.406057Z",
          "shell.execute_reply": "2024-02-06T15:06:07.404779Z",
          "shell.execute_reply.started": "2024-02-06T15:06:05.037872Z"
        },
        "id": "Zax81-qzYLc1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "a = CustomDataset()\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "val_size = int(valSize * len(a))\n",
        "test_size = len(a)-train_size-val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                                batch_size=4,\n",
        "                                                shuffle=False,\n",
        "                                                drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:06:07.528646Z",
          "iopub.status.busy": "2024-02-06T15:06:07.528173Z",
          "iopub.status.idle": "2024-02-06T15:06:07.571397Z",
          "shell.execute_reply": "2024-02-06T15:06:07.570078Z",
          "shell.execute_reply.started": "2024-02-06T15:06:07.528607Z"
        },
        "id": "e15foCZpYLc2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "final_df.drop(classes_to_drop,inplace=True, axis=1)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:06:10.338598Z",
          "iopub.status.busy": "2024-02-06T15:06:10.338099Z",
          "iopub.status.idle": "2024-02-06T15:06:10.394394Z",
          "shell.execute_reply": "2024-02-06T15:06:10.393326Z",
          "shell.execute_reply.started": "2024-02-06T15:06:10.338563Z"
        },
        "id": "MEm3CCAWYLc2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply the scaler to your DataFrame\n",
        "normalized_data = scaler.fit_transform(final_df)\n",
        "\n",
        "# Create a new DataFrame with the normalized data\n",
        "normalized_df = pd.DataFrame(normalized_data, columns=final_df.columns)\n",
        "\n",
        "normalized_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:06:12.239141Z",
          "iopub.status.busy": "2024-02-06T15:06:12.238730Z",
          "iopub.status.idle": "2024-02-06T15:06:12.283015Z",
          "shell.execute_reply": "2024-02-06T15:06:12.281523Z",
          "shell.execute_reply.started": "2024-02-06T15:06:12.239106Z"
        },
        "id": "JZy_8VEHYLc2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "result_df = pd.concat([normalized_df, target_classes], axis=1)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:06:16.460413Z",
          "iopub.status.busy": "2024-02-06T15:06:16.458985Z",
          "iopub.status.idle": "2024-02-06T15:06:16.506763Z",
          "shell.execute_reply": "2024-02-06T15:06:16.505275Z",
          "shell.execute_reply.started": "2024-02-06T15:06:16.460345Z"
        },
        "id": "KPp0hDM1YLc2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "result_df['locLabel'] = encoder.fit_transform(result_df['locLabel'])\n",
        "\n",
        "# Retrieve the mapping of numerical codes to original class labels\n",
        "class_labels = encoder.classes_\n",
        "\n",
        "# Display the mapping\n",
        "for code, label in enumerate(class_labels):\n",
        "    print(f'Code: {code} -> Label: {label}')\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:06:18.961951Z",
          "iopub.status.busy": "2024-02-06T15:06:18.961503Z",
          "iopub.status.idle": "2024-02-06T15:06:18.995188Z",
          "shell.execute_reply": "2024-02-06T15:06:18.993550Z",
          "shell.execute_reply.started": "2024-02-06T15:06:18.961914Z"
        },
        "id": "R85P1QY0YLc2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "X = result_df.drop('locLabel',axis=1)\n",
        "y = result_df['locLabel']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:20:16.239137Z",
          "iopub.status.busy": "2024-02-06T15:20:16.237999Z",
          "iopub.status.idle": "2024-02-06T15:20:18.832745Z",
          "shell.execute_reply": "2024-02-06T15:20:18.831576Z",
          "shell.execute_reply.started": "2024-02-06T15:20:16.239081Z"
        },
        "id": "mutCvwcOYLc3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create and train an XGBoost classification model\n",
        "model = XGBClassifier(objective='multi:softmax', random_state=42)  # You may need to adjust the objective based on your problem\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:20:56.265643Z",
          "iopub.status.busy": "2024-02-06T15:20:56.264862Z",
          "iopub.status.idle": "2024-02-06T15:21:01.015664Z",
          "shell.execute_reply": "2024-02-06T15:21:01.014875Z",
          "shell.execute_reply.started": "2024-02-06T15:20:56.265598Z"
        },
        "id": "moEVl6L8YLc3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Create and train a Random Forest classification model\n",
        "model1 = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust the number of trees (n_estimators) as needed\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model1.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:21:24.261708Z",
          "iopub.status.busy": "2024-02-06T15:21:24.261266Z",
          "iopub.status.idle": "2024-02-06T15:21:24.780216Z",
          "shell.execute_reply": "2024-02-06T15:21:24.779299Z",
          "shell.execute_reply.started": "2024-02-06T15:21:24.261673Z"
        },
        "id": "Zz_FUcZqYLc3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Create and train a Decision Tree classification model\n",
        "model3 = DecisionTreeClassifier(max_depth=None, random_state=42)  # You can adjust max_depth as needed\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model3.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{class_report}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Set seeds for reproducibility\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "model = Sequential()\n",
        "#model.add(Dense(int((len(data[1])*2)), activation='relu', input_shape=(48, ))\n",
        "#model.add(Dense(y_train_encoded.shape[1]), activation='softmax', kernel_initializer=GlorotNormal())\n",
        "\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],), kernel_initializer=GlorotNormal()))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=L2())) #kernel_initializer=GlorotNormal()\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(Dense(16, activation='relu', kernel_regularizer=L2())) #kernel_initializer=GlorotNormal()\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(11, activation='softmax', kernel_initializer=GlorotNormal()))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train_encoded, epochs=500, batch_size=32, validation_split = 0.1)"
      ],
      "metadata": {
        "id": "GGjCyYS1r07f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_type = model.evaluate(X_test, y_test_encoded)[1]\n",
        "print(res_type)"
      ],
      "metadata": {
        "id": "H2Lr1CXNr102"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(model, input_data, epsilon):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(input_data)\n",
        "        predictions = model(input_data)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(y_test_encoded, predictions)\n",
        "\n",
        "    # Get the gradients of the loss w.r.t. the input data\n",
        "    gradient = tape.gradient(loss, input_data)\n",
        "    # Get the sign of the gradients\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    # Perturb the input data\n",
        "    perturbed_data = input_data + epsilon * signed_grad\n",
        "    # Clip the perturbed data to ensure it stays within the valid range\n",
        "    perturbed_data = tf.clip_by_value(perturbed_data, 0, 1)\n",
        "    return perturbed_data\n",
        "\n",
        "# Define parameters for the FGSM attack\n",
        "epsilon = 0.5\n",
        "\n",
        "# Convert X_train DataFrame to a TensorFlow tensor\n",
        "X_train_tensor = tf.constant(X_train.values, dtype=tf.float32)\n",
        "X_test_tensor = tf.constant(X_test.values, dtype=tf.float32)\n",
        "# Generate adversarial examples using FGSM\n",
        "adversarial_X_test = fgsm_attack(model, X_test_tensor, epsilon)\n",
        "\n",
        "# Evaluate the model on adversarial examples\n",
        "model.evaluate(adversarial_X_test, y_test_encoded)"
      ],
      "metadata": {
        "id": "ZS7lHIcsr-40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given ASR values for two sets\n",
        "asr_values_set1 = [0.406,0.119, 0.094, 0.08, 0.06, 0.06, 0.059, 0.058, 0.062, 0.057, 0.055]\n",
        "\n",
        "# Create a list of feature numbers starting from one\n",
        "feature_numbers = [0,0.05,0.1,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50]\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.ylim(0, 1.0)\n",
        "plt.plot(feature_numbers, asr_values_set1, marker='o', linestyle='-', color='b', label='fgsm')\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs epsilon')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/model_reimplemented.pdf', format='pdf')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mz3eXo5Kucik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:09:09.762993Z",
          "iopub.status.busy": "2024-02-06T15:09:09.762508Z",
          "iopub.status.idle": "2024-02-06T15:09:09.771813Z",
          "shell.execute_reply": "2024-02-06T15:09:09.770321Z",
          "shell.execute_reply.started": "2024-02-06T15:09:09.762955Z"
        },
        "id": "VNyANYrNYLc4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:09:14.604786Z",
          "iopub.status.busy": "2024-02-06T15:09:14.604383Z",
          "iopub.status.idle": "2024-02-06T15:09:14.686053Z",
          "shell.execute_reply": "2024-02-06T15:09:14.684677Z",
          "shell.execute_reply.started": "2024-02-06T15:09:14.604755Z"
        },
        "id": "rRqv3qmUYLc5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn1 = torch.nn.GRU(num_features, 220, batch_first=True, bidirectional=True)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.fc = torch.nn.Linear(440, 4)  # Adjust the input size to the linear layer\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn1_out, h_t1 = self.rnn1(x)\n",
        "        rnn1_out1 = self.dropout(rnn1_out)\n",
        "        fc_out = self.fc(rnn1_out1[:, -1, :])\n",
        "        out = self.sigmoid(fc_out)\n",
        "        return out\n",
        "inputs, classes = next(iter(train_loader))\n",
        "model5 = RNN(inputs.shape[0],inputs.shape[1],inputs.shape[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:09:16.280611Z",
          "iopub.status.busy": "2024-02-06T15:09:16.279086Z",
          "iopub.status.idle": "2024-02-06T15:16:23.088182Z",
          "shell.execute_reply": "2024-02-06T15:16:23.087146Z",
          "shell.execute_reply.started": "2024-02-06T15:09:16.280563Z"
        },
        "id": "B9QmzZ4XYLc5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model5 = model5.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "n_epochs = 80\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model5(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_acc += torch.sum(preds == labels.data)\n",
        "\n",
        "    # Calculate metrics for the epoch\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_acc.double() / len(train_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs} -- Train Loss: {train_loss:.4f} -- Train Accuracy: {train_acc:.4f}\")\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(training_time)\n",
        "total_params = sum(p.numel() for p in model5.parameters())\n",
        "print(f\"Total Model Parameters: {total_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:19:07.079251Z",
          "iopub.status.busy": "2024-02-06T15:19:07.078735Z",
          "iopub.status.idle": "2024-02-06T15:19:25.122754Z",
          "shell.execute_reply": "2024-02-06T15:19:25.121300Z",
          "shell.execute_reply.started": "2024-02-06T15:19:07.079216Z"
        },
        "id": "5mnBFn1BYLc6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pip install torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl106tIgYLc6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "save_path = '/kaggle/working/model_without_defence_faultzone.pt'\n",
        "torch.save(model5.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-06T15:19:38.904103Z",
          "iopub.status.busy": "2024-02-06T15:19:38.903670Z",
          "iopub.status.idle": "2024-02-06T15:19:59.509513Z",
          "shell.execute_reply": "2024-02-06T15:19:59.508308Z",
          "shell.execute_reply.started": "2024-02-06T15:19:38.904070Z"
        },
        "id": "McgzF2k3YLc6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import torchvision\n",
        "import torchattacks\n",
        "model5.to(\"cpu\")\n",
        "\n",
        "# Load the pre-trained model\n",
        "model5.eval()\n",
        "\n",
        "# Assuming you have a DataLoader for the test set called 'test_loader'\n",
        "# Adjust this based on your data loading procedure\n",
        "# Also, make sure your test set is properly normalized\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.45 # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.45 # Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.45 # Perturbation magnitude for C&W\n",
        "\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "correct_adversarial_rfgsm=0\n",
        "correct_adversarial_PGD=0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = model5(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, labels)\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, labels)\n",
        "\n",
        "    # C&W: Craft adversarial example\n",
        "    attack_cw = torchattacks.CW(model5, c=epsilon_cw, kappa=0)\n",
        "    adversarial_inputs_cw = attack_cw(inputs, labels)\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, labels)\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = model5(adversarial_inputs_fgsm)\n",
        "    outputs_adversarial_bim = model5(adversarial_inputs_bim)\n",
        "    outputs_adversarial_cw = model5(adversarial_inputs_cw)\n",
        "    outputs_adversarial_rfgsm = model5(adversarial_inputs_RFGSM)\n",
        "    outputs_adversarial_PGD = model5(adversarial_inputs_PGD)\n",
        "\n",
        "\n",
        "    # Update accuracy metrics\n",
        "    total += labels.size(0)\n",
        "    correct_original += (predicted_original == labels).sum().item()\n",
        "    correct_adversarial_fgsm += (torch.argmax(outputs_adversarial_fgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_bim += (torch.argmax(outputs_adversarial_bim, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_cw += (torch.argmax(outputs_adversarial_cw, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_rfgsm += (torch.argmax(outputs_adversarial_rfgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_PGD += (torch.argmax(outputs_adversarial_PGD, dim=1) == labels).sum().item()\n",
        "\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy_original = correct_original / total\n",
        "accuracy_adversarial_fgsm = correct_adversarial_fgsm / total\n",
        "accuracy_adversarial_bim = correct_adversarial_bim / total\n",
        "accuracy_adversarial_cw = correct_adversarial_cw / total\n",
        "accuracy_adversarial_rfgsm = correct_adversarial_rfgsm / total\n",
        "accuracy_adversarial_PGD = correct_adversarial_PGD / total\n",
        "\n",
        "print(f'Accuracy on Original Data: {accuracy_original * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (FGSM): {accuracy_adversarial_fgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (BIM): {accuracy_adversarial_bim * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (C&W): {accuracy_adversarial_cw * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (RFGSM): {accuracy_adversarial_rfgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (PDG): {accuracy_adversarial_PGD * 100:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh5SZ1OkYLc6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given ASR values for two sets\n",
        "asr_values_set1 = [0.958,0.451, 0.381, 0.298, 0.284, 0.27, 0.25, 0.208, 0.201, 0.201, 0.201]\n",
        "asr_values_set2 = [0.958,0.701, 0.534, 0.444, 0.375,0.34, 0.319,  0.319, 0.291, 0.256, 0.27]\n",
        "asr_values_set3 = [0.958,0.423, 0.423, 0.423, 0.423, 0.423, 0.423, 0.423, 0.423, 0.423, 0.423]\n",
        "asr_values_set4 = [0.958,0.381, 0.263, 0.263, 0.236, 0.222,0.222, 0.215,  0.208, 0.222, 0.215]\n",
        "asr_values_set5 = [0.958,0.381, 0.27, 0.256, 0.236, 0.243, 0.236, 0.229, 0.243, 0.256, 0.25]\n",
        "\n",
        "# Create a list of feature numbers starting from one\n",
        "feature_numbers = [0,0.05,0.1,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50]\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.ylim(0, 1.0)\n",
        "plt.plot(feature_numbers, asr_values_set1, marker='o', linestyle='-', color='b', label='fgsm')\n",
        "plt.plot(feature_numbers, asr_values_set2, marker='s', linestyle='-', color='r', label='bim')\n",
        "plt.plot(feature_numbers, asr_values_set3, marker='^', linestyle='-', color='g', label='cw')  # Different color for set3\n",
        "plt.plot(feature_numbers, asr_values_set4, marker='*', linestyle='-', color='orange', label='rfgsm')  # Different color for set4\n",
        "plt.plot(feature_numbers, asr_values_set5, marker='D', linestyle='-', color='purple', label='pgd')\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs epsilon')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/model_WB_faultzone.pdf', format='pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:10:52.935529Z",
          "iopub.status.busy": "2024-02-03T18:10:52.935164Z",
          "iopub.status.idle": "2024-02-03T18:10:52.943206Z",
          "shell.execute_reply": "2024-02-03T18:10:52.941520Z",
          "shell.execute_reply.started": "2024-02-03T18:10:52.935499Z"
        },
        "id": "FJCcHuuvYLc7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:09:11.156354Z",
          "iopub.status.busy": "2024-02-03T18:09:11.155874Z",
          "iopub.status.idle": "2024-02-03T18:09:11.234135Z",
          "shell.execute_reply": "2024-02-03T18:09:11.232372Z",
          "shell.execute_reply.started": "2024-02-03T18:09:11.156285Z"
        },
        "id": "zp1z_88fYLc7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(RNN, self).__init__()\n",
        "        self.rnn1 = torch.nn.GRU(num_features, 220, batch_first=True, bidirectional=True)\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.fc = torch.nn.Linear(440, 11)  # Adjust the input size to the linear layer\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn1_out, h_t1 = self.rnn1(x)\n",
        "        rnn1_out1 = self.dropout(rnn1_out)\n",
        "        fc_out = self.fc(rnn1_out1[:, -1, :])\n",
        "        out = self.sigmoid(fc_out)\n",
        "        return out\n",
        "inputs, classes = next(iter(train_loader))\n",
        "model5 = RNN(inputs.shape[0],inputs.shape[1],inputs.shape[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-29T13:35:12.981628Z",
          "iopub.status.busy": "2024-01-29T13:35:12.980600Z",
          "iopub.status.idle": "2024-01-29T15:10:18.123837Z",
          "shell.execute_reply": "2024-01-29T15:10:18.122632Z",
          "shell.execute_reply.started": "2024-01-29T13:35:12.981582Z"
        },
        "id": "ITbgo8JCYLc7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import torchattacks\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
        "epsilon_fgsm = 0.2  # FGSM perturbation magnitude\n",
        "epsilon_bim = 0.2# BIM perturbation magnitude\n",
        " # C&W perturbation magnitude\n",
        "\n",
        "n_epochs = 80\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass on the original input\n",
        "        outputs = model5(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass on the original input\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # FGSM: Add perturbation to the input for FGSM attack\n",
        "        fgsm_attack = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "        fgsm_adversarial_inputs = fgsm_attack(inputs, labels)\n",
        "\n",
        "        # BIM: Add perturbation to the input for BIM attack\n",
        "        bim_attack = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "        bim_adversarial_inputs = bim_attack(inputs, labels)\n",
        "\n",
        "\n",
        "        # Forward pass on adversarial inputs for all attacks\n",
        "        fgsm_adversarial_outputs = model5(fgsm_adversarial_inputs)\n",
        "        bim_adversarial_outputs = model5(bim_adversarial_inputs)\n",
        "\n",
        "        # Calculate losses for all attacks\n",
        "        fgsm_adversarial_loss = criterion(fgsm_adversarial_outputs, labels)\n",
        "        bim_adversarial_loss = criterion(bim_adversarial_outputs, labels)\n",
        "\n",
        "        # Backward pass on adversarial inputs for all attacks\n",
        "        fgsm_adversarial_loss.backward()\n",
        "        bim_adversarial_loss.backward()\n",
        "\n",
        "        # Update gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += (fgsm_adversarial_loss.item() + bim_adversarial_loss.item()) * inputs.size(0)\n",
        "        _, fgsm_preds = torch.max(fgsm_adversarial_outputs, 1)\n",
        "        _, bim_preds = torch.max(bim_adversarial_outputs, 1)\n",
        "        train_acc += (torch.sum(fgsm_preds == labels.data) + torch.sum(bim_preds == labels.data))\n",
        "\n",
        "    # Calculate metrics for the epoch\n",
        "    train_loss /= (2 * len(train_loader.dataset))\n",
        "    train_acc = train_acc.double() / (2 * len(train_loader.dataset))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs} -- Train Loss: {train_loss:.4f} -- Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(training_time)\n",
        "total_params = sum(p.numel() for p in model5.parameters())\n",
        "print(f\"Total Model Parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3mGotHSYLc7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "save_path = '/kaggle/working/model_with_defence_faultzone.pt'\n",
        "torch.save(model5.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:10:26.438574Z",
          "iopub.status.busy": "2024-02-03T18:10:26.438214Z",
          "iopub.status.idle": "2024-02-03T18:10:26.491586Z",
          "shell.execute_reply": "2024-02-03T18:10:26.490826Z",
          "shell.execute_reply.started": "2024-02-03T18:10:26.438543Z"
        },
        "id": "fvrBI_emYLdD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model5.load_state_dict(torch.load('/kaggle/input/treaind-new/model_with_defence_faultzone.pt'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:11:21.138049Z",
          "iopub.status.busy": "2024-02-03T18:11:21.137582Z",
          "iopub.status.idle": "2024-02-03T18:11:46.356874Z",
          "shell.execute_reply": "2024-02-03T18:11:46.355932Z",
          "shell.execute_reply.started": "2024-02-03T18:11:21.138014Z"
        },
        "id": "bt7bFlzKYLdD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "###### import torchvision\n",
        "import torchattacks\n",
        "\n",
        "# Load the pre-trained model\n",
        "model5.eval()\n",
        "\n",
        "# Assuming you have a DataLoader for the test set called 'test_loader'\n",
        "# Adjust this based on your data loading procedure\n",
        "# Also, make sure your test set is properly normalized\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.5# Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.5  #Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.5# Perturbation magnitude for C&W\n",
        "\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "correct_adversarial_rfgsm=0\n",
        "correct_adversarial_PGD=0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = model5(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, labels)\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, labels)\n",
        "\n",
        "    # C&W: Craft adversarial example\n",
        "    attack_cw = torchattacks.CW(model5, c=epsilon_cw, kappa=0)\n",
        "    adversarial_inputs_cw = attack_cw(inputs, labels)\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, labels)\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = model5(adversarial_inputs_fgsm)\n",
        "    outputs_adversarial_bim = model5(adversarial_inputs_bim)\n",
        "    outputs_adversarial_cw = model5(adversarial_inputs_cw)\n",
        "    outputs_adversarial_rfgsm = model5(adversarial_inputs_RFGSM)\n",
        "    outputs_adversarial_PGD = model5(adversarial_inputs_PGD)\n",
        "\n",
        "\n",
        "    # Update accuracy metrics\n",
        "    total += labels.size(0)\n",
        "    correct_original += (predicted_original == labels).sum().item()\n",
        "    correct_adversarial_fgsm += (torch.argmax(outputs_adversarial_fgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_bim += (torch.argmax(outputs_adversarial_bim, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_cw += (torch.argmax(outputs_adversarial_cw, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_rfgsm += (torch.argmax(outputs_adversarial_rfgsm, dim=1) == labels).sum().item()\n",
        "    correct_adversarial_PGD += (torch.argmax(outputs_adversarial_PGD, dim=1) == labels).sum().item()\n",
        "\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy_original = correct_original / total\n",
        "accuracy_adversarial_fgsm = correct_adversarial_fgsm / total\n",
        "accuracy_adversarial_bim = correct_adversarial_bim / total\n",
        "accuracy_adversarial_cw = correct_adversarial_cw / total\n",
        "accuracy_adversarial_rfgsm = correct_adversarial_rfgsm / total\n",
        "accuracy_adversarial_PGD = correct_adversarial_PGD / total\n",
        "\n",
        "print(f'Accuracy on Original Data: {accuracy_original * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (FGSM): {accuracy_adversarial_fgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (BIM): {accuracy_adversarial_bim * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (C&W): {accuracy_adversarial_cw * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (RFGSM): {accuracy_adversarial_rfgsm * 100:.2f}%')\n",
        "print(f'Accuracy on Adversarial Data (PDG): {accuracy_adversarial_PGD * 100:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDOamSd0YLdE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Given ASR values for two sets\n",
        "asr_values_set1 = [0.965,0.944, 0.93, 0.93, 0.916, 0.868, 0.819, 0.763, 0.638, 0.541, 0.409]\n",
        "asr_values_set2 = [0.965,0.951, 0.951, 0.951, 0.951,0.923, 0.902,  0.833, 0.722, 0.68, 0.68]\n",
        "asr_values_set3 = [0.965,0.951, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944, 0.944]\n",
        "asr_values_set4 = [0.965,0.93, 0.916, 0.916, 0.909, 0.881,0.868, 0.84,  0.722, 0.631, 0.625]\n",
        "asr_values_set5 = [0.965,0.93, 0.93, 0.923, 0.909, 0.902, 0.868, 0.826, 0.645, 0.513, 0.541]\n",
        "\n",
        "# Create a list of feature numbers starting from one\n",
        "feature_numbers = [0,0.05,0.1,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50]\n",
        "\n",
        "# Plotting the graphs\n",
        "plt.ylim(0, 1.1)\n",
        "plt.plot(feature_numbers, asr_values_set1, marker='o', linestyle='-', color='b', label='fgsm')\n",
        "plt.plot(feature_numbers, asr_values_set2, marker='s', linestyle='-', color='r', label='bim')\n",
        "plt.plot(feature_numbers, asr_values_set3, marker='^', linestyle='-', color='g', label='cw')  # Different color for set3\n",
        "plt.plot(feature_numbers, asr_values_set4, marker='*', linestyle='-', color='orange', label='rfgsm')  # Different color for set4\n",
        "plt.plot(feature_numbers, asr_values_set5, marker='D', linestyle='-', color='purple', label='pgd')\n",
        "# Adding legend\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('epsilon')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs epsilon')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/model_WB_Defence_faultzone.pdf', format='pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:12:48.694757Z",
          "iopub.status.busy": "2024-02-03T18:12:48.694382Z",
          "iopub.status.idle": "2024-02-03T18:12:48.702853Z",
          "shell.execute_reply": "2024-02-03T18:12:48.701507Z",
          "shell.execute_reply.started": "2024-02-03T18:12:48.694725Z"
        },
        "id": "pMrx5DTpYLdE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:12:53.075561Z",
          "iopub.status.busy": "2024-02-03T18:12:53.075141Z",
          "iopub.status.idle": "2024-02-03T18:12:55.597164Z",
          "shell.execute_reply": "2024-02-03T18:12:55.595820Z",
          "shell.execute_reply.started": "2024-02-03T18:12:53.075529Z"
        },
        "id": "fVzC2xaXYLdE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "a = CustomDataset()\n",
        "trainSize = 0.9\n",
        "# valSize = 0.05\n",
        "a = CustomDataset()\n",
        "\n",
        "# Defining sizes\n",
        "train_size = int(trainSize * len(a))\n",
        "test_size = len(a)-train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    a, [train_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=4,\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T18:13:07.101202Z",
          "iopub.status.busy": "2024-02-03T18:13:07.100753Z",
          "iopub.status.idle": "2024-02-03T19:17:30.031449Z",
          "shell.execute_reply": "2024-02-03T19:17:30.030340Z",
          "shell.execute_reply.started": "2024-02-03T18:13:07.101167Z"
        },
        "id": "1wct7jANYLdE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the generator and discriminator for the GAN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, batch_size,window_size,num_features,latent_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_features = num_features\n",
        "        self.window_size = window_size\n",
        "       # self.fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.fc1 = nn.Linear(num_features, latent_dim)\n",
        "        self.fc2 = nn.Linear(latent_dim, 256)\n",
        "        self.fc3 = nn.Linear(256,batch_size*window_size)\n",
        "        self.fc4 = nn.Linear(batch_size*window_size,num_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        #return x.view(x.size(0), 1, -1)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, batch_size, window_size, num_features):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(num_features, 160)\n",
        "        self.fc2 = nn.Linear(160, 200)\n",
        "        self.fc3 = nn.Linear(200, 256)\n",
        "        self.fc4 = nn.Linear(256, 512)\n",
        "        self.fc5 = nn.Linear(512, 1)\n",
        "        self.window_size = window_size\n",
        "        self.num_features = num_features\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "      #x = x.view(-1, self.num_features)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = F.relu(self.fc3(x))\n",
        "      x = F.relu(self.fc4(x))\n",
        "      x = torch.sigmoid(self.fc5(x))\n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "# Define the GAN training function\n",
        "\n",
        "def train_gan(generator, discriminator, train_loader, num_epochs=100, lr=0.0002,\n",
        "              device=torch.device('cpu')):\n",
        "\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    # Define the loss functions and optimizers\n",
        "\n",
        "    adversarial_loss = nn.BCELoss()\n",
        "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (inputs,Labels) in enumerate(train_loader):\n",
        "            # Move data to device\n",
        "            inputs = inputs.to(device)\n",
        "            Labels = Labels.to(device)\n",
        "\n",
        "            # Train discriminator on real data\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            real_labels = torch.ones(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            real_outputs = discriminator(inputs)\n",
        "            discriminator_loss_real = adversarial_loss(real_outputs, real_labels)\n",
        "            discriminator_loss_real.backward()\n",
        "\n",
        "            # Train discriminator on fake data generated by the generator\n",
        "            generator_optimizer.zero_grad()\n",
        "            latent_inputs = torch.randn(inputs.shape[0], inputs.shape[1], inputs.shape[2]).to(device)\n",
        "            fake_inputs = generator(latent_inputs)\n",
        "            fake_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            fake_outputs = discriminator(fake_inputs)\n",
        "            discriminator_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
        "            discriminator_loss_fake.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "            attack_fgsm = torchattacks.FGSM(model5, eps=0.05)\n",
        "            adversarial_inputs_fgsm = attack_fgsm(inputs, torch.ones_like(Labels))\n",
        "            attack_bim = torchattacks.BIM(model5, eps=0.05)\n",
        "            adversarial_inputs_bim = attack_bim(inputs, torch.ones_like(Labels))\n",
        "            adversarial_inputs_combined = torch.cat([adversarial_inputs_fgsm, adversarial_inputs_bim], dim=0)\n",
        "            fake_labels = torch.zeros(adversarial_inputs_combined.size(0), adversarial_inputs_combined.size(1), 1).to(device)\n",
        "            fake_outputs = discriminator(adversarial_inputs_combined)\n",
        "            discriminator_loss_fake = adversarial_loss(fake_outputs, fake_labels)\n",
        "            discriminator_loss_fake.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "\n",
        "            # Train generator to generate samples that increase the discriminator loss\n",
        "            generator_optimizer.zero_grad()\n",
        "            latent_inputs = torch.randn(inputs.shape[0], inputs.shape[1], inputs.shape[2]).to(device)\n",
        "            fake_inputs = generator(latent_inputs)\n",
        "            # @S: generator wants to maximize the probability of the discriminator being wrong. So loss is computed between discriminator's output to a fake image and the\n",
        "            #fake label (if the fake label is 0)\n",
        "            fake_labels = torch.zeros(inputs.size(0), inputs.size(1), 1).to(device)\n",
        "            generator_loss =adversarial_loss(discriminator(fake_inputs), real_labels)\n",
        "            generator_loss.backward()\n",
        "            generator_optimizer.step()\n",
        "            if i % 10 == 0:\n",
        "              print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'\n",
        "                      .format(epoch, num_epochs, i, len(train_loader),\n",
        "discriminator_loss_real.item() + discriminator_loss_fake.item(), generator_loss.item()))\n",
        "                # Return the trained generator\n",
        "    return generator,discriminator\n",
        "\n",
        "\n",
        "# Define the number of epochs and learning rate for training the GAN\n",
        "num_epochs = 100\n",
        "lr = 0.0002\n",
        "inputs, classes = next(iter(train_loader))\n",
        "# Create the GAN models\n",
        "batch_size, window_size, num_features = inputs.shape\n",
        "generator = Generator(batch_size,window_size,num_features)\n",
        "discriminator = Discriminator(batch_size, window_size, num_features)\n",
        "\n",
        "# Train the GAN on your data\n",
        "trained_generator_new,trained_discriminator = train_gan(generator, discriminator, train_loader, num_epochs=num_epochs, lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:32:20.634933Z",
          "iopub.status.busy": "2024-02-03T19:32:20.634565Z",
          "iopub.status.idle": "2024-02-03T19:32:20.643658Z",
          "shell.execute_reply": "2024-02-03T19:32:20.642739Z",
          "shell.execute_reply.started": "2024-02-03T19:32:20.634904Z"
        },
        "id": "2LVn3__kYLdF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.save(trained_generator_new.state_dict(), '/kaggle/working/trained_generator_faultzone.pth')\n",
        "torch.save(trained_discriminator.state_dict(), '/kaggle/working/trained_discriminator_faultzone.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:31:40.575354Z",
          "iopub.status.busy": "2024-02-03T19:31:40.574931Z",
          "iopub.status.idle": "2024-02-03T19:31:40.798914Z",
          "shell.execute_reply": "2024-02-03T19:31:40.797357Z",
          "shell.execute_reply.started": "2024-02-03T19:31:40.575297Z"
        },
        "id": "ERv56sp5YLdF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "noise4 = torch.randn(800, 16, 50)\n",
        "\n",
        "generated_data4 = trained_generator_new(noise4)\n",
        "\n",
        "surrogate_outputs = model5(generated_data4)\n",
        "\n",
        "# Get the predicted class labels for each sample in the generated data\n",
        "predicted_labels = torch.argmax(surrogate_outputs, dim=1)\n",
        "print(predicted_labels)\n",
        "# Print the predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:32:34.115105Z",
          "iopub.status.busy": "2024-02-03T19:32:34.114708Z",
          "iopub.status.idle": "2024-02-03T19:32:34.157370Z",
          "shell.execute_reply": "2024-02-03T19:32:34.156381Z",
          "shell.execute_reply.started": "2024-02-03T19:32:34.115072Z"
        },
        "id": "GykcPCeOYLdF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# List to store predicted class labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "trained_discriminator.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in test_loader:\n",
        "\n",
        "        # Get the discriminator's output for the current batch\n",
        "        surrogate_outputs = trained_discriminator(inputs)\n",
        "\n",
        "        # Apply thresholding to determine class labels\n",
        "        threshold = 0.5\n",
        "        batch_predicted_labels = (surrogate_outputs >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "        predicted_labels.append(batch_predicted_labels)\n",
        "\n",
        "# Convert the list of predicted labels to a single tensor\n",
        "predicted_labels = torch.cat(predicted_labels, dim=0)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:32:36.815566Z",
          "iopub.status.busy": "2024-02-03T19:32:36.814299Z",
          "iopub.status.idle": "2024-02-03T19:32:36.823038Z",
          "shell.execute_reply": "2024-02-03T19:32:36.821853Z",
          "shell.execute_reply.started": "2024-02-03T19:32:36.815513Z"
        },
        "id": "RmjpZxyqYLdF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# True labels (all 1)\n",
        "true_labels = torch.ones_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:32:39.502900Z",
          "iopub.status.busy": "2024-02-03T19:32:39.502517Z",
          "iopub.status.idle": "2024-02-03T19:32:39.669348Z",
          "shell.execute_reply": "2024-02-03T19:32:39.667913Z",
          "shell.execute_reply.started": "2024-02-03T19:32:39.502867Z"
        },
        "id": "uxWCKJcGYLdF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "noise4 = torch.randn(1500, 16, 50)\n",
        "\n",
        "generated_data4 = trained_generator_new(noise4)\n",
        "\n",
        "surrogate_outputs = trained_discriminator(generated_data4)\n",
        "predicted_labels = []\n",
        "\n",
        "# Apply thresholding to determine class labels\n",
        "threshold = 0.5\n",
        "batch_predicted_labels = (surrogate_outputs >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "predicted_labels.append(batch_predicted_labels)\n",
        "\n",
        "# Convert the list of predicted labels to a single tensor\n",
        "predicted_labels = torch.cat(predicted_labels, dim=0)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:32:42.194110Z",
          "iopub.status.busy": "2024-02-03T19:32:42.193533Z",
          "iopub.status.idle": "2024-02-03T19:32:42.200276Z",
          "shell.execute_reply": "2024-02-03T19:32:42.199380Z",
          "shell.execute_reply.started": "2024-02-03T19:32:42.194077Z"
        },
        "id": "hgu-bsaCYLdF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:36:14.214414Z",
          "iopub.status.busy": "2024-02-03T19:36:14.214067Z",
          "iopub.status.idle": "2024-02-03T19:36:33.359038Z",
          "shell.execute_reply": "2024-02-03T19:36:33.357841Z",
          "shell.execute_reply.started": "2024-02-03T19:36:14.214387Z"
        },
        "id": "0GkxlFFoYLdG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import torchvision\n",
        "import torchattacks\n",
        "\n",
        "# Load the pre-trained model\n",
        "model5.eval()\n",
        "predicted_labels_fgsm= []\n",
        "predicted_labels_bim= []\n",
        "predicted_labels_cw= []\n",
        "predicted_labels_RFGSM=[]\n",
        "predicted_labels_PGD=[]\n",
        "# Assuming you have a DataLoader for the test set called 'test_loader'\n",
        "# Adjust this based on your data loading procedure\n",
        "# Also, make sure your test set is properly normalized\n",
        "\n",
        "# Attack parameters\n",
        "epsilon_fgsm = 0.15 # Perturbation magnitude for FGSM\n",
        "epsilon_bim = 0.15# Perturbation magnitude for BIM\n",
        "epsilon_cw = 0.15# Perturbation magnitude for C&W\n",
        "\n",
        "\n",
        "threshold = 0.5\n",
        "correct_original = 0\n",
        "correct_adversarial_fgsm = 0\n",
        "correct_adversarial_bim = 0\n",
        "correct_adversarial_cw = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Forward pass on the original input\n",
        "    outputs_original = model5(inputs)\n",
        "    _, predicted_original = torch.max(outputs_original, 1)\n",
        "\n",
        "    # FGSM: Craft adversarial example\n",
        "    attack_fgsm = torchattacks.FGSM(model5, eps=epsilon_fgsm)\n",
        "    adversarial_inputs_fgsm = attack_fgsm(inputs, labels)\n",
        "\n",
        "    # BIM: Craft adversarial example\n",
        "    attack_bim = torchattacks.BIM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_bim = attack_bim(inputs, labels)\n",
        "\n",
        "    # C&W: Craft adversarial example\n",
        "    attack_cw = torchattacks.CW(model5, c=epsilon_cw, kappa=0)\n",
        "    adversarial_inputs_cw = attack_cw(inputs, labels)\n",
        "\n",
        "\n",
        "    attack_RFGSM = torchattacks.RFGSM(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_RFGSM = attack_RFGSM(inputs, labels)\n",
        "\n",
        "    attack_PGD = torchattacks.PGD(model5, eps=epsilon_bim)\n",
        "    adversarial_inputs_PGD = attack_PGD(inputs, labels)\n",
        "\n",
        "    # Forward pass on the adversarial inputs\n",
        "    outputs_adversarial_fgsm = trained_discriminator(adversarial_inputs_fgsm)\n",
        "    batch_predicted_labels1 = (outputs_adversarial_fgsm >= threshold).int()  # 1 if >= threshold, 0 otherwise\n",
        "    predicted_labels_fgsm.append(batch_predicted_labels1)\n",
        "    outputs_adversarial_bim = trained_discriminator(adversarial_inputs_bim)\n",
        "    batch_predicted_labels2 = (outputs_adversarial_bim >= threshold).int()\n",
        "    predicted_labels_bim.append(batch_predicted_labels2)\n",
        "    outputs_adversarial_cw = trained_discriminator(adversarial_inputs_cw)\n",
        "    batch_predicted_labels3 = (outputs_adversarial_cw >= threshold).int()\n",
        "    predicted_labels_cw.append(batch_predicted_labels3)\n",
        "    outputs_adversarial_RFGSM = trained_discriminator(adversarial_inputs_RFGSM)\n",
        "    batch_predicted_labels4 = (outputs_adversarial_RFGSM >= threshold).int()\n",
        "    predicted_labels_RFGSM.append(batch_predicted_labels4)\n",
        "    outputs_adversarial_PGD = trained_discriminator(adversarial_inputs_PGD)\n",
        "    batch_predicted_labels5 = (outputs_adversarial_PGD >= threshold).int()\n",
        "    predicted_labels_PGD.append(batch_predicted_labels5)\n",
        "\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels_fgsm, dim=0)\n",
        "predicted_labels1 = torch.cat(predicted_labels_bim, dim=0)\n",
        "predicted_labels2= torch.cat(predicted_labels_cw, dim=0)\n",
        "predicted_labels3= torch.cat(predicted_labels_RFGSM, dim=0)\n",
        "predicted_labels4= torch.cat(predicted_labels_PGD, dim=0)\n",
        "\n",
        "print(predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:36:40.133780Z",
          "iopub.status.busy": "2024-02-03T19:36:40.133422Z",
          "iopub.status.idle": "2024-02-03T19:36:40.141593Z",
          "shell.execute_reply": "2024-02-03T19:36:40.140442Z",
          "shell.execute_reply.started": "2024-02-03T19:36:40.133750Z"
        },
        "id": "zNxDzu49YLdG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:36:42.214133Z",
          "iopub.status.busy": "2024-02-03T19:36:42.213746Z",
          "iopub.status.idle": "2024-02-03T19:36:42.220031Z",
          "shell.execute_reply": "2024-02-03T19:36:42.219283Z",
          "shell.execute_reply.started": "2024-02-03T19:36:42.214100Z"
        },
        "id": "L3uUtpvOYLdG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels1)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels1 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:36:43.614327Z",
          "iopub.status.busy": "2024-02-03T19:36:43.613856Z",
          "iopub.status.idle": "2024-02-03T19:36:43.621980Z",
          "shell.execute_reply": "2024-02-03T19:36:43.620399Z",
          "shell.execute_reply.started": "2024-02-03T19:36:43.614272Z"
        },
        "id": "9S9_LwauYLdG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels2)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels2 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:36:44.774505Z",
          "iopub.status.busy": "2024-02-03T19:36:44.774103Z",
          "iopub.status.idle": "2024-02-03T19:36:44.781864Z",
          "shell.execute_reply": "2024-02-03T19:36:44.780386Z",
          "shell.execute_reply.started": "2024-02-03T19:36:44.774473Z"
        },
        "id": "xhTFf2ZkYLdH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "###### True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels3)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels3 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T19:37:08.314162Z",
          "iopub.status.busy": "2024-02-03T19:37:08.313784Z",
          "iopub.status.idle": "2024-02-03T19:37:08.321744Z",
          "shell.execute_reply": "2024-02-03T19:37:08.320141Z",
          "shell.execute_reply.started": "2024-02-03T19:37:08.314122Z"
        },
        "id": "Xi_fwgrZYLdH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# True labels (all 0)\n",
        "true_labels = torch.zeros_like(predicted_labels4)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_labels4 == true_labels).sum().item()\n",
        "total_samples = true_labels.numel()  # Total number of elements in the tensor\n",
        "accuracy = correct_predictions / total_samples * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4259241,
          "sourceId": 7336598,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4273891,
          "sourceId": 7358200,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4286919,
          "sourceId": 7377201,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4357818,
          "sourceId": 7485574,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4395651,
          "sourceId": 7547493,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30627,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}